ccollections
OrderedDict
p0
((lp1
(lp2
S'J81-3002-63'
p3
a(dp4
S'svmval'
p5
F0.82401013
sS'features'
p6
S'-1 1:0.195872815427 2:0.0125651351955 3:0.0'
p7
sS'sentence'
p8
S'From syntax alone, there is no way to decide whether the antecedent of the relative clause is &quot;the salary of the employee&quot; or &quot;the employee&quot;.'
p9
sS'contextpos'
p10
S'But in a type-checking system in which the first argument of the relation &quot;live&quot; is associated with the human domain, and in which employees\xe2\x80\x94and not salaries\xe2\x80\x94are known to belong to this same domain, the first reading is not even possible. Ambiguities concerning different meanings of a word can often be resolved through domain checking. '
p11
sS'reallbl'
p12
S'-1'
p13
sS'depparse'
p14
S'->is---VBZ---root-----         0.195872815427<br />------->syntax---NN---prep_from-----<br />------------->alone---RB---advmod-----<br />------->there---EX---expl-----<br />------->way---NN---nsubj-----0.015893993096         0.0125651351955<br />------------->no---DT---det-----<br />------------->decide---VB---infmod-----0.00447989219833<br />------------------->to---TO---aux-----<br />------------------->salary---NN---ccomp-----0.00447989219833<br />------------------------->whether---IN---mark-----0.00895978439666<br />------------------------->antecedent---NN---nsubj-----0.00223994609917<br />------------------------------->the---DT---det-----<br />------------------------------->clause---NN---prep_of-----0.00895978439666<br />------------------------------------->the---DT---det-----<br />------------------------------------->relative---JJ---amod-----0.0201595148925<br />------------------------->is---VBZ---cop-----<br />------------------------->the---DT---det-----<br />------------------------->employee---NN---prep_of-----0.0201595148925<br />------------------------------->the---DT---det-----<br />------------------------------->employee---NN---conj_or-----0.0201595148925<br />------------------------------------->the---DT---det-----<br />------------------------->employee---NN---prep_of-----0.0201595148925<br />'
p15
sS'contextpre'
p16
S'Take for instance the query: Cual es el salario del empleado que vive en Lomas? What is the salary of the employee who lives in Lomas? '
p17
sS'textrank'
p18
F0.004319462281951657
saa(lp19
S'J81-3002-148'
p20
a(dp21
g5
F-0.6455077
sg6
S'-1 1:0.088643171945 2:0.0105959953973 3:0.0'
p22
sg8
S'These cases are: - In a subject position, with subject-verb inversion: the &quot;ningim&quot; determiner is assimilated to the &quot;every&quot; quantifier.'
p23
sg10
S"For instance, &quot;No vino ningim alumno&quot; (No student came) is represented: todo(x,alumno(x),no(vino(x))) every student not came - In a position other than the subject: the uningun&quot; determiner is assimilated to the indefinite article's quantifier. For instance, &quot;Carlos no tiene ning\xc3\xbcn hijo&quot; (Carlos has not any child) is represented: no(un(x,hijo(x),tiene(Carlos,x))) not a child has Another special case is the negation preceding the &quot;todo&quot; (every) determiner, e.g. &quot;No todo pajaro canta&quot; (Not every bird sings). "
p24
sg12
S'-1'
p25
sg14
S'->are---VBP---root-----         0.088643171945<br />------->cases---NNS---nsubj-----0.0105959953973         0.0105959953973<br />------------->These---DT---det-----<br />------->position---NN---prep_in-----<br />------------->a---DT---det-----<br />------------->subject---NN---nn-----<br />------------->inversion---NN---prep_with-----<br />------------------->subject-verb---JJ---amod-----<br />------------------->determiner---NN---dep-----<br />------------------------->the---DT---det-----<br />------------------------->ningim---NN---nn-----<br />------------------------->assimilated---VBN---rcmod-----<br />------------------------------->is---VBZ---auxpass-----<br />------------------------------->the---DT---prep_to-----<br />------------------------------------->every---DT---dep-----<br />------------------------------->quantifier---RB---advmod-----<br />'
p26
sg16
S'There are two other cases, however, in which the determiner uningiin&quot; coexists with an explicit negation. These cases require a different quantifier, as otherwise American Journal of Computational Linguistics, Volume 7, Number 3, July-September 1981 153 Veronica Dahl Translating Spanish into Logic through Logic the negation would be represented twice. '
p27
sg18
F0.003967009501031632
saa(lp28
S'J81-3002-234'
p29
a(dp30
g5
F-1.4292645
sg6
S'-1 1:0.015893993096 2:0.0425721012531 3:0.00111997304958'
p31
sg8
S"The grammar shown above, for instance, can be also used to retrieve the substring of a's, if it is modified as follows: "
p32
sg10
S'Right-hand sides of rules may contain PROLOG calls (which we shall note between square brackets). They must be successfully evaluated for the rule to apply. '
p33
sg12
S'-1'
p34
sg14
S"->used---VBN---root-----         0.015893993096<br />------->grammar---NN---nsubjpass-----0.0353199846577         0.0425721012531<br />------------->The---DT---det-----<br />------------->shown---VBN---partmod-----0.0229579900275<br />------------------->above---IN---prep-----<br />------------------------->for---IN---dep-----<br />------------------------------->instance---NN---pobj-----0.0694383290741<br />------->can---MD---aux-----<br />------->be---VB---auxpass-----<br />------->also---RB---advmod-----<br />------->retrieve---VB---xcomp-----<br />------------->grammar---NN---xsubj-----<br />------------->to---TO---aux-----<br />------------->substring---NN---dobj-----0.00223994609917         0.00111997304958<br />------------------->the---DT---det-----<br />------------------->'s---NNS---prep_of-----0.0<br />------------------------->a---DT---det-----<br />------->modified---VBN---advcl-----<br />------------->if---IN---mark-----<br />------------->it---PRP---nsubjpass-----<br />------------->is---VBZ---auxpass-----<br />------------->follows---VBZ---advcl-----<br />------------------->as---IN---mark-----<br />"
p35
sg16
S'In the rest of this paper, we shall only be concerned with parsing.  We might normally want the parser to retrieve more information than mere recognition. '
p36
sg18
F0.0038914948884665648
saa(lp37
S'J81-3002-322'
p38
a(dp39
g5
F-1.9066386
sg6
S'-1 1:0.00223994609917 2:0.0067198382975 3:0.0111997304958'
p40
sg8
S"Here &quot;...&quot; stands for any intermediate string of symbols, which the rule's application leaves untouched to the right of &quot;Donde&quot;."
p41
sg10
S'Thus, the skeleton derivation graph would now be as shown in Figure 8. Two rules (C3 and SK) have been eliminated, and the resulting graph is clearer.  '
p42
sg12
S'-1'
p43
sg14
S'->untouched---VBD---root-----         0.00223994609917<br />------->Here---VBG---dep-----<br />------->stands---NNS---nsubj-----0.0067198382975         0.0067198382975<br />------->string---NN---prep_for-----<br />------------->any---DT---det-----<br />------------->intermediate---JJ---amod-----<br />------------->symbols---NNS---prep_of-----<br />------------------->leaves---VBZ---rcmod-----<br />------------------------->symbols---NNS---dobj-----0.0111997304958         0.0111997304958<br />------------------------->application---NN---nsubj-----<br />------------------------------->rule---NN---poss-----<br />------------------------------------->the---DT---det-----<br />------->right---NN---prep_to-----<br />------------->the---DT---det-----<br />------------->Donde---NNP---prep_of-----<br />'
p44
sg16
S'which places it as the first complement. It must now skip the kernel so as to become the head of the sentence: SK) Wh-1(k) Kernel(/,s/,s2,$) Moved-mod(k,s3,s4) --> Wh-2(k) Modifier(k,s3,s4) Kernel(/,s/,s2,$) Finally, it can be replaced by a pronoun: PR) Wh-2(k) Modifier(k,s/,s2) --> donde  '
p45
sg18
F0.0038299051770827454
saa(lp46
S'J81-3002-126'
p47
a(dp48
g5
F-1.6155437
sg6
S'+1 1:0.00447989219833 2:0.0358391375866 3:0.00895978439666'
p49
sg8
S"Each quantification is thus assigned an equivalent &quot;for&quot; expression, in which the determiner's meaning is represented."
p50
sg10
S'Here are the representations of some of our Spanish quantifiers. The rest are considered in Section 2.2.1.2.  '
p51
sg12
S'+1'
p52
sg14
S'->assigned---VBN---root-----         0.00447989219833<br />------->quantification---NN---nsubjpass-----0.0358391375866         0.0358391375866<br />------------->Each---DT---det-----<br />------->is---VBZ---auxpass-----<br />------->thus---RB---advmod-----<br />------->equivalent---NN---dobj-----0.00895978439666         0.00895978439666<br />------------->an---DT---det-----<br />------->expression---NN---prep_for-----<br />------------->represented---VBN---rcmod-----<br />------------------->expression---NN---prep_in-----<br />------------------->meaning---NN---nsubjpass-----<br />------------------------->determiner---NN---poss-----<br />------------------------------->the---DT---det-----<br />------------------->is---VBZ---auxpass-----<br />'
p53
sg16
S"for(x,p,c) the intuitive meaning of which is: &quot;c holds for the set E of all x's in x's domain which satisfy p&quot;. In the formula c, the set E will be represented simply by the variable x, so that x plays a double role. "
p54
sg18
F0.0038144938397709953
saa(lp55
S'J81-3002-368'
p56
a(dp57
g5
F-1.9208422
sg6
S'-1 1:0.00223994609917 2:0.0 3:0.0179195687933'
p58
sg8
S'Some of them are meant to deal with ambiguity, which in our approach, as we have seen, is dealt with through the contextual typing of variables during the quantification process.'
p59
sg10
S'A common disadvantage of this integrated approach\xe2\x80\x94namely, that the syntactic/semantic grammar obtained is too domain-specific and therefore less transportable\xe2\x80\x94is avoided by relegating all domainspecific knowledge to the domain-dependent part of the lexicon (i.e., noun, verb, and adjective definitions). Furthermore, the fact that semantic agreement is equated with syntactic well-formedness evens the relative costs of doing semantic versus syntactic tests. '
p60
sg12
S'-1'
p61
sg14
S'->meant---VBN---root-----         0.00223994609917<br />------->Some---DT---nsubjpass-----         0.0<br />------------->them---PRP---prep_of-----<br />------->are---VBP---auxpass-----<br />------->deal---VB---xcomp-----<br />------------->Some---DT---xsubj-----<br />------------->to---TO---aux-----<br />------------->ambiguity---NNP---prep_with-----<br />------------------->dealt---VBN---rcmod-----<br />------------------------->ambiguity---NNP---nsubjpass-----<br />------------------------->approach---NN---prep_in-----<br />------------------------------->our---PRP$---poss-----<br />------------------------------->seen---VBN---dep-----<br />------------------------------------->approach---NN---dobj-----0.0179195687933         0.0179195687933<br />------------------------------------->as---IN---mark-----<br />------------------------------------->we---PRP---nsubj-----<br />------------------------------------->have---VBP---aux-----<br />------------------------->is---VBZ---auxpass-----<br />------------------------->with---IN---dep-----<br />------------------------->typing---NN---prep_through-----<br />------------------------------->the---DT---det-----<br />------------------------------->contextual---JJ---amod-----<br />------------------------------->variables---NNS---prep_of-----<br />------------------------->process---NN---prep_during-----<br />------------------------------->the---DT---det-----<br />------------------------------->quantification---NN---nn-----<br />'
p62
sg16
S'LUNAR, on the contrary, first generates deep structures and then maps them into a semantic representation. PHLIQA1 has several successive levels of semantic analysis, each requiring a special formal language. '
p63
sg18
F0.0037874650966209173
saa(lp64
S'J81-3002-33'
p65
a(dp66
g5
F-1.4775893
sg6
S'-1 1:0.0134707101682 2:0.04225353278 3:0.0'
p67
sg8
S'A complete listing of our PROLOG Spanish grammar is given in the Appendix in the Microfiche Supplement to this issue of the Journal.'
p68
sg10
S'The discussion of our analyzer is not intended to be normative: alternative solutions for the problems we encountered are certainly conceivable. Moreover, many of our choices were constrained by the hardware and software tools available to us. '
p69
sg12
S'-1'
p70
sg14
S'->given---VBN---root-----         0.0134707101682<br />------->listing---NN---nsubjpass-----0.0211044705418         0.04225353278<br />------------->A---DT---det-----<br />------------->complete---JJ---amod-----0.0166390069837<br />------------->grammar---NN---prep_of-----0.0166390069837<br />------------------->our---PRP$---poss-----<br />------------------->PROLOG---NNP---nn-----0.116473048886<br />------------------->Spanish---NNP---nn-----0.0404121305045<br />------->is---VBZ---auxpass-----<br />------->Appendix---NNP---prep_in-----<br />------------->the---DT---det-----<br />------------->Supplement---NNP---prep_in-----<br />------------------->the---DT---det-----<br />------------------->Microfiche---NNP---nn-----<br />------->issue---NN---prep_to-----<br />------------->this---DT---det-----<br />------------->Journal---NNP---prep_of-----<br />------------------->the---DT---det-----<br />'
p71
sg16
S'Then we present an informal definition of the logical system possessing these features which serves as our internal query language. Finally, we show a step-by-step development of a PROLOG analyser for Spanish, after an informal description of our programming tools. '
p72
sg18
F0.003780738691728284
saa(lp73
S'C08-1122-56'
p74
a(dp75
g5
F-1.0413874
sg6
S'+1 1:0.0138409700913 2:0.0479341109786 3:0.0542808950295'
p76
sg8
S'Given a document cluster, CollabRank makes use of the global word relationships in the cluster to evaluate and rank candidate phrases for each single document in the cluster based on the graph-based ranking algorithm.'
p77
sg10
S'Figure 1 gives the framework of the proposed approach.  In the first step of the above framework, different clustering algorithms will yield different clusters. '
p78
sg12
S'+1'
p79
sg14
S'->makes---VBZ---root-----         0.0138409700913<br />------->Given---VBN---prep-----<br />------------->cluster---NN---dep-----<br />------------------->a---DT---det-----<br />------------------->document---NN---nn-----<br />------->CollabRank---NNP---nsubj-----0.0479341109786         0.0479341109786<br />------->use---NN---dobj-----0.0179952603434         0.0542808950295<br />------------->relationships---NNS---prep_of-----0.0197180040048<br />------------------->the---DT---det-----<br />------------------->global---JJ---amod-----0.0599775370622<br />------------------->word---NN---nn-----0.0630976128155<br />------------------->cluster---NN---prep_in-----0.149960502862<br />------------------------->the---DT---det-----<br />------------------------->evaluate---VB---infmod-----0.0157744032039<br />------------------------------->to---TO---aux-----<br />------------------------------->rank---VB---conj_and-----0.00461365669709<br />------------------------------->phrases---NNS---dobj-----0.034238650699<br />------------------------------------->candidate---NN---nn-----0.0599775370622<br />------------------------------------->document---NN---prep_for-----0.10797156206<br />------------------------------------------->each---DT---det-----<br />------------------------------------------->single---JJ---amod-----0.0329913106296<br />------------------------------->cluster---NN---prep_in-----0.149960502862<br />------------------------------------->the---DT---det-----<br />------------------------------->on---IN---prepc_based_on-----<br />------------------------------->algorithm---NN---pobj-----0.0749802514309<br />------------------------------------->the---DT---det-----<br />------------------------------------->graph-based---JJ---amod-----0.0555045466929<br />------------------------------------->ranking---JJ---amod-----0.0171193253495<br />------------------------->rank---VB---infmod-----0.00461365669709<br />'
p80
sg16
S'Given a document set for keyphrase extraction of each single document, CollabRank first employs the clustering algorithm to group the documents into a few clusters. The documents within each cluster are expected to be topic-related and each cluster can be considered as a context for any document in the cluster. '
p81
sg18
F0.009728103513583247
saa(lp82
S'C08-1122-22'
p83
a(dp84
g5
F0.71593868
sg6
S'+1 1:0.0342683662386 2:0.189353760158 3:0.0987961412947'
p85
sg8
S'In this study, the cluster context is obtained by applying the clustering algorithm on the document set, and we have investigated how the cluster context influences the keyphrase extraction performance by employing different clustering algorithms.'
p86
sg10
S'The graph-based ranking algorithm is employed for collaborative keyphrase extraction for each document in a specified cluster. Instead of making only use of the word relationships in a single document, the algorithm can incorporate the \xe2\x80\x9cvoting\xe2\x80\x9d or \xe2\x80\x9crecommendations\xe2\x80\x9d between words in all the documents of the cluster, thus making use of the global information existing in the cluster context. '
p87
sg12
S'+1'
p88
sg14
S'->obtained---VBN---root-----         0.0342683662386<br />------->study---NN---prep_in-----<br />------------->this---DT---det-----<br />------->context---NN---nsubjpass-----0.155938390719         0.189353760158<br />------------->the---DT---det-----<br />------------->cluster---NN---nn-----0.222769129598<br />------->is---VBZ---auxpass-----<br />------->applying---VBG---agent-----<br />------------->algorithm---NN---dobj-----0.0668307388795         0.0987961412947<br />------------------->the---DT---det-----<br />------------------->clustering---VBG---amod-----0.0762932332442<br />------------------->set---NN---prep_on-----0.029291463457<br />------------------------->the---DT---det-----<br />------------------------->document---NN---nn-----0.222769129598<br />------->investigated---VBN---conj_and-----<br />------------->we---PRP---nsubj-----<br />------------->have---VBP---aux-----<br />------------->influences---VBZ---ccomp-----<br />------------------->how---WRB---advmod-----<br />------------------->context---NN---nsubj-----<br />------------------------->the---DT---det-----<br />------------------------->cluster---NN---nn-----<br />------------------->performance---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------------->keyphrase---JJ---amod-----<br />------------------------->extraction---NN---nn-----<br />------------------->employing---VBG---prepc_by-----<br />------------------------->algorithms---NNS---dobj-----<br />------------------------------->different---JJ---amod-----<br />------------------------------->clustering---VBG---amod-----<br />'
p89
sg16
S'Based on the above assumption, we propose a novel framework for collaborative singledocument keyphrase extraction by making use of the additional information from multiple documents within an appropriate cluster context. The collaborative framework for keyphrase extraction consists of the step of obtaining the cluster context and the step of collaborative keyphrase extraction in each cluster. '
p90
sg18
F0.009028856408952401
saa(lp91
S'C08-1122-104'
p92
a(dp93
g5
F-1.3661539
sg6
S'-1 1:0.00555804744083 2:0.0673959166072 3:0.0'
p94
sg8
S'All the candidate phrases in the document are ranked in decreasing order of the phrase scores and the top n phrases are selected as the keyphrases of the document.'
p95
sg10
S'n ranges from 1 to 20 in this study. Similarly for SingleRank, the phrase score is computed based on the document-level saliency scores of the words.  '
p96
sg12
S'-1'
p97
sg14
S'->ranked---VBN---root-----         0.00555804744083<br />------->phrases---NNS---nsubjpass-----0.034238650699         0.0673959166072<br />------------->All---PDT---predet-----<br />------------->the---DT---det-----<br />------------->candidate---NN---nn-----0.0599775370622<br />------------->document---NN---prep_in-----0.10797156206<br />------------------->the---DT---det-----<br />------->are---VBP---auxpass-----<br />------->order---NN---prep_in-----<br />------------->decreasing---VBG---amod-----<br />------------->scores---NNS---prep_of-----<br />------------------->the---DT---det-----<br />------------------->phrase---NN---nn-----<br />------->selected---VBN---conj_and-----<br />------------->phrases---NNS---nsubjpass-----<br />------------------->the---DT---det-----<br />------------------->top---JJ---amod-----<br />------------------->n---NN---nn-----<br />------------->are---VBP---auxpass-----<br />------------->keyphrases---NNS---prep_as-----<br />------------------->the---DT---det-----<br />------------------->document---NN---prep_of-----<br />------------------------->the---DT---det-----<br />'
p98
sg16
S'For instance, in the following sentence: \xe2\x80\x9cMad/JJ cow/NN disease/NN has/VBZ killed/VBN 10,000/CD cattle/NNS\xe2\x80\x9d, the candidate phrases are \xe2\x80\x9cMad cow disease\xe2\x80\x9d and \xe2\x80\x9ccattle\xe2\x80\x9d. The score of a candidate phrase pi is computed by summing the cluster-level saliency scores of the words contained in the phrase.  '
p99
sg18
F0.008704105907979511
saa(lp100
S'C08-1122-14'
p101
a(dp102
g5
F1.6483147
sg6
S'+1 1:0.111344900032 2:0.137181237832 3:0.128674083038'
p103
sg8
S'CollabRank is implemented by first employing the clustering algorithm to obtain appropriate document clusters, and then using the graph-based ranking algorithm for collaborative single-document keyphrase extraction within each cluster.'
p104
sg10
S'Experimental results demonstrate the encouraging performance of the proposed approach. Different clustering algorithms have been investigated and we find that the system performance relies positively on the quality of document clusters.  '
p105
sg12
S'+1'
p106
sg14
S'->implemented---VBN---root-----         0.111344900032<br />------->CollabRank---NNP---nsubjpass-----0.137181237832         0.137181237832<br />------->is---VBZ---auxpass-----<br />------->employing---VBG---agent-----<br />------------->first---RB---advmod-----<br />------------->algorithm---NN---dobj-----0.120166928243         0.128674083038<br />------------------->the---DT---det-----<br />------------------->clustering---VBG---amod-----0.137181237832<br />------------->obtain---VB---xcomp-----<br />------------------->to---TO---aux-----<br />------------------->clusters---NNS---dobj-----<br />------------------------->appropriate---JJ---amod-----<br />------------------------->document---NN---nn-----<br />------------->using---VBG---conj_and-----<br />------------------->then---RB---advmod-----<br />------------------->algorithm---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------------->graph-based---JJ---amod-----<br />------------------------->ranking---JJ---amod-----<br />------------------------->extraction---NN---prep_for-----<br />------------------------------->collaborative---JJ---amod-----<br />------------------------------->single-document---JJ---amod-----<br />------------------------------->keyphrase---NN---nn-----<br />------------------------------->cluster---NN---prep_within-----<br />------------------------------------->each---DT---det-----<br />------->using---VBG---agent-----<br />'
p107
sg16
S'Previous methods usually conduct the keyphrase extraction task for single documents separately without interactions for each document, under the assumption that the documents are considered independent of each other. This paper proposes a novel approach named CollabRank to collaborative single-document keyphrase extraction by making use of mutual influences of multiple documents within a cluster context. '
p108
sg18
F0.008359484796515207
saa(lp109
S'C08-1122-99'
p110
a(dp111
g5
F-1.4980525
sg6
S'+1 1:0.00922731339419 2:0.0471080938806 3:0.0'
p112
sg8
S'After the scores of all candidate words in the cluster have been computed, candidate phrases are selected and evaluated for each single document in the cluster.'
p113
sg10
S'The candidate words (i.e. nouns and adjectives) of a specified document d in the cluster, which is a subset of V, are marked in the document text, and sequences of adjacent candidate words are collapsed into a multi-word phrase. The phrases ending with an adjective are not allowed, and only the phrases ending with a noun are collected as the candidate phrases for the document. '
p114
sg12
S'+1'
p115
sg14
S'->selected---VBN---root-----         0.00922731339419<br />------->computed---VBN---advcl-----<br />------------->After---IN---mark-----<br />------------->scores---NNS---nsubjpass-----<br />------------------->the---DT---det-----<br />------------------->words---NNS---prep_of-----<br />------------------------->all---DT---det-----<br />------------------------->candidate---NN---nn-----<br />------------------------->cluster---NN---prep_in-----<br />------------------------------->the---DT---det-----<br />------------->have---VBP---aux-----<br />------------->been---VBN---auxpass-----<br />------->phrases---NNS---nsubjpass-----0.034238650699         0.0471080938806<br />------------->candidate---NN---nn-----0.0599775370622<br />------->are---VBP---auxpass-----<br />------->evaluated---VBN---conj_and-----<br />------------->phrases---NNS---nsubjpass-----<br />------->document---NN---prep_for-----<br />------------->each---DT---det-----<br />------------->single---JJ---amod-----<br />------------->cluster---NN---prep_in-----<br />------------------->the---DT---det-----<br />'
p116
sg16
S'Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any words falls below a given threshold (0.0001 in this study). For SingleRank, the saliency score WordScoredoc(vi) for word vi is computed in the same iterative way based on the local graph for the single document.  '
p117
sg18
F0.008199081027126435
saa(lp118
S'C08-1122-21'
p119
a(dp120
g5
F0.65109861
sg6
S'+1 1:0.0412829167358 2:0.121124043955 3:0.154030903567'
p121
sg8
S'The collaborative framework for keyphrase extraction consists of the step of obtaining the cluster context and the step of collaborative keyphrase extraction in each cluster.'
p122
sg10
S'In this study, the cluster context is obtained by applying the clustering algorithm on the document set, and we have investigated how the cluster context influences the keyphrase extraction performance by employing different clustering algorithms. The graph-based ranking algorithm is employed for collaborative keyphrase extraction for each document in a specified cluster. '
p123
sg12
S'+1'
p124
sg14
S'->consists---VBZ---root-----         0.0412829167358<br />------->framework---NN---nsubj-----0.0762932332442         0.121124043955<br />------------->The---DT---det-----<br />------------->collaborative---JJ---amod-----0.133661477759<br />------------->extraction---NN---prep_for-----0.137270732409<br />------------------->keyphrase---JJ---amod-----0.137270732409<br />------->step---NN---prep_of-----<br />------------->the---DT---det-----<br />------------->obtaining---VBG---prepc_of-----<br />------------------->context---NN---dobj-----0.155938390719         0.154030903567<br />------------------------->the---DT---det-----<br />------------------------->cluster---NN---nn-----0.222769129598<br />------------------------->step---NN---conj_and-----0.0685367324771<br />------------------------------->the---DT---det-----<br />------------------------------->extraction---NN---prep_of-----0.137270732409<br />------------------------------------->collaborative---JJ---amod-----0.133661477759<br />------------------------------------->keyphrase---NN---nn-----0.137270732409<br />------------------------------------->cluster---NN---prep_in-----0.222769129598<br />------------------------------------------->each---DT---det-----<br />------------------->step---NN---dobj-----<br />'
p125
sg16
S'Moreover, document keyphrases have been successfully used in the following IR and NLP tasks: document indexing (Gutwin et al., 1999), document classification (Krulwich and Burkey, 1996), document cluster Based on the above assumption, we propose a novel framework for collaborative singledocument keyphrase extraction by making use of the additional information from multiple documents within an appropriate cluster context. '
p126
sg18
F0.008136826371162508
saa(lp127
S'C08-1122-174'
p128
a(dp129
g5
F-0.45929927
sg6
S'+1 1:0.0662661830215 2:0.0 3:0.0822777656104'
p130
sg8
S'In this paper, we propose a novel approach named CollabRank for collaborative singledocument keyphrase extraction, which makes use of the mutual influences between documents in appropriate cluster context to better evaluate the saliency of words and phrases.'
p131
sg10
S'Experimental re sults demonstrate the good effectiveness of CollabRank. '
p132
sg12
S'+1'
p133
sg14
S'->propose---VBP---root-----         0.0662661830215<br />------->paper---NN---prep_in-----<br />------------->this---DT---det-----<br />------->we---PRP---nsubj-----         0.0<br />------->named---VBD---ccomp-----<br />------------->approach---NN---nsubj-----<br />------------------->a---DT---det-----<br />------------------->novel---NN---nn-----<br />------------->CollabRank---NNP---dobj-----0.115065637124         0.0822777656104<br />------------------->extraction---NN---prep_for-----0.133092030486<br />------------------------->collaborative---JJ---amod-----0.151191420686<br />------------------------->singledocument---NN---nn-----0.0775254480658<br />------------------------->keyphrase---NN---nn-----0.0887280203241<br />------------------------->makes---VBZ---rcmod-----0.0775254480658<br />------------------------------->extraction---NN---nsubj-----0.133092030486<br />------------------------------->evaluate---VB---xcomp-----0.0662661830215<br />------------------------------------->use---NN---nsubj-----0.0503971402287<br />------------------------------------------->influences---NNS---prep_of-----0.0503971402287<br />------------------------------------------------->the---DT---det-----<br />------------------------------------------------->mutual---JJ---amod-----0.0503971402287<br />------------------------------------------------->documents---NNS---prep_between-----0.0443640101621<br />------------------------------------------------------->context---NN---prep_in-----0.100794280457<br />------------------------------------------------------------->appropriate---JJ---amod-----0.100794280457<br />------------------------------------------------------------->cluster---NN---nn-----0.100794280457<br />------------------------------------->to---TO---aux-----<br />------------------------------------->better---RBR---advmod-----0.0662661830215<br />------------------------------------->saliency---NN---dobj-----0.0662661830215<br />------------------------------------------->the---DT---det-----<br />------------------------------------------->words---NNS---prep_of-----0.0575328185619<br />------------------------------------------------->phrases---NNS---conj_and-----0.0575328185619<br />------------------------------------------->phrases---NNS---prep_of-----0.0575328185619<br />'
p134
sg16
S'However, the performance improvements of RankFusion over CollabRank are not significant. We can conclude that the cluster-level global information plays the key role for evaluating the true saliency of the words.  '
p135
sg18
F0.008056960797265629
saa(lp136
S'J93-1005-217'
p137
a(dp138
g5
F-0.89280393
sg6
S'-1 1:0.00638684619036 2:0.117754460134 3:0.0'
p139
sg8
S'In the remaining 16 cases, associations between the preposition and both the noun and the verb are recorded in the dictionary.'
p140
sg10
S'For these, we select noun attachment, since it is the more probable outcome in general. For the remaining cases, we assume that the dictionary makes no decision. '
p141
sg12
S'-1'
p142
sg14
S'->recorded---VBN---root-----         0.00638684619036<br />------->cases---NNS---prep_in-----<br />------------->the---DT---det-----<br />------------->remaining---VBG---amod-----<br />------------->16---CD---num-----<br />------->associations---NNS---nsubjpass-----0.0334936373949         0.117754460134<br />------------->preposition---NN---prep_between-----0.0827594679332<br />------------------->the---DT---det-----<br />------------------->noun---NN---conj_and-----0.153984431863<br />------------------------->both---PDT---predet-----<br />------------------------->the---DT---det-----<br />------------------------->verb---NN---conj_and-----0.141152395874<br />------------------------------->the---DT---det-----<br />------------------->verb---NN---conj_and-----0.141152395874<br />------------->noun---NN---prep_between-----0.153984431863<br />------->are---VBP---auxpass-----<br />------->dictionary---NN---prep_in-----<br />------------->the---DT---det-----<br />'
p143
sg16
S'In 241 of those cases, there is information only on noun or only on verb association. In these cases, we can use the dictionary to choose the attachment according to the association indicated. '
p144
sg18
F0.006196084538369021
saa(lp145
S'J93-1005-78'
p146
a(dp147
g5
F-1.9363905
sg6
S'+1 1:0.00958026928554 2:0.0 3:0.0'
p148
sg8
S'We assume that in each case of attachment ambiguity, there is a forced choice between two outcomes: the preposition attaches either to the verb or to the noun.'
p149
sg10
S"' For example, in Example 6, we want to choose between two possibilities: either into is attached to the verb send or it is attached to the noun soldier.  Moscow sent more than 100,000 soldiers into Afghanistan ... In particular, we want to choose between two structures:  "
p150
sg12
S'+1'
p151
sg14
S'->assume---VBP---root-----         0.00958026928554<br />------->We---PRP---nsubj-----         0.0<br />------->is---VBZ---ccomp-----<br />------------->that---IN---mark-----<br />------------->case---NN---prep_in-----<br />------------------->each---DT---det-----<br />------------------->ambiguity---NNS---prep_of-----<br />------------------------->attachment---NN---nn-----<br />------------->there---EX---expl-----<br />------------->choice---NN---nsubj-----<br />------------------->a---DT---det-----<br />------------------->forced---VBN---amod-----<br />------------------->outcomes---NNS---prep_between-----<br />------------------------->two---CD---num-----<br />------->attaches---VBZ---parataxis-----<br />------------->preposition---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->either---CC---preconj-----<br />------------->verb---NN---prep_to-----<br />------------------->the---DT---det-----<br />------------------->noun---NN---conj_or-----<br />------------------------->the---DT---det-----<br />------------->noun---NN---prep_to-----<br />'
p152
sg16
S'For instance, if p is a preposition, f (p) = Ew f (w, p).  Our object is to develop a procedure to guess whether a preposition is attached to the verb or its object when a verb and its object are followed by a preposition. '
p153
sg18
F0.006049074637039203
saa(lp154
S'J93-1005-127'
p155
a(dp156
g5
F1.3989705
sg6
S'+1 1:0.228837975129 2:0.0127736923807 3:0.0235253993124'
p157
sg8
S'This task is in essence the one that we will give the computer\xe2\x80\x94to judge the attachment without any more information than the preposition and the heads of the two possible attachment sites.'
p158
sg10
S'This initial step provides a rough indication of what we might expect to be achievable based on the information our procedure is using. We also wanted a standard of correctness for the test sentences. '
p159
sg12
S'+1'
p160
sg14
S'->is---VBZ---root-----         0.228837975129<br />------->task---NN---nsubj-----0.0127736923807         0.0127736923807<br />------------->This---DT---det-----<br />------->essence---VBG---prepc_in-----<br />------------->one---NN---dobj-----0.0235253993124         0.0235253993124<br />------------------->the---DT---det-----<br />------------->give---VB---ccomp-----<br />------------------->that---IN---mark-----<br />------------------->we---PRP---nsubj-----<br />------------------->will---MD---aux-----<br />------------------->computer---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------->judge---VB---parataxis-----<br />------------------->to---TO---aux-----<br />------------------->attachment---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------->information---NN---prep_without-----<br />------------------------->any---DT---det-----<br />------------------------->more---JJR---amod-----<br />------------------------->preposition---NN---prep_than-----<br />------------------------------->the---DT---det-----<br />------------------------->heads---NNS---conj_and-----<br />------------------------------->the---DT---det-----<br />------------------------------->sites---NNS---prep_of-----<br />------------------------------------->the---DT---det-----<br />------------------------------------->two---CD---num-----<br />------------------------------------->possible---JJ---amod-----<br />------------------------------------->attachment---NN---nn-----<br />------------------->heads---NNS---prep_without-----<br />------------->judge---VB---xcomp-----<br />'
p161
sg16
S'The two authors first guessed attachments on the verb\xe2\x80\x93noun\xe2\x80\x93preposition triples, making a judgment on the basis of the three headwords alone. The judges were required to make a choice in each instance. '
p162
sg18
F0.006019084325399158
saa(lp163
S'J93-1005-162'
p164
a(dp165
g5
F-1.6207693
sg6
S'-1 1:0.0192480539828 2:0.0175784129255 3:0.0'
p166
sg8
S'Examples of this kind were given above, in the context of our description of the construction of the verb\xe2\x80\x94noun\xe2\x80\x94 preposition table.'
p167
sg10
S"Some further misidentifications that showed up in the test sample are: identifying the subject of the complement clause of say as its object, as in Example 10, which was identified as (say ministers from), and misparsing two constituents as a single-object noun phrase, as in Example 11, which was identified as (make subject to).  After agreeing on the 'correct' attachment for the test sample, we were left with 880 disambiguated verb\xe2\x80\x94noun\xe2\x80\x94preposition triples, having discarded the examples that were not instances of the relevant construction. "
p168
sg12
S'-1'
p169
sg14
S'->given---VBN---root-----         0.0192480539828<br />------->Examples---NNS---nsubjpass-----0.0287408078566         0.0175784129255<br />------------->kind---NN---prep_of-----0.00641601799428<br />------------------->this---DT---det-----<br />------->were---VBD---auxpass-----<br />------->above---RB---advmod-----<br />------->context---NN---prep_in-----<br />------------->the---DT---det-----<br />------------->description---NN---prep_of-----<br />------------------->our---PRP$---poss-----<br />------------------->construction---NN---prep_of-----<br />------------------------->the---DT---det-----<br />------------------------->table---NN---prep_of-----<br />------------------------------->the---DT---det-----<br />------------------------------->verb---JJ---amod-----<br />------------------------------->noun---NN---dep-----<br />------------------------------->preposition---JJ---amod-----<br />'
p170
sg16
S'For our present purpose, we decided to make an attachment choice in all cases, in some cases relying on controversial theoretical considerations, or relatively unanalyzed intuitions. In addition to the problematic cases, 120 of the 1000 triples identified automatically as instances of the verb\xe2\x80\x94object\xe2\x80\x94preposition configuration turned out in fact to be other constructions, often as the result of parsing errors. '
p171
sg18
F0.005918757623517674
saa(lp172
S'J93-1005-41'
p173
a(dp174
g5
F-0.98637085
sg6
S'-1 1:0.0283407701034 2:0.0702261683765 3:0.0'
p175
sg8
S'Each noun phrase in Example 3 is associated with an entry in the Noun column of the table.'
p176
sg10
S'Usually this is simply the root of the head of the noun phrase: good is the root of the head of consumer goods. Noun phrases with no head, or where the head is not a common noun, are coded in a special way: DART-PNP represents a noun phrase beginning with a definite article and headed by a proper noun, and VING represents a gerundive noun phrase. '
p177
sg12
S'-1'
p178
sg14
S'->associated---VBN---root-----         0.0283407701034<br />------->phrase---NN---nsubjpass-----0.0470507986247         0.0702261683765<br />------------->Each---DT---det-----<br />------------->noun---NN---nn-----0.153984431863<br />------------->Example---NNP---prep_in-----0.0798694430187<br />------------------->3---CD---num-----0.0<br />------->is---VBZ---auxpass-----<br />------->entry---NN---prep_with-----<br />------------->an---DT---det-----<br />------------->column---NN---prep_in-----<br />------------------->the---DT---det-----<br />------------------->Noun---JJ---amod-----<br />------------------->table---NN---prep_of-----<br />------------------------->the---DT---det-----<br />'
p179
sg16
S'For each noun phrase head, we recorded the following preposition if any occurred (ignoring whether or not the parser had attached the preposition to the noun phrase), and the preceding verb if the noun phrase was the object of that verb. The entries in Table 1 are those generated from the text above. '
p180
sg18
F0.0058112958563700905
saa(lp181
S'J93-1005-246'
p182
a(dp183
g5
F-0.21241057
sg6
S'+1 1:0.049962872986 2:0.0384439110558 3:0.103684244773'
p184
sg8
S'The performance of the human judges with access just to the verb-noun-preposition triple is a standard of what is possible based on this information, and the lexical association procedure falls somewhat short of this standard.'
p185
sg10
S'The analysis of underlying relations indicated some particular areas in which the procedure did not do well, and where there is therefore room for improvement. In particular, performance on adjuncts was poor. '
p186
sg12
S'+1'
p187
sg14
S'->standard---NN---root-----         0.049962872986<br />------->performance---NN---nsubj-----0.049962872986         0.0384439110558<br />------------->The---DT---det-----<br />------------->judges---NNS---prep_of-----0.024981436493<br />------------------->the---DT---det-----<br />------------------->human---JJ---amod-----0.049962872986<br />------------------->access---NN---prep_with-----0.0309638466252<br />------------------------->just---RB---advmod-----<br />------------------------->triple---NN---prep_to-----0.024981436493<br />------------------------------->the---DT---det-----<br />------------------------------->verb-noun-preposition---JJ---amod-----0.0498110007517<br />------->is---VBZ---cop-----<br />------->a---DT---det-----<br />------->possible---JJ---prepc_of-----<br />------------->what---WP---nsubj-----<br />------------->is---VBZ---cop-----<br />------------->on---IN---prepc_based_on-----<br />------------->information---NN---pobj-----0.103684244773         0.103684244773<br />------------------->this---DT---det-----<br />------->falls---VBZ---conj_and-----<br />------------->procedure---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->lexical---JJ---amod-----<br />------------------->association---NN---nn-----<br />------------->short---JJ---acomp-----<br />------------------->somewhat---RB---advmod-----<br />------------------->standard---NN---prep_of-----<br />------------------------->this---DT---det-----<br />'
p188
sg16
S'corpora) it is advantageous to be able to achieve increased precision in exchange for discarding a proportion of the data. From another perspective, our results are less good than what might be demanded. '
p189
sg18
F0.005725994766116921
saa(lp190
S'J93-1005-97'
p191
a(dp192
g5
F-0.86625199
sg6
S'-1 1:0.0191605385711 2:0.0987110781865 3:0.0'
p193
sg8
S'For example, if the LA score is 2.0, then the probability of verb attachment is four times greater than noun attachment.'
p194
sg10
S"Depending on the task, we can require a certain threshold of LA score magnitude before making a decision. ' As usual, in dealing with counts from corpora we must confront the problem of how to estimate probabilities when counts are small. "
p195
sg12
S'-1'
p196
sg14
S'->greater---JJR---root-----         0.0191605385711<br />------->example---NN---prep_for-----<br />------->2.0---JJ---advcl-----<br />------------->if---IN---mark-----<br />------------->score---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->LA---NNP---nn-----<br />------------->is---VBZ---cop-----<br />------->probability---NN---nsubj-----0.0159671154759         0.0987110781865<br />------------->then---RB---advmod-----<br />------------->the---DT---det-----<br />------------->attachment---NN---prep_of-----0.139013723209<br />------------------->verb---JJ---amod-----0.141152395874<br />------->is---VBZ---cop-----<br />------->times---NNS---npadvmod-----<br />------------->four---CD---num-----<br />------->attachment---NN---prep_than-----<br />------------->noun---NN---nn-----<br />'
p197
sg16
S'The sign indicates which possibility, verb attachment or noun attachment, is more likely; an LA score of zero means they are equally likely. The magnitude of the score indicates how much more probable one outcome is than the other. '
p198
sg18
F0.005688456123453255
saa(lp199
S'P99-1026-138'
p200
a(dp201
g5
F-1.5040434
sg6
S'-1 1:0.00674761988471 2:0.0351642646834 3:0.0207419160899'
p202
sg8
S'The response generation module is invoked when the user pauses, and plans responses based on the belief state of the context with the highest priority.'
p203
sg10
S'The response strategy is similar to that of previous frame-based dialogue systems (Bobrow et al., 1977). The speech production module outputs speech according to orders from the response generation module. '
p204
sg12
S'-1'
p205
sg14
S'->invoked---VBN---root-----         0.00674761988471<br />------->module---NN---nsubjpass-----0.055331448315         0.0351642646834<br />------------->The---DT---det-----<br />------------->response---NN---nn-----0.0280287664091<br />------------->generation---NN---nn-----0.022132579326<br />------->is---VBZ---auxpass-----<br />------->pauses---VBZ---advcl-----<br />------------->when---WRB---advmod-----<br />------------->user---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->plans---VBZ---conj_and-----<br />------------------->user---NN---nsubj-----<br />------------------->responses---NNS---dobj-----0.0207419160899         0.0207419160899<br />------------------->on---IN---prepc_based_on-----<br />------------------->state---NN---pobj-----<br />------------------------->the---DT---det-----<br />------------------------->belief---NN---nn-----<br />------------------------->context---NN---prep_of-----<br />------------------------------->the---DT---det-----<br />------------------------------->priority---NN---prep_with-----<br />------------------------------------->the---DT---det-----<br />------------------------------------->highest---JJS---amod-----<br />------->plans---VBZ---advcl-----<br />'
p206
sg16
S'A belief state is represented by a frame (Bobrow et al., 1977); thus, a speech act representation is a command for changing the slot value of a frame. Although a more sophisticated model would be required for the system to engage in a complicated dialogue, frame representations are sufficient for our tasks. '
p207
sg18
F0.00885570119088466
saa(lp208
S'P99-1026-93'
p209
a(dp210
g5
F-1.5182177
sg6
S'-1 1:0.00674761988471 2:0.0236166695965 3:0.0337380994235'
p211
sg8
S'For each context, if the top of the stack is an SU, empty the stack and update the belief state according to the content of the SU.'
p212
sg10
S'Increase the priority by the square of the length (i.e., the number of words) of this SU.  4. '
p213
sg12
S'-1'
p214
sg14
S'->empty---VB---root-----         0.00674761988471<br />------->context---NN---prep_for-----<br />------------->each---DT---det-----<br />------->SU---NNP---advcl-----<br />------------->if---IN---mark-----<br />------------->top---NN---nsubj-----0.0134952397694         0.0236166695965<br />------------------->the---DT---det-----<br />------------------->stack---NN---prep_of-----0.0337380994235<br />------------------------->the---DT---det-----<br />------------->is---VBZ---cop-----<br />------------->an---DT---det-----<br />------->stack---NN---dobj-----0.0337380994235         0.0337380994235<br />------------->the---DT---det-----<br />------->update---VB---conj_and-----<br />------------->state---NN---dobj-----<br />------------------->the---DT---det-----<br />------------------->belief---NN---nn-----<br />------------->to---TO---prepc_according_to-----<br />------------->content---NN---pobj-----<br />------------------->the---DT---det-----<br />------------------->SU---NNP---prep_of-----<br />------------------------->the---DT---det-----<br />'
p215
sg16
S'When a reduce operation is performed, increase the priority of the context by the priority assigned to the rule used for the reduce operation. 3. '
p216
sg18
F0.008477560904730237
saa(lp217
S'P99-1026-10'
p218
a(dp219
g5
F-1.0587578
sg6
S'-1 1:0.0256109616733 2:0.0 3:0.085201704037'
p220
sg8
S"We also use speech act in this paper to mean a command that updates the hearer's belief state about the speaker's intention and the context of the dialogue."
p221
sg10
S'In this paper, a system using this assumption is called an interval-based system. The above assumption no longer holds when no restrictions are placed on the way the user speaks. '
p222
sg12
S'-1'
p223
sg14
S'->use---VBP---root-----         0.0256109616733<br />------->We---PRP---nsubj-----         0.0<br />------->also---RB---advmod-----<br />------->act---NN---dobj-----0.0606701664185         0.085201704037<br />------------->speech---NN---nn-----0.109733241656<br />------->paper---NN---prep_in-----<br />------------->this---DT---det-----<br />------------->mean---VB---infmod-----<br />------------------->to---TO---aux-----<br />------------------->command---NN---dobj-----<br />------------------------->a---DT---det-----<br />------------------------->updates---VBD---rcmod-----<br />------------------------------->command---NN---nsubj-----<br />------------------------------->state---NN---dobj-----<br />------------------------------------->hearer---NN---poss-----<br />------------------------------------------->the---DT---det-----<br />------------------------------------->belief---NN---nn-----<br />------------------------------->intention---NN---prep_about-----<br />------------------------------------->speaker---NN---poss-----<br />------------------------------------------->the---DT---det-----<br />------------------------------------->context---NN---conj_and-----<br />------------------------------------------->the---DT---det-----<br />------------------------------------------->dialogue---NN---prep_of-----<br />------------------------------------------------->the---DT---det-----<br />------------------------------->context---NN---prep_about-----<br />'
p224
sg16
S'Most previous spoken dialogue systems (e.g. systems by Allen et al. (1996), Zue et al. (1994) and Peckham (1993)) assume that the user makes one utterance unit in each speech interval, unless the push-to-talk method is used. Here, by utterance unit we mean a phrase from which a speech act representation is derived, and it corresponds to a sentence in written language. '
p225
sg18
F0.008321510764255403
saa(lp226
S'P99-1026-31'
p227
a(dp228
g5
F-0.70709662
sg6
S'-1 1:0.036515771404 2:0.0 3:0.109547314212'
p229
sg8
S"It is expected that the system should infer the user wants to reserve the room on 'Wednesday this week' if this utterance was made on Monday."
p230
sg10
S"In real conversations, however, there is no guarantee that 'Wednesday' is the final word of the utterance. It might be followed by the phrase 'next week', in which case the system made a mistake in inferring the user's intention and must backtrack and re-understand. "
p231
sg12
S'-1'
p232
sg14
S'->expected---VBN---root-----         0.036515771404<br />------->It---PRP---nsubjpass-----         0.0<br />------->is---VBZ---auxpass-----<br />------->infer---VB---ccomp-----<br />------------->that---IN---mark-----<br />------------->system---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->should---MD---aux-----<br />------------->wants---VBZ---ccomp-----<br />------------------->user---NN---nsubj-----<br />------------------------->the---DT---det-----<br />------------------->reserve---VB---xcomp-----<br />------------------------->user---NN---xsubj-----<br />------------------------->to---TO---aux-----<br />------------------------->room---NN---dobj-----0.109547314212         0.109547314212<br />------------------------------->the---DT---det-----<br />------------------------->Wednesday---NNP---prep_on-----<br />------------------------------->week---NN---dep-----<br />------------------------------------->this---DT---det-----<br />------------------------------->made---VBN---dep-----<br />------------------------------------->if---IN---mark-----<br />------------------------------------->utterance---NN---nsubjpass-----<br />------------------------------------------->this---DT---det-----<br />------------------------------------->was---VBD---auxpass-----<br />------------------------------------->Monday---NNP---prep_on-----<br />'
p233
sg16
S"On the other hand, since parsing results cannot be obtained unless the end of the utterance is identified, making real-time responses is impossible without boundary information. For example, consider the utterance &quot;I'd like to book Meeting Room 1 on Wednesday&quot;. "
p234
sg18
F0.00818389993412036
saa(lp235
S'P99-1026-83'
p236
a(dp237
g5
F-0.74084847
sg6
S'-1 1:0.0337380994235 2:0.037179916458 3:0.066397737978'
p238
sg8
S'The second sequence is obviously the most likely at this point, but it is not possible to choose only one sequence and discard the others in the midst of a dialogue.'
p239
sg10
S'We therefore adopt beam search. Priorities are assigned to the possible sequences, and those with low priorities are neglected during the search.  '
p240
sg12
S'-1'
p241
sg14
S'->likely---JJ---root-----         0.0337380994235<br />------->sequence---NN---nsubj-----0.0608645931465         0.037179916458<br />------------->The---DT---det-----<br />------------->second---JJ---amod-----0.0134952397694<br />------->is---VBZ---cop-----<br />------->obviously---RB---advmod-----<br />------->the---DT---det-----<br />------->most---RBS---advmod-----<br />------->point---NN---prep_at-----<br />------------->this---DT---det-----<br />------->possible---JJ---conj_but-----<br />------------->it---PRP---nsubj-----<br />------------->is---VBZ---cop-----<br />------------->not---RB---neg-----<br />------------->choose---VB---xcomp-----<br />------------------->it---PRP---xsubj-----<br />------------------->to---TO---aux-----<br />------------------->sequence---NN---dobj-----0.0608645931465         0.066397737978<br />------------------------->only---RB---advmod-----<br />------------------------->one---CD---num-----0.0719308828095<br />------------------->discard---VB---conj_and-----<br />------------------------->others---NNS---dobj-----<br />------------------------------->the---DT---det-----<br />------------------------->midst---NN---prep_in-----<br />------------------------------->the---DT---det-----<br />------------------------------->dialogue---NN---prep_of-----<br />------------------------------------->a---DT---det-----<br />------------->discard---VB---xcomp-----<br />'
p242
sg16
S'Then three significantutterance sequences are possible: one consisting of &quot;Wednesday&quot;, one consisting of &quot;Wednesday next  week&quot;, and one consisting of no SUs. '
p243
sg18
F0.008019080992657732
saa(lp244
S'P99-1026-74'
p245
a(dp246
g5
F-0.58450059
sg6
S'-1 1:0.0055331448315 2:0.15415821525 3:0.0'
p247
sg8
S'From the speech act representation of these utterances, the system can infer the user wants to book Room 2 on Wednesday. '
p248
sg10
S'SUs are identified in the process of understanding. Unlike ordinary parsers, the understanding module does not try to determine whether the whole input forms an SU or not, but instead determines where SUs are. '
p249
sg12
S'-1'
p250
sg14
S'->infer---VB---root-----         0.0055331448315<br />------->representation---NN---prep_from-----<br />------------->the---DT---det-----<br />------------->speech---NN---nn-----<br />------------->act---NN---nn-----<br />------------->utterances---NNS---prep_of-----<br />------------------->these---DT---det-----<br />------->system---NN---nsubj-----0.15415821525         0.15415821525<br />------------->the---DT---det-----<br />------->can---MD---aux-----<br />------->wants---VBZ---ccomp-----<br />------------->user---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->Room---NNP---prep_to-----<br />------------------->book---NN---nn-----<br />------------------->2---CD---num-----<br />------------->Wednesday---NNP---prep_on-----<br />'
p251
sg16
S"I need to, uh, book Room 2, and it's on Wednesday. The most likely significant-utterance sequence consists of &quot;I need to, uh, book Room 2&quot; and &quot;it's on Wednesday&quot;. "
p252
sg18
F0.008002779784030224
saa(lp253
S'P99-1026-15'
p254
a(dp255
g5
F-0.78673486
sg6
S'+1 1:0.0303350832092 2:0.0885360373093 3:0.0'
p256
sg8
S'On the other hand, responding to a user utterance in real time requires understanding it and updating the belief state in real time; thus, it is impossible to wait for subsequent inputs to determine boundaries.'
p257
sg10
S'Abandoning full parsing and adopting keywordbased or fragment-based understanding could prevent this problem. This would, however, sacrifice the accuracy of understanding because phrases across the pauses could not be syntactically analyzed. '
p258
sg12
S'+1'
p259
sg14
S'->requires---VBZ---root-----         0.0303350832092<br />------->hand---NN---prep_on-----<br />------------->the---DT---det-----<br />------------->other---JJ---amod-----<br />------->responding---VBG---csubj-----0.0303350832092         0.0885360373093<br />------------->utterance---NN---prep_to-----0.128054808366<br />------------------->a---DT---det-----<br />------------------->user---NN---nn-----0.113716117988<br />------------------->time---NN---prep_in-----0.0947634316569<br />------------------------->real---JJ---amod-----0.0758107453255<br />------->understanding---VBG---ccomp-----<br />------------->it---PRP---dobj-----         0.0<br />------------->updating---VBG---conj_and-----<br />------------------->state---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------------->belief---NN---nn-----<br />------------------------->time---NN---prep_in-----<br />------------------------------->real---JJ---amod-----<br />------->updating---VBG---ccomp-----<br />------->impossible---JJ---parataxis-----<br />------------->thus---RB---advmod-----<br />------------->it---PRP---nsubj-----<br />------------->is---VBZ---cop-----<br />------------->wait---VB---xcomp-----<br />------------------->it---PRP---xsubj-----<br />------------------->to---TO---aux-----<br />------------------->inputs---NNS---prep_for-----<br />------------------------->subsequent---JJ---amod-----<br />------------------->determine---VB---xcomp-----<br />------------------------->to---TO---aux-----<br />------------------------->boundaries---NNS---dobj-----<br />'
p260
sg16
S'This is because utterance boundaries (i.e., semantic boundaries) do not always correspond to pauses and techniques based on other acoustic information are not perfect. Utterance boundaries thus cannot be identified prior to parsing, and so the timing of determining parsing results to update the belief state is unclear. '
p261
sg18
F0.007824248434107447
saa(lp262
S'C00-1073-4'
p263
a(dp264
g5
F0.20235569
sg6
S'+1 1:0.0683772228366 2:0.117388032394 3:0.0236280810749'
p265
sg8
S'The role of the dialogue manager in such systems is to interact in a natural way to help the user complete the tasks that the system is designed to support.'
p266
sg10
S'Typically, an expert designs a dialogue manager by hand, and has to make many nontrivial design choices that can seriously impact system performance. This paper applies reinforcement learning (RL) to automatically learn design choices that optimize system performance for a chosen performance measure (Levin et al., 2000; Walker et al., 1998). '
p267
sg12
S'+1'
p268
sg14
S'->is---VBZ---root-----         0.0683772228366<br />------->role---NN---nsubj-----0.0288142303435         0.117388032394<br />------------->The---DT---det-----<br />------------->manager---NN---prep_of-----0.0708842432248<br />------------------->the---DT---det-----<br />------------------->dialogue---NN---nn-----0.310008307176<br />------------------->systems---NNS---prep_in-----0.0598453488308<br />------------------------->such---JJ---amod-----<br />------->interact---VB---xcomp-----<br />------------->role---NN---xsubj-----<br />------------->to---TO---aux-----<br />------------->way---NN---prep_in-----<br />------------------->a---DT---det-----<br />------------------->natural---JJ---amod-----<br />------------->help---VB---xcomp-----<br />------------------->to---TO---aux-----<br />------------------->complete---VB---ccomp-----<br />------------------------->user---NN---nsubj-----<br />------------------------------->the---DT---det-----<br />------------------------->tasks---NNS---dobj-----0.0236280810749         0.0236280810749<br />------------------------------->the---DT---det-----<br />------------------------->designed---VBN---ccomp-----<br />------------------------------->that---IN---mark-----<br />------------------------------->system---NN---nsubjpass-----<br />------------------------------------->the---DT---det-----<br />------------------------------->is---VBZ---auxpass-----<br />------------------------------->support---VB---xcomp-----<br />------------------------------------->system---NN---xsubj-----<br />------------------------------------->to---TO---aux-----<br />'
p269
sg16
S'We then show that our approach measurably improves performance in an experimental system.  Recent advances in spoken language understanding have made it possible to develop dialogue systems for many applications. '
p270
sg18
F0.008094098496351508
saa(lp271
S'C00-1073-21'
p272
a(dp273
g5
F-1.1031282
sg6
S'+1 1:0.0199484496103 2:0.0383718536923 3:0.0441628362234'
p274
sg8
S'This paper presents an application of RL to the problem of optimizing dialogue strategy selection in the NJFun system, and experimentally demonstrates the utility of the approach.'
p275
sg10
S'Section 2 explains how we apply RL to dialogue systems, then Section 3 describes the NJFun system in detail. Section 4 describes how NJFun optimizes its dialogue strategy from experimentally obtained dialogue data. '
p276
sg12
S'+1'
p277
sg14
S'->presents---VBZ---root-----         0.0199484496103<br />------->paper---NN---nsubj-----0.0383718536923         0.0383718536923<br />------------->This---DT---det-----<br />------->application---NN---dobj-----0.0199484496103         0.0441628362234<br />------------->an---DT---det-----<br />------------->RL---NNP---prep_of-----0.0683772228366<br />------->problem---NN---prep_to-----<br />------------->the---DT---det-----<br />------------->selection---NN---prep_of-----<br />------------------->optimizing---JJ---amod-----<br />------------------->dialogue---NN---nn-----<br />------------------->strategy---NN---nn-----<br />------------------->system---NN---prep_in-----<br />------------------------->the---DT---det-----<br />------------------------->NJFun---NNP---nn-----<br />------->demonstrates---VBZ---conj_and-----<br />------------->paper---NN---nsubj-----<br />------------->experimentally---RB---advmod-----<br />------------->utility---NN---dobj-----<br />------------------->the---DT---det-----<br />------------------->approach---NN---prep_of-----<br />------------------------->the---DT---det-----<br />'
p278
sg16
S'More specifically, the MDP formalism suggests a method for optimizing dialogue strategies from sample dialogue data. The main advantage of this approach is the potential for computing an optimal dialogue strategy within a much larger search space, using a relatively small number of training dialogues. '
p279
sg18
F0.007768818934628618
saa(lp280
S'C00-1073-163'
p281
a(dp282
g5
F-1.6157864
sg6
S'-1 1:0.0 2:0.0430736627394 3:0.00933154567274'
p283
sg8
S'Thus, if the task is to go winetasting near Lambertville in the morning, and the system queries the database for an activity in New Jersey in the morning, StrongComp=0, WeakComp=1, and ASR=2.'
p284
sg10
S'In addition to the objective measures discussed above, we also computed two subjective usability measures. Feedback is obtained from the dialogue (e.g. S4 in Figure 5), by mapping good, so-so, bad to 1, 0, and -1, respectively. '
p285
sg12
S'-1'
p286
sg14
S'->=---VBZ---root-----         0.0<br />------->Thus---RB---advmod-----<br />------->is---VBZ---advcl-----<br />------------->if---IN---mark-----<br />------------->task---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->go---VB---xcomp-----<br />------------------->task---NN---xsubj-----<br />------------------->to---TO---aux-----<br />------------------->winetasting---VBG---xcomp-----<br />------------------------->Lambertville---NNP---prep_near-----<br />------------------------------->morning---NN---prep_in-----<br />------------------------------------->the---DT---det-----<br />------------->queries---VBZ---conj_and-----<br />------------------->system---NN---nsubj-----<br />------------------------->the---DT---det-----<br />------------------->database---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------------->activity---NN---prep_for-----<br />------------------------------->an---DT---det-----<br />------------------------------->Jersey---NNP---prep_in-----<br />------------------------------------->New---NNP---nn-----<br />------------------------------------->morning---NN---prep_in-----<br />------------------------------------------->the---DT---det-----<br />------->queries---VBZ---advcl-----<br />------->StrongComp---NNP---nsubj-----0.0430736627394         0.0430736627394<br />------->0---CD---dobj-----0.0         0.00933154567274<br />------------->WeakComp---NNP---conj_and-----0.018460141174<br />------------------->1---CD---rcmod-----0.0<br />------------------------->=---SYM---dep-----0.0<br />------------->ASR---NNP---conj_and-----0.0468606785352<br />------------------->2---CD---rcmod-----0.0<br />------------------------->=---SYM---dep-----0.0<br />------->WeakComp---NNP---dobj-----<br />------->ASR---NNP---dobj-----<br />'
p287
sg16
S'Otherwise, at least one attribute is wrong (e.g., the user says &quot;Lambertville&quot; but the system hears &quot;Morristown&quot;), and the value is -1. ASR is a dialogue quality measure that approximates speech recognition accuracy for the database query, and is computed by adding 1 for each correct attribute value and .5 for every wildcard. '
p288
sg18
F0.007216583667968402
saa(lp289
S'C00-1073-140'
p290
a(dp291
g5
F-1.548272
sg6
S'-1 1:0.00615338039134 2:0.0468606785352 3:0.0'
p292
sg8
S'Both the initiative and confirmation results suggest that the beginning of the dialogue was the most problematic for NJFun.'
p293
sg10
S'Figure 1 is an example dialogue using the optimal strategy.  For the testing phase, NJFun was reimplemented to use the learned strategy. '
p294
sg12
S'-1'
p295
sg14
S'->suggest---VBP---root-----         0.00615338039134<br />------->initiative---NN---nsubj-----0.0681609869603         0.0468606785352<br />------------->Both---DT---preconj-----<br />------------->the---DT---det-----<br />------------->results---NNS---conj_and-----0.0298204317951<br />------------------->confirmation---NN---nn-----0.0426006168502<br />------->results---NNS---nsubj-----<br />------->problematic---JJ---ccomp-----<br />------------->that---IN---mark-----<br />------------->beginning---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->dialogue---NN---prep_of-----<br />------------------------->the---DT---det-----<br />------------->was---VBD---cop-----<br />------------->the---DT---det-----<br />------------->most---RBS---advmod-----<br />------------->NJFun---NNP---prep_for-----<br />'
p296
sg16
S'This use of ASR confidence by the dialogue strategy is more sophisticated than previous approaches, e.g. (Niimi and Kobayashi, 1996; Litman and Pan, 2000). NJFun can learn such finegrained distinctions because the optimal strategy is based on a comparison of 242 possible exploratory strategies. '
p297
sg18
F0.007033556772114432
saa(lp298
S'C00-1073-173'
p299
a(dp300
g5
F-0.82729231
sg6
S'+1 1:0.0324245707369 2:0.0415802032625 3:0.0516273258672'
p301
sg8
S'This paper presents a practical methodology for applying RL to optimizing dialogue strategies in spoken dialogue systems, and shows empirically that the method improves performance over the EIC strategy in NJFun.'
p302
sg10
S"A companion paper (Singh et al., 2000) shows that the learned strategy is not only better than EIC, but also better than other fixed choices proposed in the literature. Our results demonstrate that the application of RL allows one to empirically optimize a system's dialogue strategy by searching through a much larger search space than can be explored with more traditional methods (i.e. empirically testing several versions of a system). "
p303
sg12
S'+1'
p304
sg14
S'->presents---VBZ---root-----         0.0324245707369<br />------->paper---NN---nsubj-----0.0415802032625         0.0415802032625<br />------------->This---DT---det-----<br />------->methodology---NN---dobj-----0.0648491414737         0.0516273258672<br />------------->a---DT---det-----<br />------------->practical---JJ---amod-----0.0384055102606<br />------->applying---VBG---prepc_for-----<br />------------->optimizing---VB---xcomp-----<br />------------------->RL---NNP---nsubj-----<br />------------------->to---TO---aux-----<br />------------------->strategies---NNS---dobj-----<br />------------------------->dialogue---NN---nn-----<br />------------------->systems---NNS---prep_in-----<br />------------------------->spoken---JJ---amod-----<br />------------------------->dialogue---NN---nn-----<br />------->shows---VBZ---conj_and-----<br />------------->paper---NN---nsubj-----<br />------------->improves---VBZ---dep-----<br />------------------->empirically---RB---advmod-----<br />------------------->that---IN---mark-----<br />------------------->method---NN---nsubj-----<br />------------------------->the---DT---det-----<br />------------------->performance---NN---dobj-----<br />------------------------->strategy---NN---prep_over-----<br />------------------------------->the---DT---det-----<br />------------------------------->EIC---NNP---nn-----<br />------------------->NJFun---NNP---prep_in-----<br />'
p305
sg16
S'Interestingly, the distributions of the subjective measures move to the middle from training to testing, i.e., test users reply to the survey using less extreme answers than training users. Explaining the subjective results is an area for future work.  '
p306
sg18
F0.006999952204600815
saa(lp307
S'C00-1073-134'
p308
a(dp309
g5
F-1.000588
sg6
S'+1 1:0.0123067607827 2:0.0956567636254 3:0.0'
p310
sg8
S'Intuitively, the learned strategy says that the optimal use of initiative is to begin with user initiative, then back off to either mixed or system initiative when reasking for an attribute.'
p311
sg10
S'Note, however, that the specific backoff method differs with attribute (e.g., system initiative for attribute 1, but generally mixed initiative for attribute 2). With respect to confirmation, the optimal strategy is to mainly confirm at lower confidence values. '
p312
sg12
S'+1'
p313
sg14
S'->says---VBZ---root-----         0.0123067607827<br />------->Intuitively---RB---advmod-----<br />------->strategy---NN---nsubj-----0.129254190836         0.0956567636254<br />------------->the---DT---det-----<br />------------->learned---JJ---amod-----0.0620593364148<br />------->is---VBZ---ccomp-----<br />------------->that---IN---mark-----<br />------------->use---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->optimal---JJ---amod-----<br />------------------->initiative---NN---prep_of-----<br />------------->begin---VB---xcomp-----<br />------------------->use---NN---xsubj-----<br />------------------->to---TO---aux-----<br />------------------->initiative---NN---prep_with-----<br />------------------------->user---NN---nn-----<br />------------------->off---RB---advmod-----<br />------------------------->then---RB---advmod-----<br />------------------------->back---RB---advmod-----<br />------------------------->initiative---NN---prep_to-----<br />------------------------------->either---DT---preconj-----<br />------------------------------->mixed---VBN---nn-----<br />------------------------------------->system---NN---conj_or-----<br />------------------------------->system---NN---nn-----<br />------->reasking---VBG---advcl-----<br />------------->when---WRB---advmod-----<br />------------->attribute---NN---prep_for-----<br />------------------->an---DT---det-----<br />'
p314
sg16
S'Note that no choice was fixed for several states, meaning that the Q-values were identical after value iteration. Thus, even when using the learned strategy, NJFun still sometimes chooses randomly between certain action pairs. '
p315
sg18
F0.006929186197151687
saa(lp316
S'C00-1073-46'
p317
a(dp318
g5
F-0.77185063
sg6
S'-1 1:0.0492266602957 2:0.0186116985196 3:0.052348301515'
p319
sg8
S'The next section details the use of this methodology to design the NJFun system. '
p320
sg10
S'NJFun is a real-time spoken dialogue system that provides users with information about things to do in New Jersey. NJFun is built using a general purpose platform for spoken dialogue systems (Levin et al., 1999), with support for modules for automatic speech recognition (ASR), spoken language  '
p321
sg12
S'-1'
p322
sg14
S'->details---VBZ---root-----         0.0492266602957<br />------->section---NN---nsubj-----0.0170401142194         0.0186116985196<br />------------->The---DT---det-----<br />------------->next---JJ---amod-----0.0201832828198<br />------->use---NN---dobj-----0.0170401142194         0.052348301515<br />------------->the---DT---det-----<br />------------->methodology---NN---prep_of-----0.0511203426581<br />------------------->this---DT---det-----<br />------------------->design---VB---infmod-----0.0170401142194<br />------------------------->to---TO---aux-----<br />------------------------->system---NN---dobj-----0.163930869587<br />------------------------------->the---DT---det-----<br />------------------------------->NJFun---NNP---nn-----0.0126100668913<br />'
p323
sg16
S'The contribution of this paper is to empirically validate a practical methodology for using RL to build a dialogue system that optimizes its behavior from dialogue data. Our methodology involves 1) representing a dialogue strategy as a mapping from each state in the chosen state space S to a set of dialogue actions, 2) deploying an initial training system that generates exploratory training data with respect to S, 3) constructing an MDP model from the obtained training data, 4) using value iteration to learn the optimal dialogue strategy in the learned MDP, and 4) redeploying the system using the learned state/action mapping. '
p324
sg18
F0.006872509768870156
saa(lp325
S'W11-2821-30'
p326
a(dp327
g5
F-1.22127
sg6
S'-1 1:0.0117998847901 2:0.0538022222872 3:0.0254092540477'
p328
sg8
S'For properties, the descriptive statements specify the domain and range, and features such as functionality and transitivity, and examples are provided by statements about individuals or classes in which the property is used. '
p329
sg10
S'A third level of organisation occurs when statements with identical structures and one identical argument are aggregated; see Williams and Power (2010) for more details. For some ontologies, this process can lead to very long lists of subclasses or individuals, so under the \xe2\x80\x98Examples\xe2\x80\x99 subheading where these occur we truncate them to a predefined maximum length and add the phrase \xe2\x80\x98and so on (N items in total)\xe2\x80\x99. '
p330
sg12
S'-1'
p331
sg14
S'->specify---VB---root-----         0.0117998847901<br />------->properties---NNS---prep_for-----<br />------->statements---NNS---nsubj-----0.0840046749943         0.0538022222872<br />------------->the---DT---det-----<br />------------->descriptive---JJ---amod-----0.0235997695802<br />------->domain---NN---dobj-----0.0471995391604         0.0254092540477<br />------------->the---DT---det-----<br />------------->range---NN---conj_and-----0.0117998847901<br />------------->features---NNS---conj_and-----0.0580564459655<br />------------------->functionality---NN---prep_such_as-----0.0117998847901<br />------------------------->transitivity---NN---conj_and-----0.0117998847901<br />------------------->transitivity---NN---prep_such_as-----0.0117998847901<br />------->range---NN---dobj-----<br />------->features---NNS---dobj-----<br />------->provided---VBN---conj_and-----<br />------------->examples---NNS---nsubjpass-----<br />------------->are---VBP---auxpass-----<br />------------->statements---NNS---agent-----<br />------------------->individuals---NNS---prep_about-----<br />------------------------->classes---NNS---conj_or-----<br />------------------->classes---NNS---prep_about-----<br />------------------->used---VBN---rcmod-----<br />------------------------->statements---NNS---prep_in-----<br />------------------------->property---NN---nsubjpass-----<br />------------------------------->the---DT---det-----<br />------------------------->is---VBZ---auxpass-----<br />'
p332
sg16
S'argument occur under the definition subheading, the taxonomy is the superclass (from an OWL SubClassOf statement), descriptive statements correspond to the OWL functor SubClassOf, distinctions to DisjointClasses, and examples to the individuals belonging to the class. For individuals the class is given first (from an OWL ClassAssertion statement), followed by descriptions typically corresponding to ObjectPropertyAssertion. '
p333
sg18
F0.01683578692923072
saa(lp334
S'W11-2821-3'
p335
a(dp336
g5
F2.2395811
sg6
S'+1 1:0.240089353728 2:0.111883766045 3:0.0'
p337
sg8
S'One consequence of this organisation is that some statements are repeated because they are relevant to more than one entry; this means that the text is longer than one in which statements are simply listed.'
p338
sg10
S'This trade-off between organisation and brevity is investigated in a user study.  Since OWL (Web Ontology Language) became the standard language for the semantic web in 2004,1 several research groups have developed systems, known as \xe2\x80\x98verbalisers\xe2\x80\x99, for generating Controlled English from OWL ontologies (Kaljurand and Fuchs, 2007; Dolbear et al., 2007; Schwitter and Tilbrook, 2004; Funk et al., 2007). '
p339
sg12
S'+1'
p340
sg14
S'->is---VBZ---root-----         0.240089353728<br />------->consequence---NN---nsubj-----0.0901440675347         0.111883766045<br />------------->One---CD---num-----0.138549645412<br />------------->organisation---NN---prep_of-----0.106957585189<br />------------------->this---DT---det-----<br />------->repeated---VBN---ccomp-----<br />------------->that---IN---mark-----<br />------------->statements---NNS---nsubjpass-----<br />------------------->some---DT---det-----<br />------------->are---VBP---auxpass-----<br />------------->relevant---JJ---advcl-----<br />------------------->because---IN---mark-----<br />------------------->they---PRP---nsubj-----<br />------------------->are---VBP---cop-----<br />------------------->entry---NN---prep_to-----<br />------------------------->one---CD---num-----<br />------------------------------->than---IN---quantmod-----<br />------------------------------------->more---JJR---mwe-----<br />------->means---VBZ---parataxis-----<br />------------->this---DT---nsubj-----<br />------------->one---CD---ccomp-----<br />------------------->that---IN---mark-----<br />------------------->text---NN---nsubj-----<br />------------------------->the---DT---det-----<br />------------------->is---VBZ---cop-----<br />------------------->than---IN---advmod-----<br />------------------------->longer---RBR---advmod-----<br />------------------->listed---VBN---rcmod-----<br />------------------------->one---CD---prep_in-----<br />------------------------->statements---NNS---nsubjpass-----<br />------------------------->are---VBP---auxpass-----<br />------------------------->simply---RB---advmod-----<br />'
p341
sg16
S'The document structure, inspired by encyclopedias and glossaries, is organised at a number of levels. At the top level, a heading is generated for every concept in the ontology; at the next level, each entry is subdivided into logically-based headings like \xe2\x80\x98Definition\xe2\x80\x99 and \xe2\x80\x98Examples\xe2\x80\x99; at the next, sentences are aggregated when they have parts in common; at the lowest level, phrases are hyperlinked to concept headings. '
p342
sg18
F0.016352339666404255
saa(lp343
S'W11-2821-42'
p344
a(dp345
g5
F-1.1878107
sg6
S'-1 1:0.0117998847901 2:0.0 3:0.0967607432758'
p346
sg8
S'This is addressed through a navigation task in which people were asked to locate information in either an organised text or an unorganised one and then give a judgement on how difficult the information was to find.'
p347
sg10
S'The study design is between-subjects in two independent groups. Participants were 57 members of the ACL special interest groups SIGGEN8 and SIGdial9.  '
p348
sg12
S'-1'
p349
sg14
S'->addressed---VBN---root-----         0.0117998847901<br />------->This---DT---nsubjpass-----         0.0<br />------->is---VBZ---auxpass-----<br />------->task---NN---prep_through-----<br />------------->a---DT---det-----<br />------------->navigation---NN---nn-----<br />------------->asked---VBN---rcmod-----<br />------------------->task---NN---prep_in-----<br />------------------->people---NNS---nsubjpass-----<br />------------------->were---VBD---auxpass-----<br />------------------->locate---VB---xcomp-----<br />------------------------->people---NNS---xsubj-----<br />------------------------->to---TO---aux-----<br />------------------------->information---NN---dobj-----0.0967607432758         0.0967607432758<br />------------------------->text---NN---prep_in-----<br />------------------------------->either---CC---preconj-----<br />------------------------------->an---DT---det-----<br />------------------------------->organised---JJ---amod-----<br />------------------------------->one---NN---conj_or-----<br />------------------------------------->an---DT---det-----<br />------------------------------------->unorganised---JJ---amod-----<br />------------------------->one---NN---prep_in-----<br />------------------------->give---VB---conj_and-----<br />------------------------------->then---RB---advmod-----<br />------------------------------->judgement---NN---dobj-----<br />------------------------------------->a---DT---det-----<br />------------------------------------->was---VBD---prepc_on-----<br />------------------------------------------->difficult---JJ---dep-----<br />------------------------------------------------->how---WRB---advmod-----<br />------------------------------------------->information---NN---nsubj-----<br />------------------------------------------------->the---DT---det-----<br />------------------------------------------->find---VB---xcomp-----<br />------------------------------------------------->information---NN---xsubj-----<br />------------------------------------------------->to---TO---aux-----<br />------------------->give---VB---xcomp-----<br />'
p350
sg16
S'Only one attempts further discourse structuring: Laing et al.\xe2\x80\x99s system for verbalising medical ontologies organises text according to rhetorical structure.  The evaluation study reported here focusses on the following question: Does the organisation just described help people to understand and navigate a text in spite of its longer length? '
p351
sg18
F0.01622633401826323
saa(lp352
S'W11-2821-35'
p353
a(dp354
g5
F-1.1922014
sg6
S'+1 1:0.0353996543703 2:0.0366728038203 3:0.0'
p355
sg8
S'The final and lowest level of organisation occurs when hyperlinks are introduced for each phrase corresponding to a class, individual or property; these link to the headings of their entries. '
p356
sg10
S'To our knowledge, SWAT TOOLS takes document structuring further than other domain-independent ontology verbalisers. We are aware of only one other domain-independent system that attempts document structuring, ACE (Kaljurand and Fuchs, 2007). '
p357
sg12
S'+1'
p358
sg14
S'->occurs---VBZ---root-----         0.0353996543703<br />------->level---NN---nsubj-----0.0774085946206         0.0366728038203<br />------------->The---DT---det-----<br />------------->final---JJ---amod-----0.0235997695802<br />------------------->lowest---JJ---conj_and-----0.00967607432758<br />------------->lowest---JJ---amod-----0.00967607432758<br />------------->organisation---NN---prep_of-----0.0630035062457<br />------->introduced---VBN---advcl-----<br />------------->when---WRB---advmod-----<br />------------->hyperlinks---NNS---nsubjpass-----<br />------------->are---VBP---auxpass-----<br />------------->phrase---NN---prep_for-----<br />------------------->each---DT---det-----<br />------------------->corresponding---JJ---amod-----<br />------------->class---NN---prep_to-----<br />------------------->a---DT---det-----<br />------------------->individual---NN---conj_or-----<br />------------------->property---NN---conj_or-----<br />------------------->link---NN---dep-----<br />------------------------->these---DT---det-----<br />------------------------->headings---NNS---prep_to-----<br />------------------------------->the---DT---det-----<br />------------------------------->entries---NNS---prep_of-----<br />------------------------------------->their---PRP$---poss-----<br />------------->individual---NN---prep_to-----<br />------------->property---NN---prep_to-----<br />'
p359
sg16
S'Figure 1 shows an example of aggregation and truncation in the sentence \xe2\x80\x98The following are seta appendage cephalothorax: male palpal femoral thorns, female palp femoral thorns and spd 0000203s, and so on (5 items in total)\xe2\x80\x99. An obvious refinement would be to add a facility to view the entire list, if desired.  '
p360
sg18
F0.015663707955868893
saa(lp361
S'W11-2821-18'
p362
a(dp363
g5
F-1.0453448
sg6
S'-1 1:0.0490152409423 2:0.0303125129906 3:0.0'
p364
sg8
S'The highest levels of organisation, illustrated in figure 1, are headings and subheadings.'
p365
sg10
S'Subheadings are inspired mainly by Berzlanovich et al.\xe2\x80\x99s (2008) \xe2\x80\x98information oriented\xe2\x80\x99 discourse labels (name, definition, description, etc. ) from their analysis of the discourse structure of encyclopedia articles; and also by Aristotle\xe2\x80\x99s genus-differentia descriptions.6 Lower levels of organisation were also influenced by Berzlanovich et al. (2008), whose investigation of lower-level lexical cohesion in encylopedia entries highlighted the high incidence of hypernymic lexical cohesion.  '
p366
sg12
S'-1'
p367
sg14
S'->headings---NNS---root-----         0.0490152409423<br />------->levels---NNS---nsubj-----0.0290282229827         0.0303125129906<br />------------->The---DT---det-----<br />------------->highest---JJS---amod-----0.0117998847901<br />------------->organisation---NN---prep_of-----0.0630035062457<br />------------->illustrated---VBN---partmod-----0.0290282229827<br />------------------->figure---NN---prep_in-----0.0490152409423<br />------------------------->1---CD---num-----0.0<br />------->are---VBP---cop-----<br />------->subheadings---NNS---conj_and-----<br />'
p368
sg16
S'Briefly, the OWL/XML input is transcoded to Prolog,5 using the format illustrated in the example just given; then a lexicon for realising atomic terms (individuals, classes or properties) is inferred from their identifier names or labels; finally, a sentence is generated from each statement using a Definite Clause Grammar (Clocksin and Mellish, 1987) covering almost all of OWL-DL, using wording influenced by earlier work on controlled languages (Schwitter et al., 2008; Kaljurand and Fuchs, 2007; Dolbear et al., 2007). Sentences are ordered according to the alphabetical order of their underlying OWL statements: i.e., sentences generated from ClassAssertion statements will come before those generated from SubClassOf statements.  '
p369
sg18
F0.014321144530819847
saa(lp370
S'W11-2821-41'
p371
a(dp372
g5
F-1.4455986
sg6
S'+1 1:0.00816920682372 2:0.0199007215608 3:0.0454595320118'
p373
sg8
S'The evaluation study reported here focusses on the following question: Does the organisation just described help people to understand and navigate a text in spite of its longer length?'
p374
sg10
S'This is addressed through a navigation task in which people were asked to locate information in either an organised text or an unorganised one and then give a judgement on how difficult the information was to find. The study design is between-subjects in two independent groups. '
p375
sg12
S'+1'
p376
sg14
S'->reported---VBD---root-----         0.00816920682372<br />------->study---NN---nsubj-----0.0280015583314         0.0199007215608<br />------------->The---DT---det-----<br />------------->evaluation---NN---nn-----0.0117998847901<br />------->here---RB---advmod-----<br />------->focusses---NNS---dobj-----0.0117998847901         0.0454595320118<br />------------->question---NN---prep_on-----0.117998847901<br />------------------->the---DT---det-----<br />------------------->following---JJ---amod-----0.0290282229827<br />------------------->help---VB---dep-----0.00967607432758<br />------------------------->Does---VBZ---aux-----<br />------------------------->organisation---NN---nsubj-----0.0630035062457<br />------------------------------->the---DT---det-----<br />------------------------------->described---VBN---partmod-----0.00967607432758<br />------------------------------------->just---RB---advmod-----<br />------------------------->understand---VB---xcomp-----0.0193521486552<br />------------------------------->people---NNS---nsubj-----0.0707993087406<br />------------------------------->to---TO---aux-----<br />------------------------------->navigate---VB---conj_and-----0.00967607432758<br />------------------------------------->people---NNS---nsubj-----0.0707993087406<br />------------------------------->text---NN---dobj-----0.175009739571<br />------------------------------------->a---DT---det-----<br />------------------------------------->length---NN---prep_in_spite_of-----0.0235997695802<br />------------------------------------------->its---PRP$---poss-----<br />------------------------------------------->longer---JJR---amod-----0.0163384136474<br />------------------------->navigate---VB---xcomp-----0.00967607432758<br />'
p377
sg16
S'Regarding domain-dependent systems, most of them aggregate statements and generate referring expressions (Bontcheva and Wilks, 2004; Dongilli, 2008; Galanis and Androutsopoulos, 2007; Hielkema, 2009; Liang et al., 2011). Only one attempts further discourse structuring: Laing et al.\xe2\x80\x99s system for verbalising medical ontologies organises text according to rhetorical structure.  '
p378
sg18
F0.013593226366161441
saa(lp379
S'W11-2821-71'
p380
a(dp381
g5
F-0.96262079
sg6
S'-1 1:0.0117998847901 2:0.0883705113568 3:0.0171688745695'
p382
sg8
S'The near-perfect performance of the organised text group on the first questions demonstrates the benefit of viewing a familiar genre.'
p383
sg10
S'A drop in performance by the unorganised text group on question 5, \xe2\x80\x98How many kinds of seta appendage cephalothorax 12In this case responses for organised texts should be faster, a point we intend to check in future work. are there in total?\xe2\x80\x99 was expected since it is a harder question that requires a search of the entire unorganised text whilst simultaneously counting instances. '
p384
sg12
S'-1'
p385
sg14
S'->demonstrates---VBZ---root-----         0.0117998847901<br />------->performance---NN---nsubj-----0.0483803716379         0.0883705113568<br />------------->The---DT---det-----<br />------------->near-perfect---JJ---amod-----0.0117998847901<br />------------->group---NN---prep_of-----0.129798732691<br />------------------->the---DT---det-----<br />------------------->organised---JJ---amod-----0.112006233326<br />------------------->text---NN---nn-----0.175009739571<br />------------------->questions---NNS---prep_on-----0.0825991935307<br />------------------------->the---DT---det-----<br />------------------------->first---JJ---amod-----0.0589994239505<br />------->benefit---NN---dobj-----0.0117998847901         0.0171688745695<br />------------->the---DT---det-----<br />------------->viewing---VBG---prepc_of-----0.0353996543703<br />------------------->genre---NN---dobj-----0.00967607432758<br />------------------------->a---DT---det-----<br />------------------------->familiar---JJ---amod-----0.0117998847901<br />'
p386
sg16
S'One explanation for these findings would be that people do whatever is necessary to achieve a desired level of performance, so that when provided with superior tools they achieve roughly the same result but with less effort.12 The drop in performance by the unorganised text group on question 1 might have been due to unfamiliarity with a sentence-list type of text (all participants answered question 1 first since questions were always presented in the same order). Improvements on later questions could have been the result of a learning effect with this group. '
p387
sg18
F0.013356100998884644
saa(lp388
S'N06-1031-114'
p389
a(dp390
g5
F0.1584204
sg6
S'-1 1:0.0583531326987 2:0.0948238406354 3:0.0692943450797'
p391
sg8
S'In Figure 8, rule \xc2\xae is relabeled as rule \xc2\xae and expects an NP-C\xcb\x86VP, i.e., an NP-C with a VP parent.'
p392
sg10
S'In the PTB, we observe that the NP-C she never has a VP parent, while her does. In fact, the most popular parent for the NP-C her is VP, while the most popular parent for she is S. Rule (1) is relabeled as the NP-C\xcb\x86S rule \xc2\xae and her is expressed as the NPC\xcb\x86VP rule Q. Only rule (E) can partner with rule & which produces the correct output deeply love her. '
p393
sg12
S'-1'
p394
sg14
S'->relabeled---VBN---root-----         0.0583531326987<br />------->Figure---NNP---prep_in-----<br />------------->8---CD---num-----<br />------->\xc2\xae---NNS---nsubjpass-----0.0         0.0948238406354<br />------------->rule---NN---nn-----0.189647681271<br />------->is---VBZ---auxpass-----<br />------->\xc2\xae---NNS---prep_as-----<br />------------->rule---NN---nn-----<br />------------->expects---VBZ---conj_and-----<br />------------------->NP-C\xcb\x86VP---NN---dobj-----0.0692943450797         0.0692943450797<br />------------------------->an---DT---det-----<br />------------------->i.e.---FW---dep-----<br />------------------->an---DT---parataxis-----<br />------------------------->NP-C---VBG---amod-----<br />------------------------->parent---NN---prep_with-----<br />------------------------------->a---DT---det-----<br />------------------------------->VP---NNP---nn-----<br />------->expects---VBZ---prep_as-----<br />'
p395
sg16
S'It seemed likely that such contextual information could also benefit MT. Let us tackle the bad output from Figure 6 with parent annotation. '
p396
sg18
F0.009912183252197525
saa(lp397
S'N06-1031-16'
p398
a(dp399
g5
F-1.1177608
sg6
S'+1 1:0.0361772904638 2:0.0 3:0.0555087226383'
p400
sg8
S'In this paper, we argue that the overly-general tagset of the PTB is problematic for MT because it fails to capture important grammatical distinctions that are critical in translation.'
p401
sg10
S'As a solution, we propose methods of relabeling the syntax trees that effectively improve translation quality. Consider the derivation in Figure 2. '
p402
sg12
S'+1'
p403
sg14
S'->argue---VBP---root-----         0.0361772904638<br />------->paper---NN---prep_in-----<br />------------->this---DT---det-----<br />------->we---PRP---nsubj-----         0.0<br />------->problematic---JJ---ccomp-----<br />------------->that---IN---mark-----<br />------------->tagset---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->overly-general---JJ---amod-----<br />------------------->PTB---NNP---prep_of-----<br />------------------------->the---DT---det-----<br />------------->is---VBZ---cop-----<br />------------->MT---NNP---prep_for-----<br />------------->fails---VBZ---advcl-----<br />------------------->because---IN---mark-----<br />------------------->it---PRP---nsubj-----<br />------------------->capture---VB---xcomp-----<br />------------------------->it---PRP---xsubj-----<br />------------------------->to---TO---aux-----<br />------------------------->distinctions---NNS---dobj-----0.0296658957036         0.0555087226383<br />------------------------------->important---JJ---amod-----0.0361772904638<br />------------------------------->grammatical---JJ---amod-----0.0296658957036<br />------------------------------->critical---JJ---rcmod-----0.0361772904638<br />------------------------------------->distinctions---NNS---nsubj-----0.0296658957036<br />------------------------------------->are---VBP---cop-----<br />------------------------------------->translation---NN---prep_in-----0.171700067791<br />'
p404
sg16
S'The Penn English Treebank (PTB) (Marcus et al., 1993) is our source of syntactic information, largely due to the availability of reliable parsers. It is not clear, however, whether this resource is suitable, as is, for the task of MT. '
p405
sg18
F0.00990127553669744
saa(lp406
S'N06-1031-11'
p407
a(dp408
g5
F0.008363732
sg6
S'-1 1:0.0296658957036 2:0.118663582815 3:0.0834499850498'
p409
sg8
S'Next, is translated as the NP-C the gunman by rule T. Finally, rule combines the sequence of NP-C VP .'
p410
sg10
S'into an S, denoting a complete tree. The yield of this tree gives the target translation: the gunman was killed by police. '
p411
sg12
S'-1'
p412
sg14
S'->combines---VBZ---root-----         0.0296658957036<br />------->Next---RB---advmod-----<br />------->translated---VBN---parataxis-----<br />------------->is---VBZ---auxpass-----<br />------------->NP-C---NN---prep_as-----<br />------------------->the---DT---det-----<br />------------->Finally---NNP---nsubjpass-----<br />------------------->the---DT---det-----<br />------------------->gunman---JJ---amod-----<br />------------------------->rule---NN---prep_by-----<br />------------------->T.---NNP---nn-----<br />------->rule---NN---nsubj-----0.118663582815         0.118663582815<br />------->sequence---NN---dobj-----0.0723545809276         0.0834499850498<br />------------->the---DT---det-----<br />------------->VP---NNP---prep_of-----0.118663582815<br />------------------->NP-C---NNP---nn-----0.0593317914073<br />'
p413
sg16
S'Rule 01 replaces the Chinese word (shaded) with the English NP-C police. Rule (2) then builds a VP over the NP-C sequence. '
p414
sg18
F0.009202111040342027
saa(lp415
S'N06-1031-64'
p416
a(dp417
g5
F-1.8248563
sg6
S'-1 1:0.00889513943976 2:0.0 3:0.0168787986828'
p418
sg8
S'This addresses two features of Chinese that are problematic in translation to English: the infrequent use of articles and the lack of overt number indicators on nouns.'
p419
sg10
S'We lexicalized these determiners: the, a, an, this, that, these, or those, and grouped together those with similar grammatical distributions (a/an, this/that, and these/those). Variant 1 included all the determiners mentioned above and variant 2 was restricted to the and a/an to focus only on articles. '
p420
sg12
S'-1'
p421
sg14
S'->addresses---VBZ---root-----         0.00889513943976<br />------->This---DT---nsubj-----         0.0<br />------->features---NNS---dobj-----0.00729414158734         0.0168787986828<br />------------->two---CD---num-----0.0510589911113<br />------------->Chinese---NNP---prep_of-----0.021882424762<br />------------->problematic---JJ---rcmod-----0.0145882831747<br />------------------->features---NNS---nsubj-----0.00729414158734<br />------------------->are---VBP---cop-----<br />------------------->translation---NN---prep_in-----0.0211084913386<br />------------------->English---NNP---prep_to-----0.043764849524<br />------------------->use---NN---nsubj-----0.00615821553361<br />------------------------->the---DT---det-----<br />------------------------->infrequent---JJ---amod-----0.00889513943976<br />------------------------->articles---NNS---prep_of-----0.0177902788795<br />------------------->lack---NN---nsubj-----0.00889513943976<br />------------------------->the---DT---det-----<br />------------------------->indicators---NNS---prep_of-----0.00889513943976<br />------------------------------->overt---JJ---amod-----0.00889513943976<br />------------------------------->number---NN---nn-----0.0364707079367<br />------------------------------->nouns---NNS---prep_on-----0.00889513943976<br />------------->use---NN---conj_and-----0.00615821553361<br />------------->lack---NN---conj_and-----0.00889513943976<br />------->use---NN---dobj-----<br />------->lack---NN---dobj-----<br />'
p422
sg16
S'The second strategy was DT lexicalization  (LEX_DT), which we encountered previously in Figure 4. '
p423
sg18
F0.009151649372078637
saa(lp424
S'N06-1031-41'
p425
a(dp426
g5
F-0.75709231
sg6
S'-1 1:0.0583531326987 2:0.0255451701032 3:0.0266854183193'
p427
sg8
S'The small tagset of the PTB has the advantage of being simple to annotate and to parse.'
p428
sg10
S'On the other hand, this can lead to tags that are overly generic. Klein and Manning (2003) discuss this as a problem in parsing and demonstrate that annotating additional information onto the PTB tags leads to improved parsing performance. '
p429
sg12
S'-1'
p430
sg14
S'->has---VBZ---root-----         0.0583531326987<br />------->tagset---NN---nsubj-----0.0123164310672         0.0255451701032<br />------------->The---DT---det-----<br />------------->small---JJ---amod-----0.00889513943976<br />------------->PTB---NNP---prep_of-----0.0554239398025<br />------------------->the---DT---det-----<br />------->advantage---NN---dobj-----0.00889513943976         0.0266854183193<br />------------->the---DT---det-----<br />------------->simple---JJ---prepc_of-----0.00889513943976<br />------------------->being---VBG---cop-----<br />------------------->annotate---VB---dep-----0.0444756971988<br />------------------------->to---TO---aux-----<br />------------------------->parse---VB---conj_and-----0.035580557759<br />------------------------------->to---TO---aux-----<br />------------------->parse---VB---dep-----0.035580557759<br />'
p431
sg16
S'The third column gives the BLEU score along with an indication whether it is a statistically significant increase (\xe2\x96\xb2), a statistically significant decrease (\xe2\x96\xbc), or neither (? ) over the baseline BLEU score.  '
p432
sg18
F0.009009839030463533
saa(lp433
S'N06-1031-53'
p434
a(dp435
g5
F-0.89465066
sg6
S'-1 1:0.0583531326987 2:0.0145882831747 3:0.0218613961791'
p436
sg8
S'If we lexicalize all DTs in the parse trees, the problematic DT is relabeled more specifically as DT_this, as seen in rule 20\xef\xbf\xbd in Figure 4.'
p437
sg10
S'This also produces rules like 40\xef\xbf\xbd, where both the determiner and the noun are plural (notice the DT_these), and \xef\xbf\xbd, where both are singular. With such a ruleset, 20 400 \xef\xbf\xbd could only combine with 400\xef\xbf\xbd, not 40\xef\xbf\xbd, enforcing the grammatical output this Turkish position. '
p438
sg12
S'-1'
p439
sg14
S'->relabeled---VBN---root-----         0.0583531326987<br />------->lexicalize---VBP---advcl-----<br />------------->If---IN---mark-----<br />------------->we---PRP---nsubj-----<br />------------->DTs---NN---dobj-----0.00889513943976         0.0218613961791<br />------------------->all---DT---det-----<br />------------------->trees---NNS---prep_in-----0.0211084913386<br />------------------------->the---DT---det-----<br />------------------------->parse---JJ---amod-----0.035580557759<br />------->DT---NN---nsubjpass-----0.0145882831747         0.0145882831747<br />------------->the---DT---det-----<br />------------->problematic---JJ---amod-----0.0145882831747<br />------->is---VBZ---auxpass-----<br />------->specifically---RB---advmod-----<br />------------->more---RBR---advmod-----<br />------->DT_this---NNP---prep_as-----<br />------->seen---VBN---advcl-----<br />------------->as---IN---mark-----<br />------------->rule---NN---prep_in-----<br />------------------->20---CD---num-----<br />------------------->Figure---NNP---prep_in-----<br />------------------------->4---CD---num-----<br />'
p440
sg16
S'We generalize lexicalization to allow a lexical item (terminal word) to be annotated onto any ancestor label, not only its parent. Let us revisit the determiner/noun number disagreement problem in Figure 2 (*this Turkish positions). '
p441
sg18
F0.008963967699707571
saa(lp442
S'N06-1031-100'
p443
a(dp444
g5
F-1.8182241
sg6
S'-1 1:0.00889513943976 2:0.0 3:0.0177902788795'
p445
sg8
S'We can sidestep this mistake through sisterhood-annotation, which yields the relabeled rules \xc2\xae and D in Figure 7.'
p446
sg10
S'Rule D expects an NP-C on the right border of the constituent (NP-C#L). Since she never occurs in this position in the PTB, it should never be sisterhood-annotated as an NP-C#L. '
p447
sg12
S'-1'
p448
sg14
S'->sidestep---VB---root-----         0.00889513943976<br />------->We---PRP---nsubj-----         0.0<br />------->can---MD---aux-----<br />------->mistake---NN---dobj-----0.0177902788795         0.0177902788795<br />------------->this---DT---det-----<br />------->sisterhood-annotation---NN---prep_through-----<br />------------->yields---VBZ---rcmod-----<br />------------------->sisterhood-annotation---NN---nsubj-----<br />------------------->\xc2\xae---NN---dobj-----<br />------------------------->the---DT---det-----<br />------------------------->relabeled---JJ---amod-----<br />------------------------->rules---NNS---nn-----<br />------------------------->D---NNP---conj_and-----<br />------------------------------->Figure---NNP---prep_in-----<br />------------------------------------->7---CD---num-----<br />------------------->D---NNP---dobj-----<br />'
p449
sg16
S'Figure 6 presents a derivation that leads to the ungrammatical output *deeply love she. The subject pronoun she is incorrectly preferred over the object form her because the most popular NP-C translation for is she. '
p450
sg18
F0.008895539152420475
saa(lp451
S'W06-3312-82'
p452
a(dp453
g5
F-0.28383413
sg6
S'-1 1:0.0369731288737 2:0.133103263945 3:0.0'
p454
sg8
S'If no nominalizations are present in the NP, instead of defaulting to VP attachment, the PP is attached to the closest NP to its left that is not the object of an of PP.'
p455
sg10
S'This behavior is intuitively consistent since in PPs are usually adjuncts to the main NP (which is usually an entity if not a nominalization) and are unlikely to modify any of the NP\xe2\x80\x99s modifiers.  The final heuristic encodes the frequent attachment of on PPs with NPs indicating effect, influence, impact, etc. '
p456
sg12
S'-1'
p457
sg14
S'->attached---VBN---root-----         0.0369731288737<br />------->present---JJ---advcl-----<br />------------->If---IN---mark-----<br />------------->nominalizations---NNS---nsubj-----<br />------------------->no---DT---det-----<br />------------->are---VBP---cop-----<br />------------->NP---NNP---prep_in-----<br />------------------->the---DT---det-----<br />------------->defaulting---VBG---prepc_instead_of-----<br />------------------->attachment---NNP---prep_to-----<br />------------------------->VP---NNP---nn-----<br />------->PP---NNP---nsubjpass-----0.133103263945         0.133103263945<br />------------->the---DT---det-----<br />------->is---VBZ---auxpass-----<br />------->NP---NN---prep_to-----<br />------------->the---DT---det-----<br />------------->closest---JJS---amod-----<br />------->left---NN---prep_to-----<br />------------->its---PRP$---poss-----<br />------------->object---NN---rcmod-----<br />------------------->left---NN---nsubj-----<br />------------------->is---VBZ---cop-----<br />------------------->not---RB---neg-----<br />------------------->the---DT---det-----<br />------------------->an---DT---prep_of-----<br />------------------------->PP---NNP---prep_of-----<br />'
p458
sg16
S'The major form of beta-amylase in Arabidopsis.. . Here, the system first attempts nominalization attachment. '
p459
sg18
F0.00781129229652004
saa(lp460
S'W06-3312-123'
p461
a(dp462
g5
F-1.242984
sg6
S'+1 1:0.0218233207542 2:0.0534803685475 3:0.0'
p463
sg8
S'The application of right association for PPs headed by of, for, and from resulted in correct attachment in 96.2% of their occurrences in the development corpus.'
p464
sg10
S'Because this class of PPs is processed using the baseline heuristic without any refinements, it has no effect on overall system accuracy as compared to overall baseline accuracy. However, it does provide a clear delineation of the subset of PPs for which right association is a sufficient and optimal solution for attachment. '
p465
sg12
S'+1'
p466
sg14
S'->resulted---VBD---root-----         0.0218233207542<br />------->application---NN---nsubj-----0.0072744402514         0.0534803685475<br />------------->The---DT---det-----<br />------------->association---NN---prep_of-----0.0357908704107<br />------------------->right---JJ---amod-----0.0417560154792<br />------------------->PPs---NNP---prep_for-----0.164685081391<br />------------------------->headed---VBN---partmod-----0.0178954352054<br />------------------------------->by---IN---prep-----<br />------------------------------------->of---IN---pcomp-----<br />------------------------------------->for---IN---conj_and-----<br />------------------------------------->from---IN---conj_and-----<br />------------------------------->for---IN---prep-----<br />------------------------------->from---IN---prep-----<br />------->attachment---NN---prep_in-----<br />------------->correct---JJ---amod-----<br />------------->%---NN---prep_in-----<br />------------------->96.2---CD---num-----<br />------------------->occurrences---NNS---prep_of-----<br />------------------------->their---PRP$---poss-----<br />------->corpus---NN---prep_in-----<br />------------->the---DT---det-----<br />------------->development---NN---nn-----<br />'
p467
sg16
S'Thus all reported accuracy numbers reflect performance of the heuristics alone, isolated from possible chunking errors. The PP attachment module is, however, designed for input from the chunker and does not handle constructs which the chunker does not provide (e.g. PP conjunctions and non-simple parenthetical NPs).  '
p468
sg18
F0.007193093444902659
saa(lp469
S'W06-3312-173'
p470
a(dp471
g5
F-1.7477545
sg6
S'-1 1:0.0218233207542 2:0.0 3:0.0'
p472
sg8
S'This resulted in a 3% increase in the accuracy for in PPs with no adverse effects on any of the other PPs with nominalization affinity.'
p473
sg10
S'Despite further anticipated improvements from similar changes, attachment of in PPs stands to benefit the most from additional semantic information in the form of rules that encode containment semantics (i.e. which types of things can be contained in other types of things). Possible containment rules exist for the few semantic categories that are already implemented; enzymes, for instance, can be contained in organisms, but organisms are rarely contained in anything (though organisms can be said to be contained in their species, the relationship is rarely expressed as containment). '
p474
sg12
S'-1'
p475
sg14
S'->resulted---VBD---root-----         0.0218233207542<br />------->This---DT---nsubj-----         0.0<br />------->increase---NN---prep_in-----<br />------------->a---DT---det-----<br />------------->%---NN---amod-----<br />------------------->3---CD---number-----<br />------------->accuracy---NN---prep_in-----<br />------------------->the---DT---det-----<br />------->for---IN---dep-----<br />------->PPs---NNP---prep_in-----<br />------------->effects---NNS---prep_with-----<br />------------------->no---DT---det-----<br />------------------->adverse---JJ---amod-----<br />------------------->any---DT---prep_on-----<br />------------------------->PPs---NN---prep_of-----<br />------------------------------->the---DT---det-----<br />------------------------------->other---JJ---amod-----<br />------------------------------->affinity---NN---prep_with-----<br />------------------------------------->nominalization---NN---nn-----<br />'
p476
sg16
S'As mentioned above, splitting nominalizations into general and specific classes may solve this problem. To explore this conjecture, the most common (particularly with in PPs) general nominalization, activity, was ignored when searching for nominalization attachment points. '
p477
sg18
F0.0069419065936823805
saa(lp478
S'W06-3312-202'
p479
a(dp480
g5
F-0.99174725
sg6
S'-1 1:0.0431562821696 2:0.0453929421192 3:0.0'
p481
sg8
S'The accuracy and coverage of each rule for the test data, as contrasted with the development set, is given in Table 2.'
p482
sg10
S'The baseline heuristic achieved an accuracy of 77.5%. A comparative performance breakdown by preposition is given in Table 1. '
p483
sg12
S'-1'
p484
sg14
S'->given---VBN---root-----         0.0431562821696<br />------->accuracy---NN---nsubjpass-----0.125153218292         0.0453929421192<br />------------->The---DT---det-----<br />------------->coverage---NN---conj_and-----0.0298257253423<br />------------->rule---NN---prep_of-----0.0151085560573<br />------------------->each---DT---det-----<br />------------------->data---NNS---prep_for-----0.0474719103865<br />------------------------->the---DT---det-----<br />------------------------->test---NN---nn-----0.0447226820341<br />------------->contrasted---VBN---dep-----0.0145488805028<br />------------------->as---IN---mark-----<br />------------------->set---NN---prep_with-----0.00431562821696<br />------------------------->the---DT---det-----<br />------------------------->development---NN---nn-----0.0819969361222<br />------->coverage---NN---nsubjpass-----<br />------->is---VBZ---auxpass-----<br />------->Table---NNP---prep_in-----<br />------------->2---CD---num-----<br />'
p485
sg16
S'The system\xe2\x80\x99s overall attachment accuracy on this 8PMC query terms: metabolism, biosynthesis, proteolysis, peptidyltransferase, hexokinase, epimerase, laccase, ligase, dehydrogenase. test data is 82%, comparable to that for the development enzymology data. '
p486
sg18
F0.0068715910612084695
saa(lp487
S'W06-3312-216'
p488
a(dp489
g5
F-0.58801098
sg6
S'+1 1:0.0218233207542 2:0.0742135081507 3:0.0683303818154'
p490
sg8
S'Applying the strong nominalization affinity heuristic to these PPs resulted in an increase offor PP attachment accuracy in the test corpus to 75.8% and an overall increase in accuracy of 1.0%.'
p491
sg10
S'A similar pattern was observed for at PPs, where the pattern <CHEMICAL> at <CONCENTRATION> accounts for 25.6% of all at PP attachment errors and the majority of the performance decrease for the strong nominalization affinity heuristic between the two data sets. The remainder of the performance decrease for this heuristic is attributed to gaps in the  '
p492
sg12
S'+1'
p493
sg14
S'->resulted---VBD---root-----         0.0218233207542<br />------->Applying---VBG---csubj-----0.0072744402514         0.0742135081507<br />------------->heuristic---NN---dobj-----0.1193029013690.119302901369         0.0683303818154<br />------------------->the---DT---det-----<br />------------------->strong---JJ---amod-----0.02982572534230.0298257253423<br />------------------->nominalization---NN---nn-----0.07050659493430.0705065949343<br />------------------->affinity---NN---nn-----0.05368630561610.0536863056161<br />------------->PPs---NNP---prep_to-----0.164685081391<br />------------------->these---DT---det-----<br />------->accuracy---NN---prep_in-----<br />------------->an---DT---det-----<br />------------->increase---NN---nn-----<br />------------->offor---NN---nn-----<br />------------->PP---NN---nn-----<br />------------->attachment---NN---nn-----<br />------------->corpus---NN---prep_in-----<br />------------------->the---DT---det-----<br />------------------->test---NN---nn-----<br />------->%---NN---prep_to-----<br />------------->75.8---CD---num-----<br />------------->increase---NN---conj_and-----<br />------------------->an---DT---det-----<br />------------------->overall---JJ---amod-----<br />------->increase---NN---prep_to-----<br />------->accuracy---NN---prep_in-----<br />------------->%---NN---prep_of-----<br />------------------->1.0---CD---num-----<br />'
p494
sg16
S'In particular, for PPs with object NPs specifying a duration (or other measurement), as exemplified below, attach almost exclusively to VPs and nominalizations.  This behavior is also apparent in the development data, though in much smaller numbers. '
p495
sg18
F0.006817563755046842
saa(lp496
S'W06-3312-41'
p497
a(dp498
g5
F-1.0303157
sg6
S'+1 1:0.0265737963594 2:0.0 3:0.0870003718671'
p499
sg8
S'In focusing on postnominal PPs, we exclude here PPs that trivially attach to the VP for lack of NP attachment points and focus on the subset of PPs with the highest degree of attachment ambiguity. '
p500
sg10
S'For this exploratory study we compiled two manually annotated corporal, a smaller, targeted development corpus consisting of sentences referring to enzymes in five articles, and a larger test corpus consisting of the full text of nine articles drawn from a wider set of topics. This bias in the data was set deliberately to test whether NPs referring to enzymes follow a distinct pattern. '
p501
sg12
S'+1'
p502
sg14
S'->exclude---VBP---root-----         0.0265737963594<br />------->focusing---VBG---prepc_in-----<br />------------->PPs---NNP---prep_on-----<br />------------------->postnominal---JJ---amod-----<br />------->we---PRP---nsubj-----         0.0<br />------->here---RB---advmod-----<br />------->PPs---NNP---dobj-----0.14385225539         0.0870003718671<br />------------->attach---VB---rcmod-----0.0224354248637<br />------------------->PPs---NNP---nsubj-----0.14385225539<br />------------------->trivially---RB---advmod-----0.0324065033878<br />------------------->VP---NNP---prep_to-----0.0673062745911<br />------------------------->the---DT---det-----<br />------------------->lack---NN---prep_for-----0.0324065033878<br />------------------------->points---NNS---prep_of-----0.0576763636514<br />------------------------------->NP---NNP---nn-----0.0996163070121<br />------------------------------->attachment---NN---nn-----0.230163608625<br />------------------->focus---VB---conj_and-----0.0265737963594<br />------------------------->PPs---NNP---nsubj-----0.14385225539<br />------------------------->subset---NN---prep_on-----0.0265737963594<br />------------------------------->the---DT---det-----<br />------------------------------->PPs---NNP---prep_of-----0.14385225539<br />------------------------->degree---NN---prep_with-----0.0265737963594<br />------------------------------->the---DT---det-----<br />------------------------------->highest---JJS---amod-----0.0324065033878<br />------------------------------->ambiguity---NNS---prep_of-----0.0797213890783<br />------------------------------------->attachment---NN---nn-----0.230163608625<br />------------->focus---VB---rcmod-----0.0265737963594<br />'
p503
sg16
S'Consequently, the possible attachment points for a given PP are more numerous. By \xe2\x80\x9cpostnominal\xe2\x80\x9d, we denote PPs following an NP, where the attachment point may be within the NP but may also precede it. '
p504
sg18
F0.0067478929557186615
saa(lp505
S'W06-3312-134'
p506
a(dp507
g5
F-0.17310763
sg6
S'-1 1:0.0072744402514 2:0.0732117405486 3:0.164685081391'
p508
sg8
S'The heuristic for strong nominalization affinity deals with only two types of PPs, those headed by the prepositions by and at, both of which occur with relatively low frequency in the development corpus.'
p509
sg10
S'Accordingly, the heuristic\xe2\x80\x99s impact on the overall accuracy of the system is rather small. However, it affords the largest increase in accuracy for the PPs of its class. '
p510
sg12
S'-1'
p511
sg14
S'->deals---VBZ---root-----         0.0072744402514<br />------->heuristic---NN---nsubj-----0.119302901369         0.0732117405486<br />------------->The---DT---det-----<br />------------->nominalization---NN---prep_for-----0.0705065949343<br />------------------->strong---JJ---amod-----0.0298257253423<br />------->affinity---RB---advmod-----<br />------->types---NNS---prep_with-----<br />------------->only---RB---advmod-----<br />------------->two---CD---num-----<br />------------->PPs---NNP---prep_of-----<br />------------------->those---DT---appos-----<br />------------------------->headed---VBN---partmod-----<br />------------------------------->prepositions---NNS---agent-----<br />------------------------------------->the---DT---det-----<br />------------------------------->by---IN---prep-----<br />------------------------------------->at---IN---conj_and-----<br />------------------------------->at---IN---prep-----<br />------------------->occur---VBP---rcmod-----<br />------------------------->of---IN---nsubj-----<br />------------------------------->PPs---NNP---pobj-----0.164685081391         0.164685081391<br />------------------------------->both---DT---dep-----<br />------------------------->frequency---NN---prep_with-----<br />------------------------------->low---JJ---amod-----<br />------------------------------------->relatively---RB---advmod-----<br />------------------------------->corpus---NN---prep_in-----<br />------------------------------------->the---DT---det-----<br />------------------------------------->development---NN---nn-----<br />'
p512
sg16
S'The majority of the error here corresponds to PPs that should be attached to a VP. For example, attachment errors occurred both in the sentence \xe2\x80\x9c... this was followed by exoglucanases liberating cellobiose from these nicks... \xe2\x80\x9d and in the sentence \xe2\x80\x9c... the reactions were stopped by placing the microtubes in boiling water for 2 to 3 min.\xe2\x80\x9d  '
p513
sg18
F0.00662477147108423
saa(lp514
S'W10-1919-61'
p515
a(dp516
g5
F-1.4031904
sg6
S'+1 1:0.00782087101074 2:0.0 3:0.0763059328168'
p517
sg8
S'As related types of statements are annotated as Localization events in the applied model, we propose to apply this event type and differentiate between the specific subtypes on the basis of the event arguments.'
p518
sg10
S'A further 39% are of categories that can be viewed as high-level processes. These are distinct from the events considered in the BioNLP\xe2\x80\x9909 shared task in involving coarsergrained events and larger-scale participants than the GGP entities considered in the task: for example, conjugation occurs between bacteria, and virulence may involve a human host. '
p519
sg12
S'+1'
p520
sg14
S'->propose---VBP---root-----         0.00782087101074<br />------->annotated---VBG---advcl-----<br />------------->As---IN---mark-----<br />------------->types---NNS---nsubj-----<br />------------------->related---JJ---amod-----<br />------------------->statements---NNS---prep_of-----<br />------------->are---VBP---aux-----<br />------------->events---NNS---prep_as-----<br />------------------->Localization---JJ---amod-----<br />------------------->model---NN---prep_in-----<br />------------------------->the---DT---det-----<br />------------------------->applied---JJ---amod-----<br />------->we---PRP---nsubj-----         0.0<br />------->apply---VB---xcomp-----<br />------------->we---PRP---xsubj-----<br />------------->to---TO---aux-----<br />------------->type---NN---dobj-----0.0351939195483         0.0763059328168<br />------------------->this---DT---det-----<br />------------------->event---NN---nn-----0.117417946085<br />------------->differentiate---VB---conj_and-----<br />------------------->subtypes---NNS---prep_between-----<br />------------------------->the---DT---det-----<br />------------------------->specific---JJ---amod-----<br />------------------------->basis---NN---prep_on-----<br />------------------------------->the---DT---det-----<br />------------------------------->arguments---NNS---prep_of-----<br />------------------------------------->the---DT---det-----<br />------------------------------------->event---NN---nn-----<br />------->differentiate---VB---xcomp-----<br />'
p521
sg16
S'To identify general categories, we performed a manual analysis of the 217 unique normalized terms annotated in the corpus as biological processes (Table 4). We find that the majority of the instances (58%) relate to location or movement. '
p522
sg18
F0.009647179644814088
saa(lp523
S'W10-1919-3'
p524
a(dp525
g5
F0.63009379
sg6
S'+1 1:0.0840349858117 2:0.0 3:0.193483584662'
p526
sg8
S'In this study, we propose an adaptation of the event extraction approach to a subdomain related to infectious diseases and present analysis and initial experiments on the feasibility of event extraction from domain full text publications. '
p527
sg10
S'For most of the previous decade, biomedical Information Extraction (IE) efforts have focused primarily on tasks that allow extracted information to be represented as simple pairs of related entities. This representation is applicable to many IE targets of interest, such as gene-disease associations (Chun et al., 2006) and protein-protein interactions (N\xc2\xb4edellec, 2005; Krallinger et al., 2007). '
p528
sg12
S'+1'
p529
sg14
S'->propose---VBP---root-----         0.0840349858117<br />------->study---NN---prep_in-----<br />------------->this---DT---det-----<br />------->we---PRP---nsubj-----         0.0<br />------->adaptation---NN---dobj-----0.0697566294146         0.193483584662<br />------------->an---DT---det-----<br />------------->approach---NN---prep_of-----0.117362951539<br />------------------->the---DT---det-----<br />------------------->event---NN---nn-----0.293407378847<br />------------------->extraction---NN---nn-----0.293407378847<br />------->subdomain---NN---prep_to-----<br />------------->a---DT---det-----<br />------------->related---VBN---partmod-----<br />------------------->diseases---NNS---prep_to-----<br />------------------------->infectious---JJ---amod-----<br />------------------------->analysis---NN---conj_and-----<br />------------------------------->present---JJ---amod-----<br />------------------------------->experiments---NNS---conj_and-----<br />------------------------------------->initial---JJ---amod-----<br />------------------------->experiments---NNS---conj_and-----<br />------------------->analysis---NN---prep_to-----<br />------------------->feasibility---NN---prep_on-----<br />------------------------->the---DT---det-----<br />------------------------->extraction---NN---prep_of-----<br />------------------------------->event---NN---nn-----<br />------------------->publications---NNS---prep_from-----<br />------------------------->domain---NN---nn-----<br />------------------------->full---JJ---amod-----<br />------------------------->text---NN---nn-----<br />'
p530
sg16
S'However, event extraction efforts have so far been limited to publication abstracts, with most studies further considering only the specific transcription factor-related subdomain of molecular biology of the GENIA corpus. To establish the broader relevance of the event extraction approach and proposed methods, it is necessary to expand on these constraints. '
p531
sg18
F0.009505345582855883
saa(lp532
S'W10-1919-91'
p533
a(dp534
g5
F-0.98994732
sg6
S'+1 1:0.0194760882813 2:0.0 3:0.107118485547'
p535
sg8
S'As gene and gene product entities are central to domain information needs and the core entities of the applied event extraction approach, we first introduced annotation for this entity class.'
p536
sg10
S'We created manual GGP annotation following the annotation guidelines of the GENIA GGP Corpus (Ohta et al., 2009). As this corpus was the source of the gene/protein entity annotation provided as the basis of the BioNLP shared task on event extraction, adopting its annotation criteria assures compatibility with recently introduced event extraction methods. '
p537
sg12
S'+1'
p538
sg14
S'->introduced---VBD---root-----         0.0194760882813<br />------->central---JJ---advcl-----<br />------------->As---IN---mark-----<br />------------->entities---NNS---nsubj-----<br />------------------->gene---NN---nn-----<br />------------------------->gene---NN---conj_and-----<br />------------------->gene---NN---nn-----<br />------------------->product---NN---nn-----<br />------------->are---VBP---cop-----<br />------------->needs---NNS---prep_to-----<br />------------------->domain---NN---nn-----<br />------------------->information---NN---nn-----<br />------------------->entities---NNS---conj_and-----<br />------------------------->the---DT---det-----<br />------------------------->core---JJ---amod-----<br />------------------------->approach---NN---prep_of-----<br />------------------------------->the---DT---det-----<br />------------------------------->applied---JJ---amod-----<br />------------------------------->event---NN---nn-----<br />------------------------------->extraction---NN---nn-----<br />------------->entities---NNS---prep_to-----<br />------->we---PRP---nsubj-----         0.0<br />------->first---RB---advmod-----<br />------->annotation---NN---dobj-----0.107118485547         0.107118485547<br />------->class---NN---prep_for-----<br />------------->this---DT---det-----<br />------------->entity---NN---nn-----<br />'
p539
sg16
S'This selection produced a subcorpus of four full-text documents and 19 abstracts. The statistics for this corpus are shown in Table 8.  '
p540
sg18
F0.009180214854765114
saa(lp541
S'W10-1919-159'
p542
a(dp543
g5
F-0.75978537
sg6
S'+1 1:0.0398585347512 2:0.0 3:0.0956832893078'
p544
sg8
S'We have presented a study of the adaptation of an event extraction approach to the T4SS subdomain as a step toward the introduction of event extraction to the broader infectious diseases domain.'
p545
sg10
S'We applied a previously introduced corpus of subdomain full texts annotated for mentions of bacteria and terms from the three top-level Gene Ontology subontologies as a reference defining domain information needs to study how these can be met through the application of events defined in the BioNLP\xe2\x80\x9909 Shared Task on event extraction. Analysis indicated that with minor revision of the arguments, the Binding and Localization event types could account for the majority of both biological processes and molecular functions of interest. '
p546
sg12
S'+1'
p547
sg14
S'->presented---VBN---root-----         0.0398585347512<br />------->We---PRP---nsubj-----         0.0<br />------->have---VBP---aux-----<br />------->study---NN---dobj-----0.0834994241487         0.0956832893078<br />------------->a---DT---det-----<br />------------->adaptation---NN---prep_of-----0.0330861844123<br />------------------->the---DT---det-----<br />------------------->approach---NN---prep_of-----0.0278331413829<br />------------------------->an---DT---det-----<br />------------------------->event---NN---nn-----0.166998848297<br />------------------------->extraction---NN---nn-----0.166998848297<br />------->subdomain---NN---prep_to-----<br />------------->the---DT---det-----<br />------------->T4SS---JJ---amod-----<br />------------->step---NN---prep_as-----<br />------------------->a---DT---det-----<br />------------------->introduction---NN---prep_toward-----<br />------------------------->the---DT---det-----<br />------------------------->extraction---NN---prep_of-----<br />------------------------------->event---NN---nn-----<br />------->domain---NN---prep_to-----<br />------------->the---DT---det-----<br />------------->broader---JJR---amod-----<br />------------->infectious---NNP---nn-----<br />------------->diseases---NNS---nn-----<br />'
p548
sg16
S'While this experiment is limited in both scope and scale, it suggests that the event extraction approach can be beneficially applied to detect domain events represented by novel argument structures. As a demonstration of feasibility the result is encouraging for both the applicability of event extraction to this specific new domain and for the adaptability of the approach to new domains in general.  '
p549
sg18
F0.009167033532741804
saa(lp550
S'W10-1919-158'
p551
a(dp552
g5
F-1.8267381
sg6
S'+1 1:0.00484688401566 2:0.0193875360626 3:0.0'
p553
sg8
S'As a demonstration of feasibility the result is encouraging for both the applicability of event extraction to this specific new domain and for the adaptability of the approach to new domains in general. '
p554
sg10
S'We have presented a study of the adaptation of an event extraction approach to the T4SS subdomain as a step toward the introduction of event extraction to the broader infectious diseases domain. We applied a previously introduced corpus of subdomain full texts annotated for mentions of bacteria and terms from the three top-level Gene Ontology subontologies as a reference defining domain information needs to study how these can be met through the application of events defined in the BioNLP\xe2\x80\x9909 Shared Task on event extraction. '
p555
sg12
S'+1'
p556
sg14
S'->encouraging---VBG---root-----         0.00484688401566<br />------->demonstration---NN---prep_as-----<br />------------->a---DT---det-----<br />------------->feasibility---NN---prep_of-----<br />------->result---NN---nsubj-----0.0193875360626         0.0193875360626<br />------------->the---DT---det-----<br />------->result---NN---nsubj-----<br />------->is---VBZ---aux-----<br />------->encouraging---VBG---conj_and-----<br />------->applicability---NN---prep_for-----<br />------------->both---PDT---predet-----<br />------------->the---DT---det-----<br />------------->extraction---NN---prep_of-----<br />------------------->event---NN---nn-----<br />------->domain---NN---prep_to-----<br />------------->this---DT---det-----<br />------------->specific---JJ---amod-----<br />------------->new---JJ---amod-----<br />------->adaptability---NN---prep_for-----<br />------------->the---DT---det-----<br />------------->approach---NN---prep_of-----<br />------------------->the---DT---det-----<br />------------------->domains---NNS---prep_to-----<br />------------------------->new---JJ---amod-----<br />------------------------->general---NN---prep_in-----<br />'
p557
sg16
S'With respect to the baseline result, the machine-learning approach achieves a 21% relative reduction in error. While this experiment is limited in both scope and scale, it suggests that the event extraction approach can be beneficially applied to detect domain events represented by novel argument structures. '
p558
sg18
F0.009104407484211822
saa(lp559
S'W10-1919-40'
p560
a(dp561
g5
F-1.9727351
sg6
S'-1 1:0.00484688401566 2:0.00391043550537 3:0.0'
p562
sg8
S'These constraints assure that the corpus is relevant to the information needs of biologists working in the domain and that it can be used as a reference for the study of automatic GO annotation.'
p563
sg10
S'In the work introducing the corpus, the task of automatic GO annotation was studied as facilitating improved information access, such as advanced search functionality: GO annotation can allow for search by semantic classes or co-occurrences of terms of specified classes. The event approach considered in this study further extends on these opportunities in introducing a model allowing e.g. search by specific associations of the concepts of interest. '
p564
sg12
S'-1'
p565
sg14
S'->assure---VB---root-----         0.00484688401566<br />------->constraints---NNS---nsubj-----0.00391043550537         0.00391043550537<br />------------->These---DT---det-----<br />------->relevant---JJ---ccomp-----<br />------------->that---IN---mark-----<br />------------->corpus---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------->is---VBZ---cop-----<br />------------->needs---NNS---prep_to-----<br />------------------->the---DT---det-----<br />------------------->information---NN---nn-----<br />------------------->biologists---NNS---prep_of-----<br />------------->working---VBG---xcomp-----<br />------------------->domain---NN---prep_in-----<br />------------------------->the---DT---det-----<br />------------->used---VBN---conj_and-----<br />------------------->that---IN---mark-----<br />------------------->it---PRP---nsubjpass-----<br />------------------->can---MD---aux-----<br />------------------->be---VB---auxpass-----<br />------------------->reference---NN---prep_as-----<br />------------------------->a---DT---det-----<br />------------------------->study---NN---prep_for-----<br />------------------------------->the---DT---det-----<br />------------------------------->annotation---NN---prep_of-----<br />------------------------------------->automatic---JJ---amod-----<br />------------------------------------->GO---NNP---nn-----<br />------->used---VBN---ccomp-----<br />'
p566
sg16
S'The latter three correspond to the three Gene Ontology (GO) (Ashburner et al., 2000) toplevel sub-ontologies, and terms of these types were annotated with reference to both GO and relevance to the interests of domain experts, with guidelines  requiring that marked terms be both found in GO and associated with T4SS. '
p567
sg18
F0.00885849025685182
saa(lp568
S'W10-1919-108'
p569
a(dp570
g5
F-1.1723742
sg6
S'-1 1:0.0117313065161 2:0.0416106249732 3:0.0484188270095'
p571
sg8
S'During annotation, the number of annotated GGP associations with the targeted class of processes in the T4SS subcorpus was found to be too low to provide material for both training and testing a supervised learning-based event extraction approach.'
p572
sg10
S'To extend the source data, we searched PubMed for cases where a known T4SS-related protein co-occurred with an expression known to relate to the targeted process class (e.g. virulence, virulent, avirulent, non-virulent) and annotated a further set of sentences from the search results for both GGPs and their process associations. As the properties of these additional examples could not be assured to correspond to those of the targeted domain texts, we used these annotations only as development and training data, performing evaluation on cases drawn from the T4SS subcorpus. '
p573
sg12
S'-1'
p574
sg14
S'->found---VBN---root-----         0.0117313065161<br />------->annotation---NN---prep_during-----<br />------->number---NN---nsubjpass-----0.0129840588542         0.0416106249732<br />------------->the---DT---det-----<br />------------->associations---NNS---prep_of-----0.0162300735678<br />------------------->annotated---JJ---amod-----0.0454442059897<br />------------------->GGP---NNP---nn-----0.0860295811182<br />------------------->class---NN---prep_with-----0.0391043550537<br />------------------------->the---DT---det-----<br />------------------------->targeted---JJ---amod-----0.0242344200783<br />------------------------->processes---NNS---prep_of-----0.074298274602<br />------------------------------->subcorpus---NNS---prep_in-----0.0242344200783<br />------------------------------------->the---DT---det-----<br />------------------------------------->T4SS---CD---num-----0.0519362354168<br />------->was---VBD---auxpass-----<br />------->low---JJ---xcomp-----<br />------------->number---NN---xsubj-----<br />------------->to---TO---aux-----<br />------------->be---VB---cop-----<br />------------->too---RB---advmod-----<br />------------->provide---VB---xcomp-----<br />------------------->to---TO---aux-----<br />------------------->material---NN---dobj-----<br />------------------->training---NN---prep_for-----<br />------------------------->both---DT---det-----<br />------->testing---VBG---conj_and-----<br />------------->number---NN---nsubjpass-----<br />------------->approach---NN---dobj-----0.0464210484523         0.0484188270095<br />------------------->a---DT---det-----<br />------------------->supervised---JJ---amod-----0.00969376803132<br />------------------->learning-based---JJ---amod-----0.0194096741173<br />------------------->event---NN---nn-----0.117417946085<br />------------------->extraction---NN---nn-----0.0491516983613<br />'
p575
sg16
S'We adopted the GENIA Event corpus annotation guidelines (Kim et al., 2008), marking associations between specific GGPs and biological processes discussed in the text even when these are stated speculatively or their existence explicitly denied. As the analysis indicated this category of processes to typically involve a single stated participant in a fixed role, annotations were initially recorded as (GGP, process) pairs and later converted into an event representation. '
p576
sg18
F0.008583000719335836
saa(lp577
S'P10-1024-9'
p578
a(dp579
g5
F0.45529955
sg6
S'-1 1:0.122585278274 2:0.0761179904431 3:0.0'
p580
sg8
S'The marked argument is a core in 1 and an adjunct in 2 and 3.'
p581
sg10
S'Adjuncts form an independent semantic unit and their semantic role can often be inferred independently of the predicate (e.g., [after lunch] is usually a temporal modifier). Core \xe2\x88\x97 Omri Abend is grateful to the Azrieli Foundation for the award of an Azrieli Fellowship. '
p582
sg12
S'-1'
p583
sg14
S'->core---NN---root-----         0.122585278274<br />------->argument---NN---nsubj-----0.122585278274         0.0761179904431<br />------------->The---DT---det-----<br />------------->marked---JJ---amod-----0.0296507026125<br />------->is---VBZ---cop-----<br />------->a---DT---det-----<br />------->1---CD---prep_in-----<br />------->adjunct---NN---conj_and-----<br />------------->an---DT---det-----<br />------------->2---CD---prep_in-----<br />------------------->3---CD---conj_and-----<br />------------->3---CD---prep_in-----<br />'
p584
sg16
S'Adjuncts are optional arguments which, like adverbs, modify the meaning of the described event in a predictable or predicate-independent manner. Consider the following examples:  '
p585
sg18
F0.005569316727695693
saa(lp586
S'P10-1024-203'
p587
a(dp588
g5
F-1.0671766
sg6
S'-1 1:0.0559408031338 2:0.0 3:0.0219814958908'
p589
sg8
S'In order to avoid tuning a parameter for each of the measures, we set the threshold as the median value of this measure in the test set.'
p590
sg10
S'That is, we find the threshold which tags half of the arguments as cores and half as adjuncts. This relies on the prior knowledge that prepositional arguments are roughly equally divided between cores and adjuncts7.  '
p591
sg12
S'-1'
p592
sg14
S'->set---VBD---root-----         0.0559408031338<br />------->avoid---VB---advcl-----<br />------------->In---IN---mark-----<br />------------->order---NN---dep-----<br />------------->to---TO---aux-----<br />------------->tuning---VBG---xcomp-----<br />------------------->parameter---NN---dobj-----<br />------------------------->a---DT---det-----<br />------------------->each---DT---prep_for-----<br />------------------------->measures---NNS---prep_of-----<br />------------------------------->the---DT---det-----<br />------->we---PRP---nsubj-----         0.0<br />------->threshold---NN---dobj-----0.0219814958908         0.0219814958908<br />------------->the---DT---det-----<br />------->value---NN---prep_as-----<br />------------->the---DT---det-----<br />------------->median---JJ---amod-----<br />------------->measure---NN---prep_of-----<br />------------------->this---DT---det-----<br />------->set---NN---prep_in-----<br />------------->the---DT---det-----<br />------------->test---NN---nn-----<br />'
p593
sg16
S'Thresholding. In order to turn these measures into classifiers, we set a threshold below which arguments are marked as adjuncts and above which as cores. '
p594
sg18
F0.005420468336813948
saa(lp595
S'P10-1024-200'
p596
a(dp597
g5
F-0.88423588
sg6
S'-1 1:0.0425628779471 2:0.0578152320838 3:0.0'
p598
sg8
S'Again, the AS of the whole argument is defined to be the arithmetic mean of the measure over all of its head words.'
p599
sg10
S'Thresholding. In order to turn these measures into classifiers, we set a threshold below which arguments are marked as adjuncts and above which as cores. '
p600
sg12
S'-1'
p601
sg14
S'->defined---VBN---root-----         0.0425628779471<br />------->Again---RB---advmod-----<br />------->AS---NNP---nsubjpass-----         0.0578152320838<br />------------->the---DT---det-----<br />------------->argument---NN---prep_of-----0.106837865811<br />------------------->the---DT---det-----<br />------------------->whole---JJ---amod-----0.00879259835633<br />------->is---VBZ---auxpass-----<br />------->mean---NN---xcomp-----<br />------------->AS---NNP---xsubj-----<br />------------->to---TO---aux-----<br />------------->be---VB---cop-----<br />------------->the---DT---det-----<br />------------->arithmetic---NN---nn-----<br />------------->measure---NN---prep_of-----<br />------------------->the---DT---det-----<br />------------------->all---DT---prep_over-----<br />------------------------->words---NNS---prep_of-----<br />------------------------------->its---PRP$---poss-----<br />------------------------------->head---NN---nn-----<br />'
p602
sg16
S'We then use6:  We select the head words of the argument as we did with the selectional preference measure. '
p603
sg18
F0.0052074471965326274
saa(lp604
S'P10-1024-180'
p605
a(dp606
g5
F-1.0224051
sg6
S'+1 1:0.0425628779471 2:0.0430952420243 3:0.0'
p607
sg8
S'The selectional preference of the whole argument is then defined to be the arithmetic mean of this measure over all of its head words.'
p608
sg10
S'If the argument has no head words under this definition or if none of the head words appeared in the training corpus, the selectional preference is undefined. Predicate-Slot Collocation. '
p609
sg12
S'+1'
p610
sg14
S'->defined---VBN---root-----         0.0425628779471<br />------->preference---NN---nsubjpass-----0.0319221584604         0.0430952420243<br />------------->The---DT---det-----<br />------------->selectional---JJ---amod-----0.0248283454692<br />------------->argument---NN---prep_of-----0.106837865811<br />------------------->the---DT---det-----<br />------------------->whole---JJ---amod-----0.00879259835633<br />------->is---VBZ---auxpass-----<br />------->then---RB---advmod-----<br />------->mean---NN---xcomp-----<br />------------->preference---NN---xsubj-----<br />------------->to---TO---aux-----<br />------------->be---VB---cop-----<br />------------->the---DT---det-----<br />------------->arithmetic---NN---nn-----<br />------------->measure---NN---prep_of-----<br />------------------->this---DT---det-----<br />------------------->all---DT---prep_over-----<br />------------------------->words---NNS---prep_of-----<br />------------------------------->its---PRP$---poss-----<br />------------------------------->head---NN---nn-----<br />'
p611
sg16
S'Instead, only those appearing in the top level (depth = 1) of the argument under its unsupervised parse tree are taken. In case there are no such open class words, we take those appearing in depth 2. '
p612
sg18
F0.0050437090405122354
saa(lp613
S'P10-1024-173'
p614
a(dp615
g5
F-1.065722
sg6
S'+1 1:0.0353310335582 2:0.0279101615171 3:0.0294425279652'
p616
sg8
S'The similarity measure we use is based on the slot distributions of the arguments.'
p617
sg10
S'That is, two arguments are considered similar if they tend to appear in the same slots. Each head word h is assigned a vector where each coordinate corresponds to a slot s. The value of the coordinate is the number of times h appeared in s, i.e. Ep\xe2\x80\xb2N(p\xe2\x80\xb2, s, h) (p\xe2\x80\xb2 is summed over all predicates). '
p618
sg12
S'+1'
p619
sg14
S'->based---VBN---root-----         0.0353310335582<br />------->measure---NN---nsubjpass-----0.0294425279652         0.0279101615171<br />------------->The---DT---det-----<br />------------->similarity---NN---nn-----0.0131888975345<br />------------->use---VBP---rcmod-----0.0395666926035<br />------------------->measure---NN---dobj-----0.02944252796520.0294425279652         0.0294425279652<br />------------------->we---PRP---nsubj-----<br />------->is---VBZ---auxpass-----<br />------->distributions---NNS---prep_on-----<br />------------->the---DT---det-----<br />------------->slot---NN---nn-----<br />------------->arguments---NNS---prep_of-----<br />------------------->the---DT---det-----<br />'
p620
sg16
S'Their average length in the test set is 5.1 words. This is a natural extension of the naive (and sparse) maximum likelihood estimator Pr(h|p, s), which is obtained by taking sim(h, h\xe2\x80\xb2) to be 1 if h = h\xe2\x80\xb2 and 0 otherwise. '
p621
sg18
F0.004865102707902403
saa(lp622
S'P10-1024-152'
p623
a(dp624
g5
F-1.8806151
sg6
S'-1 1:0.00354690649559 2:0.0 3:0.0206532942965'
p625
sg8
S'In this section we present the three types of measures used by the algorithm and the rationale behind each of them.'
p626
sg10
S'These measures are all based on the PSH joint distribution. Given a (predicate, prepositional argument) pair from the test set, we first tag and parse the argument using the unsupervised tools above5. '
p627
sg12
S'-1'
p628
sg14
S'->present---VBP---root-----         0.00354690649559<br />------->section---NN---prep_in-----<br />------------->this---DT---det-----<br />------->we---PRP---nsubj-----         0.0<br />------->types---NNS---dobj-----0.0106407194868         0.0206532942965<br />------------->the---DT---det-----<br />------------->three---CD---num-----0.0148607896271<br />------------->measures---NNS---prep_of-----0.0346751757966<br />------------------->used---VBN---partmod-----0.0500522975408<br />------------------------->algorithm---NN---agent-----0.0167588809116<br />------------------------------->the---DT---det-----<br />------------------------------->rationale---NN---conj_and-----0.00879259835633<br />------------------------------------->the---DT---det-----<br />------------------------->rationale---NN---agent-----0.00879259835633<br />------------------------->each---DT---prep_behind-----<br />------------------------------->them---PRP---prep_of-----<br />'
p629
sg16
S'In case an argument has several head words, each of them is considered as an independent sample. We denote the number of times that a triplet occurred in the training corpus by N(p, s, h).  '
p630
sg18
F0.004772048784179539
saa(lp631
S'P10-1024-194'
p632
a(dp633
g5
F-1.0333564
sg6
S'-1 1:0.00709381299119 2:0.0696123232865 3:0.0428240063229'
p634
sg8
S'In this case, the argument and the preposition can be viewed as forming a unit on their own, independent of the predicate with which they appear.'
p635
sg10
S'We therefore expect such arguments to be adjuncts. We formalize this notion using the following measure. '
p636
sg12
S'-1'
p637
sg14
S'->viewed---VBN---root-----         0.00709381299119<br />------->case---NN---prep_in-----<br />------------->this---DT---det-----<br />------->argument---NN---nsubjpass-----0.106837865811         0.0696123232865<br />------------->the---DT---det-----<br />------------->preposition---NN---conj_and-----0.0323867807617<br />------------------->the---DT---det-----<br />------->preposition---NN---nsubjpass-----<br />------->can---MD---aux-----<br />------->be---VB---auxpass-----<br />------->forming---VBG---prepc_as-----<br />------------->unit---NN---dobj-----<br />------------------->a---DT---det-----<br />------------->own---JJ---prep_on-----<br />------------------->their---PRP$---poss-----<br />------->independent---JJ---dobj-----0.00709381299119         0.0428240063229<br />------------->predicate---NN---prep_of-----0.0767807464068<br />------------------->the---DT---det-----<br />------------------->appear---VBP---rcmod-----0.0106407194868<br />------------------------->predicate---NN---prep_with-----0.0767807464068<br />------------------------->they---PRP---nsubj-----<br />'
p638
sg16
S'Adjuncts tend to belong to one of a few specific semantic domains (see Section 2). Therefore, if an argument tends to appear in a certain slot in many of its instances, it is an indication that this argument tends to have a consistent semantic flavor in most of its instances. '
p639
sg18
F0.004741435676223328
saa(lp640
S'P07-3014-1'
p641
a(dp642
g5
F0.95991412
sg6
S'+1 1:0.0720420104188 2:0.0947265861909 3:0.160243692097'
p643
sg8
S'The attributes used as input to the learning algorithms are the web frequencies for phrases containing the modifier, noun, and a prepositional joining term.'
p644
sg10
S"We compare and evaluate different algorithms and different joining phrases on Nastase and Szpakowicz's (2003) dataset of 600 modifier-noun compounds. We find that by using a Support Vector Machine classifier we can obtain better performance on this dataset than a current state-of-the-art system; even with a relatively small set of prepositional joining terms.  "
p645
sg12
S'+1'
p646
sg14
S'->used---VBD---root-----         0.0720420104188<br />------->attributes---NNS---nsubj-----0.0947265861909         0.0947265861909<br />------------->The---DT---det-----<br />------->frequencies---NNS---advcl-----<br />------------->as---IN---mark-----<br />------------->input---NN---nsubj-----<br />------------------->algorithms---NNS---prep_to-----<br />------------------------->the---DT---det-----<br />------------------------->learning---NN---nn-----<br />------------->are---VBP---cop-----<br />------------->the---DT---det-----<br />------------->web---NN---nn-----<br />------------->phrases---NNS---prep_for-----<br />------------------->containing---VBG---partmod-----<br />------------------------->modifier---NN---dobj-----0.190253204913         0.160243692097<br />------------------------------->the---DT---det-----<br />------------------------------->noun---NN---conj_and-----0.190253204913<br />------------------------------->prepositional---NN---conj_and-----0.189453172382<br />------------------------------------->a---DT---det-----<br />------------------------------------->joining---VBG---partmod-----0.167841143307<br />------------------------------------------->term---NN---dobj-----0.0634177349709<br />------------------------->noun---NN---dobj-----<br />------------------------->prepositional---NN---dobj-----<br />'
p647
sg16
S'This paper investigates the use of machine learning algorithms to label modifier-noun compounds with a semantic relation. '
p648
sg18
F0.010675771669434501
saa(lp649
S'P07-3014-17'
p650
a(dp651
g5
F1.7084906
sg6
S'+1 1:0.183378045708 2:0.0526487303693 3:0.0924433636085'
p652
sg8
S'The motivation for this paper is to discover which joining terms are good predictors of a semantic relation, and which learning algorithms perform best at the task of mapping from joining terms to semantic relations for modifier-noun compounds. '
p653
sg10
S'Choosing a set of joining terms in a principled manner in the hope of capturing the semantic relation between constituents in the noun phrase is difficult, but there is certainly some correlation between a prepositional term or short linking verb and a semantic relation. For example, the preposition &quot;during&quot; indicates a temporal relation, while the preposition &quot;in&quot; indicates a locative relation, either temporal or spatial. '
p654
sg12
S'+1'
p655
sg14
S'->is---VBZ---root-----         0.183378045708<br />------->motivation---NN---nsubj-----0.0457786297206         0.0526487303693<br />------------->The---DT---det-----<br />------------->paper---NN---prep_for-----0.0595188310179<br />------------------->this---DT---det-----<br />------->discover---VB---xcomp-----<br />------------->motivation---NN---xsubj-----<br />------------->to---TO---aux-----<br />------------->joining---VBG---dep-----<br />------------------->which---WDT---nsubj-----<br />------------------->predictors---NNS---ccomp-----<br />------------------------->terms---NNS---nsubj-----<br />------------------------->are---VBP---cop-----<br />------------------------->good---JJ---amod-----<br />------------------------->relation---NN---prep_of-----<br />------------------------------->a---DT---det-----<br />------------------------------->semantic---JJ---amod-----<br />------------------->learning---VBG---conj_and-----<br />------------------------->which---WDT---nsubj-----<br />------------------------->perform---VB---ccomp-----<br />------------------------------->algorithms---NNS---nsubj-----<br />------------------------------->best---RBS---advmod-----<br />------------------------------->task---NN---prep_at-----<br />------------------------------------->the---DT---det-----<br />------------------------------------->mapping---VBG---prepc_of-----<br />------------------------------------------->joining---VBG---prepc_from-----<br />------------------------------------------------->terms---NNS---dobj-----0.0924433636085         0.0924433636085<br />------------------------------------------------->relations---NNS---prep_to-----<br />------------------------------------------------------->semantic---JJ---amod-----<br />------------------------------------------------------->compounds---NNS---prep_for-----<br />------------------------------------------------------------->modifier-noun---JJ---amod-----<br />------------->learning---VBG---dep-----<br />'
p656
sg16
S'This is the approach we use in our experiments. We choose two sets of joining terms, based on the frequency with which they occur in between nouns in the British National Cor '
p657
sg18
F0.010526874696614808
saa(lp658
S'P07-3014-24'
p659
a(dp660
g5
F-0.10392857
sg6
S'+1 1:0.0915572594412 2:0.0 3:0.0797278627553'
p661
sg8
S'We are also interested in comparing the performance of machine learning algorithms on the task of mapping from n-gram frequencies of joining terms to semantic relations.'
p662
sg10
S'For the experiments we use Weka, (Witten and Frank, 1999) a machine learning toolkit which allows for fast experimentation with many standard learning algorithms. In Section 5 we present the results obtained using the nearestneighbor, neural network (i.e. multi-layer perceptron) and SVM. '
p663
sg12
S'+1'
p664
sg14
S'->interested---JJ---root-----         0.0915572594412<br />------->We---PRP---nsubj-----         0.0<br />------->are---VBP---cop-----<br />------->also---RB---advmod-----<br />------->comparing---VBG---prepc_in-----<br />------------->performance---NN---dobj-----0.0391300551138         0.0797278627553<br />------------------->the---DT---det-----<br />------------------->algorithms---NNS---prep_of-----0.0785905910175<br />------------------------->machine---NN---nn-----0.052393727345<br />------------------------->learning---NN---nn-----0.148797077545<br />------------->task---NN---prep_on-----<br />------------------->the---DT---det-----<br />------------------->mapping---NN---prep_of-----<br />------------->frequencies---NNS---prep_from-----<br />------------------->n-gram---JJ---amod-----<br />------------------->joining---VBG---prepc_of-----<br />------------------------->terms---NNS---dobj-----<br />------------------------->relations---NNS---prep_to-----<br />------------------------------->semantic---JJ---amod-----<br />'
p665
sg16
S'If this is true, we would expect that very frequent prepositions, such as &quot;of&quot;, would have many possible meanings and therefore not reliably predict a semantic relation. However, less frequent prepositions, such as &quot;while&quot; would have a more limited set of senses and therefore accurately predict a semantic relation.  '
p666
sg18
F0.009912699454019212
saa(lp667
S'P07-3014-92'
p668
a(dp669
g5
F-0.9799928
sg6
S'-1 1:0.0151081938351 2:0.0467873636724 3:0.0616356232624'
p670
sg8
S'For the first condition, the attributes used by the learning algorithms consisted of vectors of web hits obtained using the 14 most frequent joining terms found in the BNC.'
p671
sg10
S'The next condition used a vector of web hits obtained using the joining terms that occurred  with which they occurred between two nouns in the BNC. '
p672
sg12
S'-1'
p673
sg14
S'->consisted---VBD---root-----         0.0151081938351<br />------->condition---NN---prep_for-----<br />------------->the---DT---det-----<br />------------->first---JJ---amod-----<br />------->attributes---NNS---nsubj-----0.0107197151416         0.0467873636724<br />------------->the---DT---det-----<br />------------->used---VBN---partmod-----0.11413667539<br />------------------->algorithms---NNS---agent-----0.0215299658043<br />------------------------->the---DT---det-----<br />------------------------->learning---NN---nn-----0.0407630983536<br />------->vectors---NNS---prep_of-----<br />------------->hits---NNS---prep_of-----<br />------------------->web---NN---nn-----<br />------------------->obtained---VBN---partmod-----<br />------------------------->using---VBG---xcomp-----<br />------------------------------->terms---NNS---dobj-----0.0949685467221         0.0616356232624<br />------------------------------------->the---DT---det-----<br />------------------------------------->14---CD---num-----0.0376232950926<br />------------------------------------->most---JJS---amod-----<br />------------------------------------->frequent---JJ---amod-----0.0326104786829<br />------------------------------------->joining---JJ---amod-----0.113962256066<br />------------------------------------->found---VBN---partmod-----0.0302163876702<br />------------------------------------------->BNC---NNP---prep_in-----0.0604327753404<br />------------------------------------------------->the---DT---det-----<br />'
p674
sg16
S'We excluded determiners on the basis that the presence of a determiner does not affect the semantic properties of the interaction between the head and modifier.  There were three conditions experimented with using three different algorithms. '
p675
sg18
F0.009840145296211652
saa(lp676
S'P07-3014-61'
p677
a(dp678
g5
F-0.91561597
sg6
S'-1 1:0.0453245815053 2:0.0 3:0.0637875456714'
p679
sg8
S'We did not collect queries of the form &quot;modifier joining term head&quot;; in the majority of paraphrases of noun phrases the head noun occurs before the modifying word.'
p680
sg10
S'As well as trying to achieve reasonable accuracy, we were interested in discovering what kinds of joining phrases are most useful when trying to predict the semantic relation, and which machine learning algorithms perform best at the task of using vectors of web-based n-gram frequencies to predict the semantic relation. For our experiments we used the set of 600 labeled noun-modifier pairs of Nastase and Szpakowicz (2003). '
p681
sg12
S'-1'
p682
sg14
S'->collect---VB---root-----         0.0453245815053<br />------->We---PRP---nsubj-----         0.0<br />------->did---VBD---aux-----<br />------->not---RB---neg-----<br />------->queries---NNS---dobj-----0.100328786914         0.0637875456714<br />------------->form---NN---prep_of-----0.0250821967284<br />------------------->the---DT---det-----<br />------------------->joining---VBG---dep-----0.113962256066<br />------------------------->modifier---NN---nsubj-----0.0574132421447<br />------------------------->head---NN---dobj-----0.0428788605665<br />------------------------------->term---NN---nn-----0.0430599316086<br />------->occurs---VBZ---parataxis-----<br />------------->majority---NN---prep_in-----<br />------------------->the---DT---det-----<br />------------------->paraphrases---NNS---prep_of-----<br />------------------------->phrases---NNS---prep_of-----<br />------------------------------->noun---NN---nn-----<br />------------->noun---NN---nsubj-----<br />------------------->the---DT---det-----<br />------------------->head---NN---nn-----<br />------------->word---NN---prep_before-----<br />------------------->the---DT---det-----<br />------------------->modifying---VBG---amod-----<br />'
p683
sg16
S'The method described in this paper is similar to the work presented in Turney and Littman (2005). We collect web frequencies for queries of the form &quot;head joining term modifier&quot;. '
p684
sg18
F0.00959055087929893
saa(lp685
S'P07-3014-121'
p686
a(dp687
g5
F-1.2089682
sg6
S'+1 1:0.0450533827828 2:0.0 3:0.0250523356423'
p688
sg8
S'Firstly, we wanted to compare the performance of different machine learning algorithms on the task of mapping from a vector of web frequencies of paraphrases containing joining terms to semantic relations.'
p689
sg10
S'Secondly, we wanted to discover whether the frequency of joining terms was related to their effectiveness at predicting a semantic relation.  The results suggest that the nearest neighbor approach is not the most effective algorithm for the classification task. '
p690
sg12
S'+1'
p691
sg14
S'->wanted---VBD---root-----         0.0450533827828<br />------->Firstly---RB---advmod-----<br />------->we---PRP---nsubj-----         0.0<br />------->compare---VB---xcomp-----<br />------------->we---PRP---xsubj-----<br />------------->to---TO---aux-----<br />------------->performance---NN---dobj-----0.0385101380734         0.0250523356423<br />------------------->the---DT---det-----<br />------------------->algorithms---NNS---prep_of-----0.025781840434<br />------------------------->different---JJ---amod-----0.0334348031764<br />------------------------->machine---NN---nn-----0.012890920217<br />------------------------->learning---NN---nn-----0.0146439763106<br />------------->task---NN---prep_on-----<br />------------------->the---DT---det-----<br />------------------->mapping---VBG---prepc_of-----<br />------------------------->vector---NN---prep_from-----<br />------------------------------->a---DT---det-----<br />------------------------------->frequencies---NNS---prep_of-----<br />------------------------------------->web---NN---nn-----<br />------------------------------------->paraphrases---NNS---prep_of-----<br />------------------------------------------->containing---VBG---partmod-----<br />------------------------------------------------->joining---VBG---partmod-----<br />------------------------------------------------------->terms---NNS---dobj-----<br />------------------------------------------------------->relations---NNS---prep_to-----<br />------------------------------------------------------------->semantic---JJ---amod-----<br />'
p692
sg16
S'The SVM consistently outperformed the baseline; neither of the other algorithms did so.  Our motivation in this paper was twofold. '
p693
sg18
F0.009565306807450477
saa(lp694
S'P07-3014-81'
p695
a(dp696
g5
F-1.3348718
sg6
S'-1 1:0.0151081938351 2:0.0214394302832 3:0.0438200047713'
p697
sg8
S'Possibly the most difficult problem with this method is deciding on a set of joining terms which is likely to provide enough information about the noun-modifier pairs to allow a learning algorithm to predict the semantic relation.'
p698
sg10
S'Turney and Littman (2005) use a large and varied set of joining terms. They include the most common prepositions, conjunctions and simple verbs like &quot;has&quot;, &quot;goes &quot; and &quot;is&quot;. '
p699
sg12
S'-1'
p700
sg14
S'->deciding---VBG---root-----         0.0151081938351<br />------->Possibly---RB---advmod-----<br />------->problem---NN---nsubj-----0.0107197151416         0.0214394302832<br />------------->the---DT---det-----<br />------------->difficult---JJ---amod-----0.0107197151416<br />------------------->most---RBS---advmod-----<br />------------->method---NN---prep_with-----0.0428788605665<br />------------------->this---DT---det-----<br />------->is---VBZ---aux-----<br />------->set---NN---prep_on-----<br />------------->a---DT---det-----<br />------------->joining---VBG---prepc_of-----<br />------------------->terms---NNS---dobj-----0.0949685467221         0.0438200047713<br />------------------------->likely---JJ---rcmod-----0.00930694055637<br />------------------------------->terms---NNS---nsubj-----0.0949685467221<br />------------------------------->is---VBZ---cop-----<br />------------------------------->provide---VB---xcomp-----0.0151081938351<br />------------------------------------->terms---NNS---xsubj-----0.0949685467221<br />------------------------------------->to---TO---aux-----<br />------------------------------------->information---NN---dobj-----0.0107197151416<br />------------------------------------------->enough---JJ---amod-----0.0107197151416<br />------------------------------------------->pairs---NNS---prep_about-----0.0376232950926<br />------------------------------------------------->the---DT---det-----<br />------------------------------------------------->noun-modifier---JJ---amod-----0.0538249145107<br />------------------------------------->allow---VB---xcomp-----0.0125410983642<br />------------------------------------------->to---TO---aux-----<br />------------------------------------------->algorithm---NN---dobj-----0.0652209573658<br />------------------------------------------------->a---DT---det-----<br />------------------------------------------------->learning---NN---nn-----0.0407630983536<br />------------------------------------------->predict---VB---xcomp-----0.0376232950926<br />------------------------------------------------->to---TO---aux-----<br />------------------------------------------------->relation---NN---dobj-----0.0358832763405<br />------------------------------------------------------->the---DT---det-----<br />------------------------------------------------------->semantic---JJ---amod-----0.0430599316086<br />'
p701
sg16
S'The idea is that these sensible paraphrases will return more hits than nonsense ones, such as: &quot;invention has student&quot; OR &quot;invention has a student&quot; OR &quot;invention has the student&quot; It would be possible to construct a set of handcoded rules to map from joining terms to semantic relations; for example &quot;during&quot; maps to temporal, &quot;by&quot; maps to causal and so on. However, we hope that the classifiers will be able to identify combinations of prepositions that indicate a relation.  '
p702
sg18
F0.009557936737661822
saatp703
Rp704
.