ccollections
OrderedDict
p0
((lp1
(lp2
S'N06-1031-116'
p3
a(dp4
S'sentence'
p5
S'In fact, the most popular parent for the NP-C her is VP, while the most popular parent for she is S. Rule (1) is relabeled as the NP-C\xcb\x86S rule \xc2\xae and her is expressed as the NPC\xcb\x86VP rule Q. Only rule (E) can partner with rule & which produces the correct output deeply love her.'
p6
sS'contextpos'
p7
S'We tested three variants of parent annotation (PARENT): (1) all nonterminals are parentannotated, (2) only S nodes are parent-annotated, and (3) all nonterminals are parent- and grandparentannotated (the annotation of a node\xe2\x80\x99s parent\xe2\x80\x99s parent). The first and third variants yielded the largest ruleset sizes of all relabeling methods. '
p8
sS'depparse'
p9
S'0->relabeled-VBN-root             0.0583531326987<BR>  1->fact-NN-prep_in    <BR>  1->parent-NN-nsubjpass    0.151217370476         0.0747889707377<BR>    2->the-DT-det    <BR>    2->popular-JJ-amod    0.0266854183193<BR>      3->most-RBS-advmod    <BR>    2->NP-C-NN-prep_for    0.0692943450797<BR>      3->the-DT-det    <BR>      3->VP-NNP-rcmod    0.0583531326987<BR>        4->her-PRP-nsubj    <BR>        4->is-VBZ-cop    <BR>        4->Rule-NNP-dep    0.189647681271<BR>          5->while-IN-mark    <BR>          5->parent-NN-nsubj    0.151217370476<BR>            6->the-DT-det    <BR>            6->popular-JJ-amod    0.0266854183193<BR>              7->most-RBS-advmod    <BR>            6->she-PRP-prep_for    <BR>          5->is-VBZ-cop    <BR>          5->S.-NNP-nn    0.0<BR>          5->1-CD-appos    0.0<BR>  1->is-VBZ-auxpass    <BR>  1->\xc2\xae-NN-prep_as    <BR>    2->the-DT-det    <BR>    2->NP-C\xcb\x86S-NNP-nn    <BR>    2->rule-NN-nn    <BR>  1->expressed-VBN-conj_and    <BR>    2->her-PRP-nsubjpass    <BR>    2->is-VBZ-auxpass    <BR>    2->Q.-VBD-advcl    <BR>      3->as-IN-mark    <BR>      3->rule-NN-nsubj    <BR>        4->the-DT-det    <BR>        4->NPC\xcb\x86VP-NNP-nn    <BR>      3->partner-NN-ccomp    <BR>        4->rule-NN-nsubj    <BR>          5->Only-RB-advmod    <BR>          5->E-NNP-appos    <BR>        4->can-MD-aux    <BR>        4->rule-CD-prep_with    <BR>          5->&-CC-cc    <BR>          5->produces-VBZ-rcmod    <BR>            6->rule-CD-nsubj    <BR>            6->love-VBP-ccomp    <BR>              7->output-NN-nsubj    <BR>                8->the-DT-det    <BR>                8->correct-JJ-amod    <BR>              7->deeply-RB-advmod    <BR>              7->her-PRP-dobj             0.0<BR>'
p10
sS'svm-val'
p11
F-0.32190517
sS'contextpre'
p12
S'In Figure 8, rule \xc2\xae is relabeled as rule \xc2\xae and expects an NP-C\xcb\x86VP, i.e., an NP-C with a VP parent. In the PTB, we observe that the NP-C she never has a VP parent, while her does. '
p13
sS'textrank'
p14
F0.011235246851544761
saa(lp15
S'N06-1031-104'
p16
a(dp17
g5
S'The object NP-C her, on the other hand, is frequently rightmost in a constituent, which is reflected in the NP-C#L rule (F).'
p18
sg7
S'Using this rule with rule \xc2\xae gives the desired result deeply love her. We experimented with four sisterhood annotation (SISTERHOOD) variants of decreasing complexity. '
p19
sg9
S'0->NP-C-VBD-root             0.0692943450797<BR>  1->object-NN-nsubj    0.0177902788795         0.0177902788795<BR>    2->The-DT-det    <BR>  1->rightmost-JJ-ccomp    <BR>    2->her-PRP-nsubj    <BR>    2->hand-NN-prep_on    <BR>      3->the-DT-det    <BR>      3->other-JJ-amod    <BR>    2->is-VBZ-cop    <BR>    2->frequently-RB-advmod    <BR>    2->constituent-NN-prep_in    <BR>      3->a-DT-det    <BR>      3->reflected-VBN-rcmod    <BR>        4->constituent-NN-nsubjpass    <BR>        4->is-VBZ-auxpass    <BR>        4->rule-NN-prep_in    <BR>          5->the-DT-det    <BR>          5->NP-C-JJ-amod    <BR>          5->#L-JJ-amod    <BR>          5->F-NNP-appos    <BR>'
p20
sg11
F-0.24817248
sg12
S'Since she never occurs in this position in the PTB, it should never be sisterhood-annotated as an NP-C#L. It does occur with sisters to the right, which gives the NP-C#R rule \xc2\xae. '
p21
sg14
F0.009934883147155658
saa(lp22
S'N06-1031-114'
p23
a(dp24
g5
S'In Figure 8, rule \xc2\xae is relabeled as rule \xc2\xae and expects an NP-C\xcb\x86VP, i.e., an NP-C with a VP parent.'
p25
sg7
S'In the PTB, we observe that the NP-C she never has a VP parent, while her does. In fact, the most popular parent for the NP-C her is VP, while the most popular parent for she is S. Rule (1) is relabeled as the NP-C\xcb\x86S rule \xc2\xae and her is expressed as the NPC\xcb\x86VP rule Q. Only rule (E) can partner with rule & which produces the correct output deeply love her. '
p26
sg9
S'0->relabeled-VBN-root             0.0583531326987<BR>  1->Figure-NNP-prep_in    <BR>    2->8-CD-num    <BR>  1->\xc2\xae-NNS-nsubjpass    0.0         0.0948238406354<BR>    2->rule-NN-nn    0.189647681271<BR>  1->is-VBZ-auxpass    <BR>  1->\xc2\xae-NNS-prep_as    <BR>    2->rule-NN-nn    <BR>    2->expects-VBZ-conj_and    <BR>      3->NP-C\xcb\x86VP-NN-dobj    0.0692943450797         0.0692943450797<BR>        4->an-DT-det    <BR>      3->i.e.-FW-dep    <BR>      3->an-DT-parataxis    <BR>        4->NP-C-VBG-amod    <BR>        4->parent-NN-prep_with    <BR>          5->a-DT-det    <BR>          5->VP-NNP-nn    <BR>  1->expects-VBZ-prep_as    <BR>'
p27
sg11
F0.24182524
sg12
S'It seemed likely that such contextual information could also benefit MT. Let us tackle the bad output from Figure 6 with parent annotation. '
p28
sg14
F0.009912183252197527
saa(lp29
S'N06-1031-16'
p30
a(dp31
g5
S'In this paper, we argue that the overly-general tagset of the PTB is problematic for MT because it fails to capture important grammatical distinctions that are critical in translation.'
p32
sg7
S'As a solution, we propose methods of relabeling the syntax trees that effectively improve translation quality. Consider the derivation in Figure 2. '
p33
sg9
S'0->argue-VBP-root             0.0361772904638<BR>  1->paper-NN-prep_in    <BR>    2->this-DT-det    <BR>  1->we-PRP-nsubj             0.0<BR>  1->problematic-JJ-ccomp    <BR>    2->that-IN-mark    <BR>    2->tagset-NN-nsubj    <BR>      3->the-DT-det    <BR>      3->overly-general-JJ-amod    <BR>      3->PTB-NNP-prep_of    <BR>        4->the-DT-det    <BR>    2->is-VBZ-cop    <BR>    2->MT-NNP-prep_for    <BR>    2->fails-VBZ-advcl    <BR>      3->because-IN-mark    <BR>      3->it-PRP-nsubj    <BR>      3->capture-VB-xcomp    <BR>        4->it-PRP-xsubj    <BR>        4->to-TO-aux    <BR>        4->distinctions-NNS-dobj    0.0296658957036         0.0555087226383<BR>          5->important-JJ-amod    0.0361772904638<BR>          5->grammatical-JJ-amod    0.0296658957036<BR>          5->critical-JJ-rcmod    0.0361772904638<BR>            6->distinctions-NNS-nsubj    0.0296658957036<BR>            6->are-VBP-cop    <BR>            6->translation-NN-prep_in    0.171700067791<BR>'
p34
sg11
F-0.80309067
sg12
S'The Penn English Treebank (PTB) (Marcus et al., 1993) is our source of syntactic information, largely due to the availability of reliable parsers. It is not clear, however, whether this resource is suitable, as is, for the task of MT. '
p35
sg14
F0.009901275536697441
saa(lp36
S'N06-1031-68'
p37
a(dp38
g5
S'The third type was auxiliary lexicalization (LEX_AUX), in which all forms of the verb be are annotated with _be, and similarly with do and have.'
p39
sg7
S'The PTB purposely eliminated such distinctions; here we seek to recover them. However, auxiliaries and verbs function very differently and thus cannot be treated identically. '
p40
sg9
S'0->lexicalization-NN-root             0.0889513943976<BR>  1->type-NN-nsubj    0.0177902788795         0.0266854183193<BR>    2->The-DT-det    <BR>    2->third-JJ-amod    0.035580557759<BR>  1->was-VBD-cop    <BR>  1->auxiliary-JJ-amod    <BR>  1->LEX_AUX-NNP-appos    <BR>  1->be-VB-rcmod    <BR>    2->lexicalization-NN-prep_in    <BR>    2->forms-NNS-nsubj    <BR>      3->all-DT-det    <BR>      3->verb-NN-prep_of    <BR>        4->the-DT-det    <BR>    2->annotated-JJ-dep    <BR>      3->are-VBP-cop    <BR>      3->_-VBG-prepc_with    <BR>        4->be-VB-dep    <BR>      3->do-VBP-conj_and    <BR>        4->similarly-RB-advmod    <BR>        4->with-IN-mark    <BR>    2->do-VBP-dep    <BR>    2->have-VB-conj_and    <BR>      3->forms-NNS-nsubj    <BR>  1->have-VB-rcmod    <BR>'
p41
sg11
F0.31200187
sg12
S'Variant 1 included all the determiners mentioned above and variant 2 was restricted to the and a/an to focus only on articles. The second slightly improved on the first. '
p42
sg14
F0.009878775861675031
saa(lp43
S'N06-1031-21'
p44
a(dp45
g5
S'In the second problem, the VP-C tag fails to communicate that it is headed by the base verb (VB) demonstrate, which should prevent it from being used with the auxiliary VBZ has.'
p46
sg7
S'Information-poor tags like DT and VP-C can be relabeled to encourage more fluent translations, which is the thrust of this paper.  Section 2 describes our data and experimental procedure. '
p47
sg9
S'0->fails-VBZ-root             0.0723545809276<BR>  1->problem-NN-prep_in    <BR>    2->the-DT-det    <BR>    2->second-JJ-amod    <BR>  1->tag-NN-nsubj    0.0593317914073         0.0593317914073<BR>    2->the-DT-det    <BR>    2->VP-C-JJ-amod    0.0593317914073<BR>  1->communicate-VB-xcomp    <BR>    2->tag-NN-xsubj    <BR>    2->to-TO-aux    <BR>    2->headed-VBN-ccomp    <BR>      3->that-IN-mark    <BR>      3->it-PRP-nsubjpass    <BR>      3->is-VBZ-auxpass    <BR>      3->demonstrate-NNP-agent    <BR>        4->the-DT-det    <BR>        4->base-JJ-amod    <BR>        4->verb-NNP-nn    <BR>        4->VB-NNP-appos    <BR>        4->prevent-VB-rcmod    <BR>          5->demonstrate-NNP-nsubj    <BR>          5->should-MD-aux    <BR>          5->it-PRP-dobj             0.0<BR>          5->used-VBN-prepc_from    <BR>            6->being-VBG-auxpass    <BR>            6->VBZ-NN-prep_with    <BR>              7->the-DT-det    <BR>              7->auxiliary-JJ-amod    <BR>              7->has-VBZ-dep    <BR>'
p48
sg11
F-0.0048353598
sg12
S'The output translation has two salient errors: determiner/noun number disagreement (*this Turkish positions) and auxiliary/verb tense disagreement (*has demonstrate). The first problem arises because the DT tag, which does not distinguish between singular and plural determiners, allows singular this to be used with plural NNS positions. '
p49
sg14
F0.009774399329691826
saa(lp50
S'N06-1031-130'
p51
a(dp52
g5
S'Rule (g) is relabeled as the IN/PP-C rule 20\xef\xbf\xbd since PP-C is the most common complement for out (99% of the time).'
p53
sg7
S'Since rule 300\xef\xbf\xbd expects an IN/NP-C, rule 20 \xef\xbf\xbd is disqualified. The preposition from (rule 200\xef\xbf\xbd), on the other hand, frequently takes NP-C as complement (82% of the time). '
p54
sg9
S'0->relabeled-JJ-root             0.0583531326987<BR>  1->Rule-NNP-nsubj    0.189647681271         0.0948238406354<BR>    2->g-NN-appos    0.0<BR>  1->is-VBZ-cop    <BR>  1->rule-NN-prep_as    <BR>    2->the-DT-det    <BR>    2->IN/PP-C-JJ-amod    <BR>  1->20-CD-dep    <BR>  1->complement-NN-advcl    <BR>    2->since-IN-mark    <BR>    2->PP-C-NNP-nsubj    <BR>    2->is-VBZ-cop    <BR>    2->the-DT-det    <BR>    2->common-JJ-amod    <BR>      3->most-RBS-advmod    <BR>    2->for-IN-prep    <BR>      3->out-RB-pcomp    <BR>    2->%-NN-dep    <BR>      3->99-CD-num    <BR>      3->time-NN-prep_of    <BR>        4->the-DT-det    <BR>'
p55
sg11
F-0.24932733
sg12
S'A way to restrict this is to annotate the IN\xe2\x80\x99s complement. Complement-annotated versions of rules (2) and Q are given in Figure 10. '
p56
sg14
F0.009772183083537295
saa(lp57
S'W10-1919-49'
p58
a(dp59
g5
S'As part of the present study, we introduce annotation for gene/gene product (GGP) mentions (Section 3.2), and in the following discussion of applying an event extraction approach to the domain the availability of this class annotation as an additional category is assumed. '
p60
sg7
S'The event model involves two primary categories of representation: physical entities such as genes and proteins are elementary (non-structured) and their mentions annotated as typed spans of text,2 and events and processes (\xe2\x80\x9cthings that happen\xe2\x80\x9d) are represented using the structured event representation described in Section 2.1. This division applies straightforwardly to the T4SS annotations, suggesting an approach where bacteria and cell components retain their simple tagged-term representation and the biological processes and molecular functions are given an event representation. '
p61
sg9
S'0->introduce-VB-root             0.00484688401566<BR>  1->part-NN-prep_as    <BR>    2->study-NN-prep_of    <BR>      3->the-DT-det    <BR>      3->present-JJ-amod    <BR>  1->we-PRP-nsubj             0.0<BR>  1->annotation-NN-dobj    0.107118485547         0.107118485547<BR>  1->mentions-NNS-prep_for    <BR>    2->gene/gene-JJ-amod    <BR>    2->product-NN-nn    <BR>    2->GGP-NNP-appos    <BR>    2->Section-NN-appos    <BR>      3->3.2-CD-num    <BR>  1->assumed-VBN-conj_and    <BR>    2->discussion-NN-prep_in    <BR>      3->the-DT-det    <BR>      3->following-JJ-amod    <BR>      3->applying-VBG-prepc_of    <BR>        4->approach-NN-dobj    <BR>          5->an-DT-det    <BR>          5->event-NN-nn    <BR>          5->extraction-NN-nn    <BR>        4->domain-NN-prep_to    <BR>          5->the-DT-det    <BR>    2->availability-NN-nsubjpass    <BR>      3->the-DT-det    <BR>      3->annotation-NN-prep_of    <BR>        4->this-DT-det    <BR>        4->class-NN-nn    <BR>        4->category-NN-prep_as    <BR>          5->an-DT-det    <BR>          5->additional-JJ-amod    <BR>    2->is-VBZ-auxpass    <BR>'
p62
sg11
F-1.2697396
sg12
S'In addition to the four annotated types it was  recognized during the original T4SS corpus annotation that genes and gene products are centrally important for domain information needs, but their annotation was deferred to focus on novel categories. '
p63
sg14
F0.00965492358872806
saa(lp64
S'W10-1919-61'
p65
a(dp66
g5
S'As related types of statements are annotated as Localization events in the applied model, we propose to apply this event type and differentiate between the specific subtypes on the basis of the event arguments.'
p67
sg7
S'A further 39% are of categories that can be viewed as high-level processes. These are distinct from the events considered in the BioNLP\xe2\x80\x9909 shared task in involving coarsergrained events and larger-scale participants than the GGP entities considered in the task: for example, conjugation occurs between bacteria, and virulence may involve a human host. '
p68
sg9
S'0->propose-VBP-root             0.00782087101074<BR>  1->annotated-VBG-advcl    <BR>    2->As-IN-mark    <BR>    2->types-NNS-nsubj    <BR>      3->related-JJ-amod    <BR>      3->statements-NNS-prep_of    <BR>    2->are-VBP-aux    <BR>    2->events-NNS-prep_as    <BR>      3->Localization-JJ-amod    <BR>      3->model-NN-prep_in    <BR>        4->the-DT-det    <BR>        4->applied-JJ-amod    <BR>  1->we-PRP-nsubj             0.0<BR>  1->apply-VB-xcomp    <BR>    2->we-PRP-xsubj    <BR>    2->to-TO-aux    <BR>    2->type-NN-dobj    0.0351939195483         0.0763059328168<BR>      3->this-DT-det    <BR>      3->event-NN-nn    0.117417946085<BR>    2->differentiate-VB-conj_and    <BR>      3->subtypes-NNS-prep_between    <BR>        4->the-DT-det    <BR>        4->specific-JJ-amod    <BR>        4->basis-NN-prep_on    <BR>          5->the-DT-det    <BR>          5->arguments-NNS-prep_of    <BR>            6->the-DT-det    <BR>            6->event-NN-nn    <BR>  1->differentiate-VB-xcomp    <BR>'
p69
sg11
F-1.4111179
sg12
S'To identify general categories, we performed a manual analysis of the 217 unique normalized terms annotated in the corpus as biological processes (Table 4). We find that the majority of the instances (58%) relate to location or movement. '
p70
sg14
F0.009647179644814086
saa(lp71
S'W10-1919-3'
p72
a(dp73
g5
S'In this study, we propose an adaptation of the event extraction approach to a subdomain related to infectious diseases and present analysis and initial experiments on the feasibility of event extraction from domain full text publications. '
p74
sg7
S'For most of the previous decade, biomedical Information Extraction (IE) efforts have focused primarily on tasks that allow extracted information to be represented as simple pairs of related entities. This representation is applicable to many IE targets of interest, such as gene-disease associations (Chun et al., 2006) and protein-protein interactions (N\xc2\xb4edellec, 2005; Krallinger et al., 2007). '
p75
sg9
S'0->propose-VBP-root             0.0840349858117<BR>  1->study-NN-prep_in    <BR>    2->this-DT-det    <BR>  1->we-PRP-nsubj             0.0<BR>  1->adaptation-NN-dobj    0.0697566294146         0.193483584662<BR>    2->an-DT-det    <BR>    2->approach-NN-prep_of    0.117362951539<BR>      3->the-DT-det    <BR>      3->event-NN-nn    0.293407378847<BR>      3->extraction-NN-nn    0.293407378847<BR>  1->subdomain-NN-prep_to    <BR>    2->a-DT-det    <BR>    2->related-VBN-partmod    <BR>      3->diseases-NNS-prep_to    <BR>        4->infectious-JJ-amod    <BR>        4->analysis-NN-conj_and    <BR>          5->present-JJ-amod    <BR>          5->experiments-NNS-conj_and    <BR>            6->initial-JJ-amod    <BR>        4->experiments-NNS-conj_and    <BR>      3->analysis-NN-prep_to    <BR>      3->feasibility-NN-prep_on    <BR>        4->the-DT-det    <BR>        4->extraction-NN-prep_of    <BR>          5->event-NN-nn    <BR>      3->publications-NNS-prep_from    <BR>        4->domain-NN-nn    <BR>        4->full-JJ-amod    <BR>        4->text-NN-nn    <BR>'
p76
sg11
F1.3998558
sg12
S'However, event extraction efforts have so far been limited to publication abstracts, with most studies further considering only the specific transcription factor-related subdomain of molecular biology of the GENIA corpus. To establish the broader relevance of the event extraction approach and proposed methods, it is necessary to expand on these constraints. '
p77
sg14
F0.009505345582855882
saa(lp78
S'W10-1919-160'
p79
a(dp80
g5
S'We applied a previously introduced corpus of subdomain full texts annotated for mentions of bacteria and terms from the three top-level Gene Ontology subontologies as a reference defining domain information needs to study how these can be met through the application of events defined in the BioNLP\xe2\x80\x9909 Shared Task on event extraction.'
p81
sg7
S'Analysis indicated that with minor revision of the arguments, the Binding and Localization event types could account for the majority of both biological processes and molecular functions of interest. We further identified a category of \xe2\x80\x9chighlevel\xe2\x80\x9d biological processes such as the virulence process typical of the subdomain, which necessitated extension of the considered event extraction model. '
p82
sg9
S'0->applied-VBD-root             0.0398585347512<BR>  1->We-PRP-nsubj             0.0<BR>  1->needs-VBZ-ccomp    <BR>    2->corpus-NN-nsubj    <BR>      3->a-DT-det    <BR>      3->introduced-VBN-amod    <BR>        4->previously-RB-advmod    <BR>      3->texts-NNS-prep_of    <BR>        4->subdomain-JJ-amod    <BR>        4->full-JJ-amod    <BR>      3->annotated-VBN-partmod    <BR>        4->mentions-NNP-prep_for    <BR>          5->bacteria-NNS-prep_of    <BR>            6->terms-NNS-conj_and    <BR>          5->terms-NNS-prep_of    <BR>        4->subontologies-NNS-prep_from    <BR>          5->the-DT-det    <BR>          5->three-CD-num    <BR>          5->top-level-JJ-amod    <BR>          5->Gene-NNP-nn    <BR>          5->Ontology-NNP-nn    <BR>        4->information-NN-prep_as    <BR>          5->a-DT-det    <BR>          5->reference-NN-nn    <BR>          5->defining-NN-nn    <BR>          5->domain-NN-nn    <BR>    2->study-VB-xcomp    <BR>      3->corpus-NN-xsubj    <BR>      3->to-TO-aux    <BR>      3->met-VBN-ccomp    <BR>        4->how-WRB-advmod    <BR>        4->these-DT-nsubjpass    <BR>        4->can-MD-aux    <BR>        4->be-VB-auxpass    <BR>        4->application-NN-prep_through    <BR>          5->the-DT-det    <BR>          5->events-NNS-prep_of    <BR>            6->defined-VBN-partmod    <BR>              7->Task-NNP-prep_in    <BR>                8->the-DT-det    <BR>                8->BioNLP-NNP-nn    <BR>                8->\xe2\x80\x9909-NNP-nn    <BR>                8->Shared-NNP-nn    <BR>              7->extraction-NN-prep_on    <BR>                8->event-NN-nn    <BR>'
p83
sg11
F-1.1065364
sg12
S'As a demonstration of feasibility the result is encouraging for both the applicability of event extraction to this specific new domain and for the adaptability of the approach to new domains in general.  We have presented a study of the adaptation of an event extraction approach to the T4SS subdomain as a step toward the introduction of event extraction to the broader infectious diseases domain. '
p84
sg14
F0.009370169792172853
saa(lp85
S'W10-1919-91'
p86
a(dp87
g5
S'As gene and gene product entities are central to domain information needs and the core entities of the applied event extraction approach, we first introduced annotation for this entity class.'
p88
sg7
S'We created manual GGP annotation following the annotation guidelines of the GENIA GGP Corpus (Ohta et al., 2009). As this corpus was the source of the gene/protein entity annotation provided as the basis of the BioNLP shared task on event extraction, adopting its annotation criteria assures compatibility with recently introduced event extraction methods. '
p89
sg9
S'0->introduced-VBD-root             0.0194760882813<BR>  1->central-JJ-advcl    <BR>    2->As-IN-mark    <BR>    2->entities-NNS-nsubj    <BR>      3->gene-NN-nn    <BR>        4->gene-NN-conj_and    <BR>      3->gene-NN-nn    <BR>      3->product-NN-nn    <BR>    2->are-VBP-cop    <BR>    2->needs-NNS-prep_to    <BR>      3->domain-NN-nn    <BR>      3->information-NN-nn    <BR>      3->entities-NNS-conj_and    <BR>        4->the-DT-det    <BR>        4->core-JJ-amod    <BR>        4->approach-NN-prep_of    <BR>          5->the-DT-det    <BR>          5->applied-JJ-amod    <BR>          5->event-NN-nn    <BR>          5->extraction-NN-nn    <BR>    2->entities-NNS-prep_to    <BR>  1->we-PRP-nsubj             0.0<BR>  1->first-RB-advmod    <BR>  1->annotation-NN-dobj    0.107118485547         0.107118485547<BR>  1->class-NN-prep_for    <BR>    2->this-DT-det    <BR>    2->entity-NN-nn    <BR>'
p90
sg11
F-0.88057287
sg12
S'This selection produced a subcorpus of four full-text documents and 19 abstracts. The statistics for this corpus are shown in Table 8.  '
p91
sg14
F0.009180214854765114
saa(lp92
S'W10-1919-159'
p93
a(dp94
g5
S'We have presented a study of the adaptation of an event extraction approach to the T4SS subdomain as a step toward the introduction of event extraction to the broader infectious diseases domain.'
p95
sg7
S'We applied a previously introduced corpus of subdomain full texts annotated for mentions of bacteria and terms from the three top-level Gene Ontology subontologies as a reference defining domain information needs to study how these can be met through the application of events defined in the BioNLP\xe2\x80\x9909 Shared Task on event extraction. Analysis indicated that with minor revision of the arguments, the Binding and Localization event types could account for the majority of both biological processes and molecular functions of interest. '
p96
sg9
S'0->presented-VBN-root             0.0398585347512<BR>  1->We-PRP-nsubj             0.0<BR>  1->have-VBP-aux    <BR>  1->study-NN-dobj    0.0834994241487         0.0956832893078<BR>    2->a-DT-det    <BR>    2->adaptation-NN-prep_of    0.0330861844123<BR>      3->the-DT-det    <BR>      3->approach-NN-prep_of    0.0278331413829<BR>        4->an-DT-det    <BR>        4->event-NN-nn    0.166998848297<BR>        4->extraction-NN-nn    0.166998848297<BR>  1->subdomain-NN-prep_to    <BR>    2->the-DT-det    <BR>    2->T4SS-JJ-amod    <BR>    2->step-NN-prep_as    <BR>      3->a-DT-det    <BR>      3->introduction-NN-prep_toward    <BR>        4->the-DT-det    <BR>        4->extraction-NN-prep_of    <BR>          5->event-NN-nn    <BR>  1->domain-NN-prep_to    <BR>    2->the-DT-det    <BR>    2->broader-JJR-amod    <BR>    2->infectious-NNP-nn    <BR>    2->diseases-NNS-nn    <BR>'
p97
sg11
F-0.41784193
sg12
S'While this experiment is limited in both scope and scale, it suggests that the event extraction approach can be beneficially applied to detect domain events represented by novel argument structures. As a demonstration of feasibility the result is encouraging for both the applicability of event extraction to this specific new domain and for the adaptability of the approach to new domains in general.  '
p98
sg14
F0.009167033532741802
saa(lp99
S'W10-1919-158'
p100
a(dp101
g5
S'As a demonstration of feasibility the result is encouraging for both the applicability of event extraction to this specific new domain and for the adaptability of the approach to new domains in general. '
p102
sg7
S'We have presented a study of the adaptation of an event extraction approach to the T4SS subdomain as a step toward the introduction of event extraction to the broader infectious diseases domain. We applied a previously introduced corpus of subdomain full texts annotated for mentions of bacteria and terms from the three top-level Gene Ontology subontologies as a reference defining domain information needs to study how these can be met through the application of events defined in the BioNLP\xe2\x80\x9909 Shared Task on event extraction. '
p103
sg9
S'0->encouraging-VBG-root             0.00484688401566<BR>  1->demonstration-NN-prep_as    <BR>    2->a-DT-det    <BR>    2->feasibility-NN-prep_of    <BR>  1->result-NN-nsubj    0.0193875360626         0.0193875360626<BR>    2->the-DT-det    <BR>  1->result-NN-nsubj    <BR>  1->is-VBZ-aux    <BR>  1->encouraging-VBG-conj_and    <BR>  1->applicability-NN-prep_for    <BR>    2->both-PDT-predet    <BR>    2->the-DT-det    <BR>    2->extraction-NN-prep_of    <BR>      3->event-NN-nn    <BR>  1->domain-NN-prep_to    <BR>    2->this-DT-det    <BR>    2->specific-JJ-amod    <BR>    2->new-JJ-amod    <BR>  1->adaptability-NN-prep_for    <BR>    2->the-DT-det    <BR>    2->approach-NN-prep_of    <BR>      3->the-DT-det    <BR>      3->domains-NNS-prep_to    <BR>        4->new-JJ-amod    <BR>        4->general-NN-prep_in    <BR>'
p104
sg11
F-1.9644295
sg12
S'With respect to the baseline result, the machine-learning approach achieves a 21% relative reduction in error. While this experiment is limited in both scope and scale, it suggests that the event extraction approach can be beneficially applied to detect domain events represented by novel argument structures. '
p105
sg14
F0.00910440748421182
saa(lp106
S'J93-1005-180'
p107
a(dp108
g5
S'If we restrict the lexical association procedure to choose attachment only in cases where the absolute value of the LA score is greater than 2.0 (an arbitrary threshold indicating that the probability of one attachment is four times greater than the other), we get attachment judgments on 621 of the 880 test sentences, with overall precision of about 89%.'
p109
sg7
S'On these same examples, the judges also showed improvement, as evident in Table 3.7  The fact that an LA score threshold improves precision indicates that the LA score gives information about how confident we can be about an attachment choice. '
p110
sg9
S'0->get-VBP-root             0.00257643364576<BR>  1->restrict-VBP-advcl    <BR>    2->If-IN-mark    <BR>    2->we-PRP-nsubj    <BR>    2->choose-VB-xcomp    <BR>      3->procedure-NN-nsubj    <BR>        4->the-DT-det    <BR>        4->lexical-JJ-amod    <BR>        4->association-NN-nn    <BR>      3->to-TO-aux    <BR>      3->attachment-NN-dobj    <BR>      3->only-RB-advmod    <BR>      3->cases-NNS-prep_in    <BR>        4->2.0-CD-rcmod    <BR>          5->where-WRB-advmod    <BR>          5->value-NN-nsubj    <BR>            6->the-DT-det    <BR>            6->absolute-JJ-amod    <BR>            6->score-NN-prep_of    <BR>              7->the-DT-det    <BR>              7->LA-NNP-nn    <BR>          5->is-VBZ-cop    <BR>          5->than-IN-quantmod    <BR>            6->greater-JJR-mwe    <BR>          5->threshold-NN-dep    <BR>            6->an-DT-det    <BR>            6->arbitrary-JJ-amod    <BR>            6->indicating-VBG-rcmod    <BR>              7->greater-JJR-ccomp    <BR>                8->threshold-NN-mark    <BR>                8->probability-NN-nsubj    <BR>                  9->the-DT-det    <BR>                  9->attachment-NN-prep_of    <BR>                    10->one-CD-num    <BR>                8->is-VBZ-cop    <BR>                8->times-NNS-npadvmod    <BR>                  9->four-CD-num    <BR>            6->other-JJ-prep_than    <BR>              7->the-DT-det    <BR>  1->we-PRP-nsubj             0.0<BR>  1->judgments-NNS-dobj    0.00319342309518         0.0711035731523<BR>    2->attachment-NN-nn    0.139013723209<BR>  1->621-NNP-prep_on    <BR>    2->sentences-NNS-prep_of    <BR>      3->the-DT-det    <BR>      3->880-CD-num    <BR>      3->test-NN-nn    <BR>  1->precision-NN-prep_with    <BR>    2->overall-JJ-amod    <BR>    2->%-NN-prep_of    <BR>      3->89-CD-num    <BR>        4->about-RB-quantmod    <BR>'
p111
sg11
F-1.5882146
sg12
S'The recall figures indicate the proportion of test items actually belonging to a given category that were assigned to that category: N precision is the fraction of actual N attachments that were identified as N attachments. The LA procedure recognized about 85% of the 586 actual noun attachment examples as noun attachments, and about 70% of the actual verb attachments as verb attachments. '
p112
sg14
F0.006570197287822111
saa(lp113
S'J93-1005-39'
p114
a(dp115
g5
S'For each noun phrase head, we recorded the following preposition if any occurred (ignoring whether or not the parser had attached the preposition to the noun phrase), and the preceding verb if the noun phrase was the object of that verb.'
p116
sg7
S'The entries in Table 1 are those generated from the text above. Each noun phrase in Example 3 is associated with an entry in the Noun column of the table. '
p117
sg9
S'0->recorded-VBD-root             0.00638684619036<BR>  1->head-NN-prep_for    <BR>    2->each-DT-det    <BR>    2->noun-NN-nn    <BR>    2->phrase-NN-nn    <BR>  1->we-PRP-nsubj             0.0<BR>  1->preposition-NN-dobj    0.0827594679332         0.0605402725377<BR>    2->the-DT-det    <BR>    2->following-JJ-amod    0.0383210771422<BR>  1->occurred-VBD-advcl    <BR>    2->if-IN-mark    <BR>    2->any-DT-nsubj    <BR>    2->ignoring-VBG-parataxis    <BR>      3->not-RB-ccomp    <BR>      3->attached-VBN-ccomp    <BR>        4->whether-IN-mark    <BR>        4->not-RB-conj_or    <BR>        4->parser-NN-nsubj    <BR>          5->the-DT-det    <BR>        4->had-VBD-aux    <BR>        4->preposition-NN-dobj    <BR>          5->the-DT-det    <BR>        4->phrase-NN-prep_to    <BR>          5->the-DT-det    <BR>          5->noun-NN-nn    <BR>  1->verb-VB-conj_and    <BR>    2->the-DT-nsubj    <BR>      3->preceding-VBG-amod    <BR>    2->object-NN-advcl    <BR>      3->if-IN-mark    <BR>      3->phrase-NN-nsubj    <BR>        4->the-DT-det    <BR>        4->noun-NN-nn    <BR>      3->was-VBD-cop    <BR>      3->the-DT-det    <BR>      3->verb-NN-prep_of    <BR>        4->that-DT-det    <BR>'
p118
sg11
F-1.5627929
sg12
S'Example 2 The radical changes in export and customs regulations evidently are aimed at remedying an extreme shortage of consumer goods in the Soviet Union and assuaging citizens angry over the scarcity of such basic items as soap and windshield wipers. From the syntactic analysis provided by the parser, we extracted a table containing the heads of all noun phrases. '
p119
sg14
F0.006312946017563066
saa(lp120
S'J93-1005-217'
p121
a(dp122
g5
S'In the remaining 16 cases, associations between the preposition and both the noun and the verb are recorded in the dictionary.'
p123
sg7
S'For these, we select noun attachment, since it is the more probable outcome in general. For the remaining cases, we assume that the dictionary makes no decision. '
p124
sg9
S'0->recorded-VBN-root             0.00638684619036<BR>  1->cases-NNS-prep_in    <BR>    2->the-DT-det    <BR>    2->remaining-VBG-amod    <BR>    2->16-CD-num    <BR>  1->associations-NNS-nsubjpass    0.0334936373949         0.117754460134<BR>    2->preposition-NN-prep_between    0.0827594679332<BR>      3->the-DT-det    <BR>      3->noun-NN-conj_and    0.153984431863<BR>        4->both-PDT-predet    <BR>        4->the-DT-det    <BR>        4->verb-NN-conj_and    0.141152395874<BR>          5->the-DT-det    <BR>      3->verb-NN-conj_and    0.141152395874<BR>    2->noun-NN-prep_between    0.153984431863<BR>  1->are-VBP-auxpass    <BR>  1->dictionary-NN-prep_in    <BR>    2->the-DT-det    <BR>'
p125
sg11
F-1.5542131
sg12
S'In 241 of those cases, there is information only on noun or only on verb association. In these cases, we can use the dictionary to choose the attachment according to the association indicated. '
p126
sg14
F0.006196084538369026
saa(lp127
S'J93-1005-78'
p128
a(dp129
g5
S'We assume that in each case of attachment ambiguity, there is a forced choice between two outcomes: the preposition attaches either to the verb or to the noun.'
p130
sg7
S"' For example, in Example 6, we want to choose between two possibilities: either into is attached to the verb send or it is attached to the noun soldier.  Moscow sent more than 100,000 soldiers into Afghanistan ... In particular, we want to choose between two structures:  "
p131
sg9
S'0->assume-VBP-root             0.00958026928554<BR>  1->We-PRP-nsubj             0.0<BR>  1->is-VBZ-ccomp    <BR>    2->that-IN-mark    <BR>    2->case-NN-prep_in    <BR>      3->each-DT-det    <BR>      3->ambiguity-NNS-prep_of    <BR>        4->attachment-NN-nn    <BR>    2->there-EX-expl    <BR>    2->choice-NN-nsubj    <BR>      3->a-DT-det    <BR>      3->forced-VBN-amod    <BR>      3->outcomes-NNS-prep_between    <BR>        4->two-CD-num    <BR>  1->attaches-VBZ-parataxis    <BR>    2->preposition-NN-nsubj    <BR>      3->the-DT-det    <BR>    2->either-CC-preconj    <BR>    2->verb-NN-prep_to    <BR>      3->the-DT-det    <BR>      3->noun-NN-conj_or    <BR>        4->the-DT-det    <BR>    2->noun-NN-prep_to    <BR>'
p132
sg11
F-1.9140611
sg12
S'For instance, if p is a preposition, f (p) = Ew f (w, p).  Our object is to develop a procedure to guess whether a preposition is attached to the verb or its object when a verb and its object are followed by a preposition. '
p133
sg14
F0.006049074637039208
saa(lp134
S'J93-1005-141'
p135
a(dp136
g5
S'We chose always to assign light verb constructions to noun attachment, based on the fact that the noun supplies the lexical information about what prepositions are possible, and small clauses to verb attachment, based on the fact that this is a predicative construction lexically licensed by the verb.'
p137
sg7
S'Another difficulty arose with cases where there seemed to be a systematic semantically based indeterminacy about the attachment. In the situation described by Example 12a, the bar and the described event or events are presumably in the same location, and so there is no semantic reason to decide on one attachment. '
p138
sg9
S'0->chose-VBD-root             0.00319342309518<BR>  1->We-PRP-nsubj             0.0<BR>  1->always-RB-advmod    <BR>  1->assign-VB-xcomp    <BR>    2->We-PRP-xsubj    <BR>    2->to-TO-aux    <BR>    2->constructions-NNS-dobj    <BR>      3->light-JJ-amod    <BR>      3->verb-JJ-amod    <BR>    2->attachment-NN-prep_to    <BR>      3->noun-NN-nn    <BR>    2->based-VBN-prep    <BR>      3->on-IN-pcomp    <BR>        4->fact-NN-pobj    <BR>          5->the-DT-det    <BR>  1->supplies-VBZ-ccomp    <BR>    2->that-IN-mark    <BR>    2->noun-NN-nsubj    <BR>      3->the-DT-det    <BR>    2->information-NN-dobj    <BR>      3->the-DT-det    <BR>      3->lexical-JJ-amod    <BR>      3->possible-JJ-rcmod    <BR>        4->information-NN-prep_about    <BR>        4->prepositions-NNS-nsubj    <BR>        4->are-VBP-cop    <BR>        4->clauses-NNS-prep_about    <BR>          5->small-JJ-amod    <BR>          5->verb-VB-infmod    <BR>            6->to-TO-aux    <BR>            6->attachment-NN-dobj    <BR>      3->clauses-NNS-conj_and    <BR>    2->clauses-NNS-dobj    <BR>  1->on-IN-prepc_based_on    <BR>  1->fact-NN-pobj    0.0192480539828         0.0308203759987<BR>    2->the-DT-det    <BR>    2->construction-NN-dep    0.00855469065904<BR>      3->that-IN-mark    <BR>      3->this-DT-nsubj    <BR>      3->is-VBZ-cop    <BR>      3->a-DT-det    <BR>      3->predicative-JJ-amod    0.00319342309518<BR>      3->licensed-VBN-partmod    0.00958026928554<BR>        4->lexically-RB-advmod    0.00319342309518<BR>        4->verb-NN-agent    0.141152395874<BR>          5->the-DT-det    <BR>'
p139
sg11
F-1.8621688
sg12
S"Example 11 Sides said Francke kept a .38-caliber revolver in his car's glove compartment. In the case of idioms, we made the assignment on the basis of a guess about the syntactic structure of the idiom, though this was sometimes difficult to judge. "
p140
sg14
F0.006033437722700056
saa(lp141
S'J93-1005-127'
p142
a(dp143
g5
S'This task is in essence the one that we will give the computer\xe2\x80\x94to judge the attachment without any more information than the preposition and the heads of the two possible attachment sites.'
p144
sg7
S'This initial step provides a rough indication of what we might expect to be achievable based on the information our procedure is using. We also wanted a standard of correctness for the test sentences. '
p145
sg9
S'0->is-VBZ-root             0.228837975129<BR>  1->task-NN-nsubj    0.0127736923807         0.0127736923807<BR>    2->This-DT-det    <BR>  1->essence-VBG-prepc_in    <BR>    2->one-NN-dobj    0.0235253993124         0.0235253993124<BR>      3->the-DT-det    <BR>    2->give-VB-ccomp    <BR>      3->that-IN-mark    <BR>      3->we-PRP-nsubj    <BR>      3->will-MD-aux    <BR>      3->computer-NN-dobj    <BR>        4->the-DT-det    <BR>    2->judge-VB-parataxis    <BR>      3->to-TO-aux    <BR>      3->attachment-NN-dobj    <BR>        4->the-DT-det    <BR>      3->information-NN-prep_without    <BR>        4->any-DT-det    <BR>        4->more-JJR-amod    <BR>        4->preposition-NN-prep_than    <BR>          5->the-DT-det    <BR>        4->heads-NNS-conj_and    <BR>          5->the-DT-det    <BR>          5->sites-NNS-prep_of    <BR>            6->the-DT-det    <BR>            6->two-CD-num    <BR>            6->possible-JJ-amod    <BR>            6->attachment-NN-nn    <BR>      3->heads-NNS-prep_without    <BR>    2->judge-VB-xcomp    <BR>'
p146
sg11
F4.0180069
sg12
S'The two authors first guessed attachments on the verb\xe2\x80\x93noun\xe2\x80\x93preposition triples, making a judgment on the basis of the three headwords alone. The judges were required to make a choice in each instance. '
p147
sg14
F0.006019084325399162
saa(lp148
S'J93-1005-75'
p149
a(dp150
g5
S'We use the following notation: f(w,p) is the frequency count for the pair consisting of the verb or noun w and the preposition p. The unigram frequency count for the word w (either a verb, noun, or preposition) can be viewed as a sum of bigram frequencies, and is written f (w).'
p151
sg7
S'For instance, if p is a preposition, f (p) = Ew f (w, p).  Our object is to develop a procedure to guess whether a preposition is attached to the verb or its object when a verb and its object are followed by a preposition. '
p152
sg9
S'0->use-VBP-root             0.0309172037492<BR>  1->We-PRP-nsubj             0.0<BR>  1->notation-NN-dobj    0.00638684619036         0.0223539616663<BR>    2->the-DT-det    <BR>    2->following-JJ-amod    0.0383210771422<BR>  1->count-NN-parataxis    <BR>    2->f-SYM-nsubj    <BR>      3->w-NN-dep    <BR>        4->p-NN-appos    <BR>    2->is-VBZ-cop    <BR>    2->the-DT-det    <BR>    2->frequency-NN-nn    <BR>    2->pair-NN-prep_for    <BR>      3->the-DT-det    <BR>      3->consisting-VBG-partmod    <BR>        4->w-NN-prep_of    <BR>          5->the-DT-det    <BR>          5->verb-NN-nn    <BR>            6->noun-NN-conj_or    <BR>          5->noun-NN-nn    <BR>          5->p-NN-conj_and    <BR>            6->the-DT-det    <BR>            6->preposition-NN-nn    <BR>        4->p-NN-prep_of    <BR>'
p153
sg11
F-1.183418
sg12
S'The procedure for assigning prepositions is as follows:  This procedure gives us bigram counts representing the frequency with which a given noun occurs associated with an immediately following preposition (or no preposition), or a given verb occurs in a transitive use and is associated with a preposition immediately following the object of the verb. '
p154
sg14
F0.006014389325091984
saa(lp155
S'P07-3014-1'
p156
a(dp157
g5
S'The attributes used as input to the learning algorithms are the web frequencies for phrases containing the modifier, noun, and a prepositional joining term.'
p158
sg7
S"We compare and evaluate different algorithms and different joining phrases on Nastase and Szpakowicz's (2003) dataset of 600 modifier-noun compounds. We find that by using a Support Vector Machine classifier we can obtain better performance on this dataset than a current state-of-the-art system; even with a relatively small set of prepositional joining terms.  "
p159
sg9
S'0->used-VBD-root             0.0720420104188<BR>  1->attributes-NNS-nsubj    0.0947265861909         0.0947265861909<BR>    2->The-DT-det    <BR>  1->frequencies-NNS-advcl    <BR>    2->as-IN-mark    <BR>    2->input-NN-nsubj    <BR>      3->algorithms-NNS-prep_to    <BR>        4->the-DT-det    <BR>        4->learning-NN-nn    <BR>    2->are-VBP-cop    <BR>    2->the-DT-det    <BR>    2->web-NN-nn    <BR>    2->phrases-NNS-prep_for    <BR>      3->containing-VBG-partmod    <BR>        4->modifier-NN-dobj    0.190253204913         0.160243692097<BR>          5->the-DT-det    <BR>          5->noun-NN-conj_and    0.190253204913<BR>          5->prepositional-NN-conj_and    0.189453172382<BR>            6->a-DT-det    <BR>            6->joining-VBG-partmod    0.167841143307<BR>              7->term-NN-dobj    0.0634177349709<BR>        4->noun-NN-dobj    <BR>        4->prepositional-NN-dobj    <BR>'
p160
sg11
F1.2105804
sg12
S'This paper investigates the use of machine learning algorithms to label modifier-noun compounds with a semantic relation. '
p161
sg14
F0.010675771669434501
saa(lp162
S'P07-3014-17'
p163
a(dp164
g5
S'The motivation for this paper is to discover which joining terms are good predictors of a semantic relation, and which learning algorithms perform best at the task of mapping from joining terms to semantic relations for modifier-noun compounds. '
p165
sg7
S'Choosing a set of joining terms in a principled manner in the hope of capturing the semantic relation between constituents in the noun phrase is difficult, but there is certainly some correlation between a prepositional term or short linking verb and a semantic relation. For example, the preposition &quot;during&quot; indicates a temporal relation, while the preposition &quot;in&quot; indicates a locative relation, either temporal or spatial. '
p166
sg9
S'0->is-VBZ-root             0.183378045708<BR>  1->motivation-NN-nsubj    0.0457786297206         0.0526487303693<BR>    2->The-DT-det    <BR>    2->paper-NN-prep_for    0.0595188310179<BR>      3->this-DT-det    <BR>  1->discover-VB-xcomp    <BR>    2->motivation-NN-xsubj    <BR>    2->to-TO-aux    <BR>    2->joining-VBG-dep    <BR>      3->which-WDT-nsubj    <BR>      3->predictors-NNS-ccomp    <BR>        4->terms-NNS-nsubj    <BR>        4->are-VBP-cop    <BR>        4->good-JJ-amod    <BR>        4->relation-NN-prep_of    <BR>          5->a-DT-det    <BR>          5->semantic-JJ-amod    <BR>      3->learning-VBG-conj_and    <BR>        4->which-WDT-nsubj    <BR>        4->perform-VB-ccomp    <BR>          5->algorithms-NNS-nsubj    <BR>          5->best-RBS-advmod    <BR>          5->task-NN-prep_at    <BR>            6->the-DT-det    <BR>            6->mapping-VBG-prepc_of    <BR>              7->joining-VBG-prepc_from    <BR>                8->terms-NNS-dobj    0.0924433636085         0.0924433636085<BR>                8->relations-NNS-prep_to    <BR>                  9->semantic-JJ-amod    <BR>                  9->compounds-NNS-prep_for    <BR>                    10->modifier-noun-JJ-amod    <BR>    2->learning-VBG-dep    <BR>'
p167
sg11
F3.5210596
sg12
S'This is the approach we use in our experiments. We choose two sets of joining terms, based on the frequency with which they occur in between nouns in the British National Cor '
p168
sg14
F0.01052687469661481
saa(lp169
S'P07-3014-56'
p170
a(dp171
g5
S'Turney and Littman (2005) use a set of 64 short prepositional and conjunctive phrases they call &quot;joining terms&quot; to generate exact queries for AltaVista of the form &quot;noun joining term modifier&quot;, and &quot;modifier joining term noun&quot;.'
p172
sg7
S'These hit counts were used with a nearest neighbor algorithm to assign the noun phrases semantic relations. Over the set of 5 semantic relations defined by Nastase and Szpakowicz (2003), they achieve an accuracy of 45.7% for the task of assigning one of 5 semantic relations to each of the 600 modifier-noun phrases.  '
p173
sg9
S'0->use-VBP-root             0.112964327461<BR>  1->Turney-NNP-nsubj    0.0374964339642         0.0374964339642<BR>    2->Littman-NNP-conj_and    0.0187482169821<BR>    2->2005-CD-appos    0.0562446509462<BR>  1->Littman-NNP-nsubj    <BR>  1->set-NN-dobj    0.0251031838802         0.0663484868359<BR>    2->a-DT-det    <BR>    2->prepositional-JJ-prep_of    0.0187482169821<BR>      3->64-CD-number    0.0219337202733<BR>      3->short-JJ-amod    0.0219337202733<BR>      3->phrases-NNS-conj_and    0.128326520328<BR>        4->conjunctive-JJ-amod    0.0264234349967<BR>    2->phrases-NNS-prep_of    0.128326520328<BR>    2->call-VBP-rcmod    0.0264234349967<BR>      3->set-NN-dobj    0.0251031838802<BR>      3->they-PRP-nsubj    <BR>      3->joining-VBG-dep    0.0332189969023<BR>        4->terms-NNS-dobj    0.0221459979349<BR>        4->generate-VB-xcomp    0.0528468699934<BR>          5->to-TO-aux    <BR>          5->queries-NNS-dobj    0.0438674405466<BR>            6->exact-JJ-amod    0.0219337202733<BR>          5->AltaVista-NNP-prep_for    0.0264234349967<BR>            6->form-NN-prep_of    0.0658011608199<BR>              7->the-DT-det    <BR>              7->joining-VBG-dep    0.0332189969023<BR>                8->noun-NN-nsubj    0.200825471042<BR>                8->modifier-NN-dobj    0.150619103281<BR>                  9->term-NN-nn    0.0251031838802<BR>        4->modifier-VB-conj_and    0.150619103281<BR>          5->joining-VBG-dep    0.0332189969023<BR>            6->noun-NN-dobj    0.200825471042<BR>              7->term-NN-nn    0.0251031838802<BR>      3->modifier-VB-dep    0.150619103281<BR>'
p174
sg11
F1.4694122
sg12
S'The second approach is to use statistical information about the occurrence of the noun and modifier in a corpus to generate attributes for a machine learning algorithm. This is the method we will describe in this paper. '
p175
sg14
F0.01031230736825144
saa(lp176
S'P07-3014-58'
p177
a(dp178
g5
S'Over the set of 5 semantic relations defined by Nastase and Szpakowicz (2003), they achieve an accuracy of 45.7% for the task of assigning one of 5 semantic relations to each of the 600 modifier-noun phrases. '
p179
sg7
S'The method described in this paper is similar to the work presented in Turney and Littman (2005). We collect web frequencies for queries of the form &quot;head joining term modifier&quot;. '
p180
sg9
S'0->achieve-VBP-root             0.0162773486688<BR>  1->set-NN-prep_over    <BR>    2->the-DT-det    <BR>    2->relations-NNS-prep_of    <BR>      3->5-CD-num    <BR>      3->semantic-JJ-amod    <BR>      3->defined-VBN-partmod    <BR>        4->Nastase-NNP-agent    <BR>          5->Szpakowicz-NNP-conj_and    <BR>        4->Szpakowicz-NNP-agent    <BR>    2->2003-CD-appos    <BR>  1->they-PRP-nsubj             0.0<BR>  1->accuracy-NN-dobj    0.0325546973376         0.0575724976783<BR>    2->an-DT-det    <BR>    2->%-NN-prep_of    0.0<BR>      3->45.7-CD-num    0.0<BR>      3->task-NN-prep_for    0.0712925112933<BR>        4->the-DT-det    <BR>        4->assigning-VBG-prepc_of    0.0528468699934<BR>          5->one-CD-dobj    0.0162773486688<BR>            6->relations-NNS-prep_of    0.0570340090346<BR>              7->5-CD-num    0.0<BR>              7->semantic-JJ-amod    0.138067511341<BR>          5->each-DT-prep_to    <BR>            6->phrases-NNS-prep_of    0.128326520328<BR>              7->the-DT-det    <BR>              7->600-CD-num    0.0187482169821<BR>              7->modifier-noun-JJ-amod    0.175722287161<BR>'
p181
sg11
F-1.3203094
sg12
S'Turney and Littman (2005) use a set of 64 short prepositional and conjunctive phrases they call &quot;joining terms&quot; to generate exact queries for AltaVista of the form &quot;noun joining term modifier&quot;, and &quot;modifier joining term noun&quot;. These hit counts were used with a nearest neighbor algorithm to assign the noun phrases semantic relations. '
p182
sg14
F0.01014995311985659
saa(lp183
S'P07-3014-126'
p184
a(dp185
g5
S'Also, they use 64 joining terms and gather counts for both the forms &quot;noun joining term modifier&quot; and &quot;modifier joining term noun&quot; (128 frequencies in total); while we use only the former construction with 28 joining terms.'
p186
sg7
S'By using the SVM classifier, we were able to achieve a higher accuracy than Turney and Littman (50.1% versus 45.7%) with significantly fewer joining terms (28 versus 128). However, one issue with the SVM is  '
p187
sg9
S'0->use-VBP-root             0.025781840434<BR>  1->Also-RB-advmod    <BR>  1->they-PRP-nsubj             0.0<BR>  1->64-CD-dobj    0.0225266913914         0.0441143049402<BR>    2->joining-VBG-rcmod    0.102351185603<BR>      3->terms-NNS-dobj    0.090978831647<BR>      3->gather-VB-conj_and    0.0271377841176<BR>        4->counts-NNS-dobj    0.0334348031764<BR>        4->joining-VBG-prepc_for    0.102351185603<BR>          5->forms-NNS-nsubj    0.0225266913914<BR>            6->both-PDT-predet    <BR>            6->the-DT-det    <BR>          5->noun-RB-advmod    0.0386727606511<BR>          5->modifier-NN-dobj    0.025781840434<BR>            6->term-NN-nn    0.025781840434<BR>            6->frequencies-NNS-conj_and    0.0227447079118<BR>              7->modifier-NN-dep    0.025781840434<BR>                8->joining-VBG-dep    0.102351185603<BR>                  9->noun-NN-dobj    0.0386727606511<BR>                    10->term-NN-nn    0.025781840434<BR>              7->128-CD-num    0.0542755682351<BR>              7->total-NN-prep_in    0.0271377841176<BR>          5->frequencies-NNS-dobj    0.0227447079118<BR>    2->gather-VB-rcmod    0.0271377841176<BR>  1->use-VBP-advcl    <BR>    2->while-IN-mark    <BR>    2->we-PRP-nsubj    <BR>    2->construction-NN-dobj    <BR>      3->only-RB-advmod    <BR>      3->the-DT-det    <BR>      3->former-JJ-amod    <BR>    2->28-CD-prep_with    <BR>    2->joining-VBG-xcomp    <BR>      3->terms-NNS-dobj    <BR>'
p188
sg11
F-1.1633771
sg12
S'Turney and Littman (2005) achieve an accuracy of 45.7%, where we achieve a maximum accuracy of 38.1% on this dataset using a nearest neighbor algorithm. However, their technique uses the cosine of the angle between the vectors of web counts as the similarity metric, while the nearest neighbor implementation in Weka uses the Euclidean distance. '
p189
sg14
F0.010021033823423838
saa(lp190
S'P07-3014-130'
p191
a(dp192
g5
S'The largest class in our dataset is &quot;participant&quot;, which is the label for 43% of the examples; the smallest is &quot;temporal&quot;, which labels 9% of the examples.'
p193
sg7
S'&quot;Causal&quot; labels 14% of the data. It is difficult to explain why the algorithm fails to account for the &quot;causal&quot; class; a useful task for future work would be to conduct a similar experiment with a more balanced dataset.  '
p194
sg9
S'0->participant-NN-root             0.0225266913914<BR>  1->class-NN-nsubj    0.0577652071102         0.0434813677554<BR>    2->The-DT-det    <BR>    2->largest-JJS-amod    0.0225266913914<BR>    2->dataset-NN-prep_in    0.0501522047646<BR>      3->our-PRP$-poss    <BR>  1->is-VBZ-cop    <BR>  1->label-NN-rcmod    <BR>    2->participant-NN-nsubj    <BR>    2->is-VBZ-cop    <BR>    2->the-DT-det    <BR>    2->%-NN-prep_for    <BR>      3->43-CD-num    <BR>      3->examples-NNS-prep_of    <BR>        4->the-DT-det    <BR>  1->temporal-NNP-parataxis    <BR>    2->smallest-JJS-nsubj    <BR>      3->the-DT-det    <BR>    2->is-VBZ-cop    <BR>    2->labels-VBZ-rcmod    <BR>      3->temporal-NNP-nsubj    <BR>      3->%-NN-dobj    0.0         0.0167174015882<BR>        4->9-CD-num    0.0<BR>        4->examples-NNS-prep_of    0.0501522047646<BR>          5->the-DT-det    <BR>'
p195
sg11
F-1.2793979
sg12
S'However, one issue with the SVM is  that it never predicted the class &quot;causal&quot; for any of the examples. '
p196
sg14
F0.010007336000196359
saa(lp197
S'P07-3014-24'
p198
a(dp199
g5
S'We are also interested in comparing the performance of machine learning algorithms on the task of mapping from n-gram frequencies of joining terms to semantic relations.'
p200
sg7
S'For the experiments we use Weka, (Witten and Frank, 1999) a machine learning toolkit which allows for fast experimentation with many standard learning algorithms. In Section 5 we present the results obtained using the nearestneighbor, neural network (i.e. multi-layer perceptron) and SVM. '
p201
sg9
S'0->interested-JJ-root             0.0915572594412<BR>  1->We-PRP-nsubj             0.0<BR>  1->are-VBP-cop    <BR>  1->also-RB-advmod    <BR>  1->comparing-VBG-prepc_in    <BR>    2->performance-NN-dobj    0.0391300551138         0.0797278627553<BR>      3->the-DT-det    <BR>      3->algorithms-NNS-prep_of    0.0785905910175<BR>        4->machine-NN-nn    0.052393727345<BR>        4->learning-NN-nn    0.148797077545<BR>    2->task-NN-prep_on    <BR>      3->the-DT-det    <BR>      3->mapping-NN-prep_of    <BR>    2->frequencies-NNS-prep_from    <BR>      3->n-gram-JJ-amod    <BR>      3->joining-VBG-prepc_of    <BR>        4->terms-NNS-dobj    <BR>        4->relations-NNS-prep_to    <BR>          5->semantic-JJ-amod    <BR>'
p202
sg11
F0.84783005
sg12
S'If this is true, we would expect that very frequent prepositions, such as &quot;of&quot;, would have many possible meanings and therefore not reliably predict a semantic relation. However, less frequent prepositions, such as &quot;while&quot; would have a more limited set of senses and therefore accurately predict a semantic relation.  '
p203
sg14
F0.009912699454019215
saa(lp204
S'W11-2821-69'
p205
a(dp206
g5
S'One explanation for these findings would be that people do whatever is necessary to achieve a desired level of performance, so that when provided with superior tools they achieve roughly the same result but with less effort.12 The drop in performance by the unorganised text group on question 1 might have been due to unfamiliarity with a sentence-list type of text (all participants answered question 1 first since questions were always presented in the same order).'
p207
sg7
S'Improvements on later questions could have been the result of a learning effect with this group. The near-perfect performance of the organised text group on the first questions demonstrates the benefit of viewing a familiar genre. '
p208
sg9
S'0->be-VB-root             0.067732520293<BR>  1->explanation-NN-nsubj    0.0117998847901         0.0260027789437<BR>    2->One-CD-num    0.0544085672508<BR>    2->findings-NNS-prep_for    0.0117998847901<BR>      3->these-DT-det    <BR>  1->would-MD-aux    <BR>  1->do-VBP-ccomp    <BR>    2->that-IN-mark    <BR>    2->people-NNS-nsubj    <BR>    2->necessary-JJ-ccomp    <BR>      3->whatever-WDT-nsubj    <BR>      3->is-VBZ-cop    <BR>      3->achieve-VB-xcomp    <BR>        4->whatever-WDT-xsubj    <BR>        4->to-TO-aux    <BR>        4->level-NN-dobj    0.0774085946206         0.0497962452796<BR>          5->a-DT-det    <BR>          5->desired-VBN-amod    0.0235997695802<BR>          5->performance-NN-prep_of    0.0483803716379<BR>      3->achieve-VBP-conj_so    <BR>        4->that-IN-mark    <BR>        4->provided-VBN-advcl    <BR>          5->when-WRB-advmod    <BR>          5->tools-NNS-prep_with    <BR>            6->superior-JJ-amod    <BR>        4->they-PRP-nsubj    <BR>        4->result-NN-dobj    <BR>          5->roughly-RB-advmod    <BR>          5->the-DT-det    <BR>          5->same-JJ-amod    <BR>        4->with-IN-prep    <BR>          5->effort-NN-conj_less    <BR>            6->.12-CD-num    <BR>            6->due-JJ-rcmod    <BR>              7->effort-NN-dobj    <BR>              7->drop-NN-nsubj    <BR>                8->The-DT-det    <BR>                8->performance-NN-prep_in    <BR>                  9->group-NN-prep_by    <BR>                    10->the-DT-det    <BR>                    10->unorganised-JJ-amod    <BR>                    10->text-NN-nn    <BR>                    10->question-NN-prep_on    <BR>                      11->1-CD-num    <BR>              7->might-MD-aux    <BR>              7->have-VB-aux    <BR>              7->been-VBN-cop    <BR>              7->unfamiliarity-NN-prep_to    <BR>              7->type-NN-prep_with    <BR>                8->a-DT-det    <BR>                8->sentence-list-JJ-amod    <BR>                8->text-NN-prep_of    <BR>            6->participants-NNS-dep    <BR>              7->all-DT-det    <BR>              7->answered-VBN-partmod    <BR>                8->question-NN-dobj    <BR>                  9->1-CD-num    <BR>                8->first-RB-advmod    <BR>                8->presented-VBN-advcl    <BR>                  9->since-IN-mark    <BR>                  9->questions-NNS-nsubjpass    <BR>                  9->were-VBD-auxpass    <BR>                  9->always-RB-advmod    <BR>                  9->order-NN-prep_in    <BR>                    10->the-DT-det    <BR>                    10->same-JJ-amod    <BR>          5->effort-NN-pobj    <BR>        4->effort-NN-prep    <BR>    2->achieve-VBP-ccomp    <BR>'
p209
sg11
F0.10337686
sg12
S'None of this organisation is directly encoded in an OWL ontology: it represents rather a further move towards making the verbalisation more natural and humanlike. From our study comparing organised and unorganised texts, two main points emerge: first, we find no evidence that people viewing the organised text perform a navigation task more accurately; second, people viewing the organised texts found the task easier. '
p210
sg14
F0.01720653159448897
saa(lp211
S'W11-2821-78'
p212
a(dp213
g5
S'A second possible objection is that the organised text is necessarily longer than a bare list of sentences; this point is tested in the study reported here, which suggests that organisation makes the texts easier to use, with no loss of performance.'
p214
sg7
S'In future work we intend to look more closely at how the texts are used in retrieval tasks, and to obtain accurate measures of time differences.  The SWAT project (Semantic Web Authoring Tool) is supported by the UK Engineering and Physical Sciences Research Council (EPSRC) grants G033579/1 (Open University) and G032459/1 (University of Manchester). '
p215
sg9
S'0->is-VBZ-root             0.242994603288<BR>  1->objection-NN-nsubj    0.182469747944         0.135637151104<BR>    2->A-DT-det    <BR>    2->second-JJ-amod    0.0748139017898<BR>    2->possible-JJ-amod    0.14962780358<BR>  1->is-VBZ-ccomp    <BR>    2->that-IN-mark    <BR>    2->text-NN-nsubj    <BR>      3->the-DT-det    <BR>      3->organised-JJ-amod    <BR>    2->longer-RB-advmod    <BR>      3->necessarily-RB-advmod    <BR>    2->list-NN-prep_than    <BR>      3->a-DT-det    <BR>      3->bare-JJ-amod    <BR>      3->sentences-NNS-prep_of    <BR>  1->tested-VBN-parataxis    <BR>    2->point-NN-nsubjpass    <BR>      3->this-DT-det    <BR>    2->is-VBZ-auxpass    <BR>    2->study-NN-prep_in    <BR>      3->the-DT-det    <BR>      3->reported-VBN-partmod    <BR>        4->here-RB-advmod    <BR>      3->suggests-VBZ-rcmod    <BR>        4->study-NN-nsubj    <BR>        4->makes-VBZ-ccomp    <BR>          5->that-IN-mark    <BR>          5->organisation-NN-nsubj    <BR>          5->use-VB-xcomp    <BR>            6->texts-NNS-nsubj    <BR>              7->the-DT-det    <BR>            6->easier-RBR-dep    <BR>            6->to-TO-aux    <BR>            6->loss-NN-prep_with    <BR>              7->no-DT-det    <BR>              7->performance-NN-prep_of    <BR>'
p216
sg11
F4.5933823
sg12
S'We assume that most users prefer an ontology verbalisation that is worded and organised like a naturally occurring text of the appropriate genre \xe2\x80\x94 i.e., an encyclopedia or technical glossary. One possible objection is that such a text provides a loose rendering of OWL semantics, introducing organisational principles that are not present in the original code; however, as evidenced by the earlier studies we have cited, this attitude is not taken even by OWL specialists. '
p217
sg14
F0.01718446340780735
saa(lp218
S'W11-2821-47'
p219
a(dp220
g5
S'To render the unorganised text\xe2\x80\x99s appearance as similar as possible to the organised one, spaces were introduced every fourth line with blocks of text placed on a taupe-coloured background identical to that of the entries in the organised text.'
p221
sg7
S'The same five navigation and information location tasks (table 1) were used for both groups. The survey was administered via SurveyMonkey11 in which each navigation question was followed  '
p222
sg9
S'0->introduced-VBN-root             0.0235997695802<BR>  1->render-VB-advcl    <BR>    2->To-TO-aux    <BR>    2->appearance-NN-dobj    <BR>      3->text-NN-poss    <BR>        4->the-DT-det    <BR>        4->unorganised-JJ-amod    <BR>      3->similar-JJ-amod    <BR>        4->as-RB-advmod    <BR>    2->possible-JJ-prep_as    <BR>    2->one-NN-prep_to    <BR>      3->the-DT-det    <BR>      3->organised-JJ-amod    <BR>  1->spaces-NNS-nsubjpass    0.0117998847901         0.0117998847901<BR>  1->were-VBD-auxpass    <BR>  1->line-NN-dobj    0.0235997695802         0.0150252428993<BR>    2->every-DT-det    0.00967607432758<BR>    2->fourth-JJ-amod    0.0117998847901<BR>  1->blocks-NNS-prep_with    <BR>    2->text-NN-prep_of    <BR>      3->placed-VBN-partmod    <BR>        4->background-NN-prep_on    <BR>          5->a-DT-det    <BR>          5->taupe-coloured-JJ-amod    <BR>          5->identical-JJ-amod    <BR>            6->that-DT-prep_to    <BR>              7->entries-NNS-prep_of    <BR>                8->the-DT-det    <BR>                8->text-NN-prep_in    <BR>                  9->the-DT-det    <BR>                  9->organised-JJ-amod    <BR>'
p223
sg11
F-1.3855572
sg12
S'The texts were generated from an ontology about spider anatomy.3 One group saw the encyclopediastyled version illustrated in figure 1, henceforth the \xe2\x80\x98organised text\xe2\x80\x99; the other saw the same information as a list of sentences10 as shown in figure 2 (\xe2\x80\x98unorganised text\xe2\x80\x99). At 7746 words (25 A4-sized pages), the organised text is much longer than the unorganised one (4803 words, 9-pages) mainly because of duplicated information and headings (as explained in section 3). '
p224
sg14
F0.0168381853443525
saa(lp225
S'W11-2821-30'
p226
a(dp227
g5
S'For properties, the descriptive statements specify the domain and range, and features such as functionality and transitivity, and examples are provided by statements about individuals or classes in which the property is used. '
p228
sg7
S'A third level of organisation occurs when statements with identical structures and one identical argument are aggregated; see Williams and Power (2010) for more details. For some ontologies, this process can lead to very long lists of subclasses or individuals, so under the \xe2\x80\x98Examples\xe2\x80\x99 subheading where these occur we truncate them to a predefined maximum length and add the phrase \xe2\x80\x98and so on (N items in total)\xe2\x80\x99. '
p229
sg9
S'0->specify-VB-root             0.0117998847901<BR>  1->properties-NNS-prep_for    <BR>  1->statements-NNS-nsubj    0.0840046749943         0.0538022222872<BR>    2->the-DT-det    <BR>    2->descriptive-JJ-amod    0.0235997695802<BR>  1->domain-NN-dobj    0.0471995391604         0.0254092540477<BR>    2->the-DT-det    <BR>    2->range-NN-conj_and    0.0117998847901<BR>    2->features-NNS-conj_and    0.0580564459655<BR>      3->functionality-NN-prep_such_as    0.0117998847901<BR>        4->transitivity-NN-conj_and    0.0117998847901<BR>      3->transitivity-NN-prep_such_as    0.0117998847901<BR>  1->range-NN-dobj    <BR>  1->features-NNS-dobj    <BR>  1->provided-VBN-conj_and    <BR>    2->examples-NNS-nsubjpass    <BR>    2->are-VBP-auxpass    <BR>    2->statements-NNS-agent    <BR>      3->individuals-NNS-prep_about    <BR>        4->classes-NNS-conj_or    <BR>      3->classes-NNS-prep_about    <BR>      3->used-VBN-rcmod    <BR>        4->statements-NNS-prep_in    <BR>        4->property-NN-nsubjpass    <BR>          5->the-DT-det    <BR>        4->is-VBZ-auxpass    <BR>'
p230
sg11
F-1.4650637
sg12
S'argument occur under the definition subheading, the taxonomy is the superclass (from an OWL SubClassOf statement), descriptive statements correspond to the OWL functor SubClassOf, distinctions to DisjointClasses, and examples to the individuals belonging to the class. For individuals the class is given first (from an OWL ClassAssertion statement), followed by descriptions typically corresponding to ObjectPropertyAssertion. '
p231
sg14
F0.01683578692923072
saa(lp232
S'W11-2821-45'
p233
a(dp234
g5
S'The texts were generated from an ontology about spider anatomy.3 One group saw the encyclopediastyled version illustrated in figure 1, henceforth the \xe2\x80\x98organised text\xe2\x80\x99; the other saw the same information as a list of sentences10 as shown in figure 2 (\xe2\x80\x98unorganised text\xe2\x80\x99).'
p235
sg7
S'At 7746 words (25 A4-sized pages), the organised text is much longer than the unorganised one (4803 words, 9-pages) mainly because of duplicated information and headings (as explained in section 3). To render the unorganised text\xe2\x80\x99s appearance as similar as possible to the organised one, spaces were introduced every fourth line with blocks of text placed on a taupe-coloured background identical to that of the entries in the organised text. '
p236
sg9
S'0->generated-VBN-root             0.0163384136474<BR>  1->texts-NNS-nsubjpass    0.0408460341186         0.0408460341186<BR>    2->The-DT-det    <BR>  1->were-VBD-auxpass    <BR>  1->ontology-NN-prep_from    <BR>    2->an-DT-det    <BR>    2->anatomy-NN-prep_about    <BR>      3->spider-NN-nn    <BR>  1->.3-CD-dobj    0.0         0.0506888467262<BR>    2->saw-VBD-rcmod    0.0235997695802<BR>      3->group-NN-nsubj    0.129798732691<BR>        4->One-CD-num    0.0544085672508<BR>      3->version-NN-dobj    0.0117998847901<BR>        4->the-DT-det    <BR>        4->encyclopediastyled-JJ-amod    0.0117998847901<BR>        4->illustrated-VBN-partmod    0.0290282229827<BR>          5->figure-NN-prep_in    0.0490152409423<BR>            6->1-CD-num    0.0<BR>    2->henceforth-RB-advmod    0.0117998847901<BR>    2->text-NN-dep    0.175009739571<BR>      3->the-DT-det    <BR>      3->organised-JJ-amod    0.112006233326<BR>  1->saw-VBD-parataxis    <BR>    2->other-JJ-nsubj    <BR>      3->the-DT-det    <BR>    2->information-NN-dobj    <BR>      3->the-DT-det    <BR>      3->same-JJ-amod    <BR>    2->list-NN-prep_as    <BR>      3->a-DT-det    <BR>      3->sentences10-CD-prep_of    <BR>    2->shown-VBN-advcl    <BR>      3->as-IN-mark    <BR>      3->figure-NN-prep_in    <BR>        4->2-CD-num    <BR>        4->text-NN-dep    <BR>          5->unorganised-JJ-amod    <BR>'
p237
sg11
F-1.2114626
sg12
S'The study design is between-subjects in two independent groups. Participants were 57 members of the ACL special interest groups SIGGEN8 and SIGdial9.  '
p238
sg14
F0.016825558633962127
saa(lp239
S'W11-2821-3'
p240
a(dp241
g5
S'One consequence of this organisation is that some statements are repeated because they are relevant to more than one entry; this means that the text is longer than one in which statements are simply listed.'
p242
sg7
S'This trade-off between organisation and brevity is investigated in a user study.  Since OWL (Web Ontology Language) became the standard language for the semantic web in 2004,1 several research groups have developed systems, known as \xe2\x80\x98verbalisers\xe2\x80\x99, for generating Controlled English from OWL ontologies (Kaljurand and Fuchs, 2007; Dolbear et al., 2007; Schwitter and Tilbrook, 2004; Funk et al., 2007). '
p243
sg9
S'0->is-VBZ-root             0.240089353728<BR>  1->consequence-NN-nsubj    0.0901440675347         0.111883766045<BR>    2->One-CD-num    0.138549645412<BR>    2->organisation-NN-prep_of    0.106957585189<BR>      3->this-DT-det    <BR>  1->repeated-VBN-ccomp    <BR>    2->that-IN-mark    <BR>    2->statements-NNS-nsubjpass    <BR>      3->some-DT-det    <BR>    2->are-VBP-auxpass    <BR>    2->relevant-JJ-advcl    <BR>      3->because-IN-mark    <BR>      3->they-PRP-nsubj    <BR>      3->are-VBP-cop    <BR>      3->entry-NN-prep_to    <BR>        4->one-CD-num    <BR>          5->than-IN-quantmod    <BR>            6->more-JJR-mwe    <BR>  1->means-VBZ-parataxis    <BR>    2->this-DT-nsubj    <BR>    2->one-CD-ccomp    <BR>      3->that-IN-mark    <BR>      3->text-NN-nsubj    <BR>        4->the-DT-det    <BR>      3->is-VBZ-cop    <BR>      3->than-IN-advmod    <BR>        4->longer-RBR-advmod    <BR>      3->listed-VBN-rcmod    <BR>        4->one-CD-prep_in    <BR>        4->statements-NNS-nsubjpass    <BR>        4->are-VBP-auxpass    <BR>        4->simply-RB-advmod    <BR>'
p244
sg11
F4.4641909
sg12
S'The document structure, inspired by encyclopedias and glossaries, is organised at a number of levels. At the top level, a heading is generated for every concept in the ontology; at the next level, each entry is subdivided into logically-based headings like \xe2\x80\x98Definition\xe2\x80\x99 and \xe2\x80\x98Examples\xe2\x80\x99; at the next, sentences are aggregated when they have parts in common; at the lowest level, phrases are hyperlinked to concept headings. '
p245
sg14
F0.01635233966640425
saa(lp246
S'W11-2821-42'
p247
a(dp248
g5
S'This is addressed through a navigation task in which people were asked to locate information in either an organised text or an unorganised one and then give a judgement on how difficult the information was to find.'
p249
sg7
S'The study design is between-subjects in two independent groups. Participants were 57 members of the ACL special interest groups SIGGEN8 and SIGdial9.  '
p250
sg9
S'0->addressed-VBN-root             0.0117998847901<BR>  1->This-DT-nsubjpass             0.0<BR>  1->is-VBZ-auxpass    <BR>  1->task-NN-prep_through    <BR>    2->a-DT-det    <BR>    2->navigation-NN-nn    <BR>    2->asked-VBN-rcmod    <BR>      3->task-NN-prep_in    <BR>      3->people-NNS-nsubjpass    <BR>      3->were-VBD-auxpass    <BR>      3->locate-VB-xcomp    <BR>        4->people-NNS-xsubj    <BR>        4->to-TO-aux    <BR>        4->information-NN-dobj    0.0967607432758         0.0967607432758<BR>        4->text-NN-prep_in    <BR>          5->either-CC-preconj    <BR>          5->an-DT-det    <BR>          5->organised-JJ-amod    <BR>          5->one-NN-conj_or    <BR>            6->an-DT-det    <BR>            6->unorganised-JJ-amod    <BR>        4->one-NN-prep_in    <BR>        4->give-VB-conj_and    <BR>          5->then-RB-advmod    <BR>          5->judgement-NN-dobj    <BR>            6->a-DT-det    <BR>            6->was-VBD-prepc_on    <BR>              7->difficult-JJ-dep    <BR>                8->how-WRB-advmod    <BR>              7->information-NN-nsubj    <BR>                8->the-DT-det    <BR>              7->find-VB-xcomp    <BR>                8->information-NN-xsubj    <BR>                8->to-TO-aux    <BR>      3->give-VB-xcomp    <BR>'
p251
sg11
F-1.1586266
sg12
S'Only one attempts further discourse structuring: Laing et al.\xe2\x80\x99s system for verbalising medical ontologies organises text according to rhetorical structure.  The evaluation study reported here focusses on the following question: Does the organisation just described help people to understand and navigate a text in spite of its longer length? '
p252
sg14
F0.01622633401826323
saa(lp253
S'C08-1122-56'
p254
a(dp255
g5
S'Given a document cluster, CollabRank makes use of the global word relationships in the cluster to evaluate and rank candidate phrases for each single document in the cluster based on the graph-based ranking algorithm.'
p256
sg7
S'Figure 1 gives the framework of the proposed approach.  In the first step of the above framework, different clustering algorithms will yield different clusters. '
p257
sg9
S'0->makes-VBZ-root             0.0138409700913<BR>  1->Given-VBN-prep    <BR>    2->cluster-NN-dep    <BR>      3->a-DT-det    <BR>      3->document-NN-nn    <BR>  1->CollabRank-NNP-nsubj    0.0479341109786         0.0479341109786<BR>  1->use-NN-dobj    0.0179952603434         0.0542808950295<BR>    2->relationships-NNS-prep_of    0.0197180040048<BR>      3->the-DT-det    <BR>      3->global-JJ-amod    0.0599775370622<BR>      3->word-NN-nn    0.0630976128155<BR>      3->cluster-NN-prep_in    0.149960502862<BR>        4->the-DT-det    <BR>        4->evaluate-VB-infmod    0.0157744032039<BR>          5->to-TO-aux    <BR>          5->rank-VB-conj_and    0.00461365669709<BR>          5->phrases-NNS-dobj    0.034238650699<BR>            6->candidate-NN-nn    0.0599775370622<BR>            6->document-NN-prep_for    0.10797156206<BR>              7->each-DT-det    <BR>              7->single-JJ-amod    0.0329913106296<BR>          5->cluster-NN-prep_in    0.149960502862<BR>            6->the-DT-det    <BR>          5->on-IN-prepc_based_on    <BR>          5->algorithm-NN-pobj    0.0749802514309<BR>            6->the-DT-det    <BR>            6->graph-based-JJ-amod    0.0555045466929<BR>            6->ranking-JJ-amod    0.0171193253495<BR>        4->rank-VB-infmod    0.00461365669709<BR>'
p258
sg11
F-1.2260163
sg12
S'Given a document set for keyphrase extraction of each single document, CollabRank first employs the clustering algorithm to group the documents into a few clusters. The documents within each cluster are expected to be topic-related and each cluster can be considered as a context for any document in the cluster. '
p259
sg14
F0.009728103513583245
saa(lp260
S'C08-1122-24'
p261
a(dp262
g5
S'Instead of making only use of the word relationships in a single document, the algorithm can incorporate the \xe2\x80\x9cvoting\xe2\x80\x9d or \xe2\x80\x9crecommendations\xe2\x80\x9d between words in all the documents of the cluster, thus making use of the global information existing in the cluster context.'
p263
sg7
S'The above implementation of the collaborative framework is denoted as CollabRank in this paper. Experiments have been performed on a dataset consisting of 308 news articles with humanannotated keyphrases, and the results demonstrate the good effectiveness of the CollabRank approach. '
p264
sg9
S'0->incorporate-VB-root             0.0412829167358<BR>  1->making-VBG-prepc_instead_of    <BR>    2->use-NN-dobj    <BR>      3->only-JJ-amod    <BR>      3->relationships-NNS-prep_of    <BR>        4->the-DT-det    <BR>        4->word-NN-nn    <BR>        4->document-NN-prep_in    <BR>          5->a-DT-det    <BR>          5->single-JJ-amod    <BR>  1->algorithm-NN-nsubj    0.0668307388795         0.0668307388795<BR>    2->the-DT-det    <BR>  1->can-MD-aux    <BR>  1->voting-NN-dobj    0.029291463457         0.0752822648099<BR>    2->the-DT-det    <BR>    2->recommendations-NNS-conj_or    0.0342683662386<BR>      3->words-NNS-prep_between    0.0508621554962<BR>        4->documents-NNS-prep_in    0.0392202092596<BR>          5->all-PDT-predet    <BR>          5->the-DT-det    <BR>          5->cluster-NN-prep_of    0.222769129598<BR>            6->the-DT-det    <BR>  1->recommendations-NNS-dobj    <BR>  1->making-VBG-partmod    <BR>    2->thus-RB-advmod    <BR>    2->use-NN-dobj    <BR>      3->information-NN-prep_of    <BR>        4->the-DT-det    <BR>        4->global-JJ-amod    <BR>        4->existing-VBG-amod    <BR>        4->context-NN-prep_in    <BR>          5->the-DT-det    <BR>          5->cluster-NN-nn    <BR>'
p265
sg11
F-0.2718331
sg12
S'In this study, the cluster context is obtained by applying the clustering algorithm on the document set, and we have investigated how the cluster context influences the keyphrase extraction performance by employing different clustering algorithms. The graph-based ranking algorithm is employed for collaborative keyphrase extraction for each document in a specified cluster. '
p266
sg14
F0.00919632083428603
saa(lp267
S'C08-1122-22'
p268
a(dp269
g5
S'In this study, the cluster context is obtained by applying the clustering algorithm on the document set, and we have investigated how the cluster context influences the keyphrase extraction performance by employing different clustering algorithms.'
p270
sg7
S'The graph-based ranking algorithm is employed for collaborative keyphrase extraction for each document in a specified cluster. Instead of making only use of the word relationships in a single document, the algorithm can incorporate the \xe2\x80\x9cvoting\xe2\x80\x9d or \xe2\x80\x9crecommendations\xe2\x80\x9d between words in all the documents of the cluster, thus making use of the global information existing in the cluster context. '
p271
sg9
S'0->obtained-VBN-root             0.0342683662386<BR>  1->study-NN-prep_in    <BR>    2->this-DT-det    <BR>  1->context-NN-nsubjpass    0.155938390719         0.189353760158<BR>    2->the-DT-det    <BR>    2->cluster-NN-nn    0.222769129598<BR>  1->is-VBZ-auxpass    <BR>  1->applying-VBG-agent    <BR>    2->algorithm-NN-dobj    0.0668307388795         0.0987961412947<BR>      3->the-DT-det    <BR>      3->clustering-VBG-amod    0.0762932332442<BR>      3->set-NN-prep_on    0.029291463457<BR>        4->the-DT-det    <BR>        4->document-NN-nn    0.222769129598<BR>  1->investigated-VBN-conj_and    <BR>    2->we-PRP-nsubj    <BR>    2->have-VBP-aux    <BR>    2->influences-VBZ-ccomp    <BR>      3->how-WRB-advmod    <BR>      3->context-NN-nsubj    <BR>        4->the-DT-det    <BR>        4->cluster-NN-nn    <BR>      3->performance-NN-dobj    <BR>        4->the-DT-det    <BR>        4->keyphrase-JJ-amod    <BR>        4->extraction-NN-nn    <BR>      3->employing-VBG-prepc_by    <BR>        4->algorithms-NNS-dobj    <BR>          5->different-JJ-amod    <BR>          5->clustering-VBG-amod    <BR>'
p272
sg11
F0.090741562
sg12
S'Based on the above assumption, we propose a novel framework for collaborative singledocument keyphrase extraction by making use of the additional information from multiple documents within an appropriate cluster context. The collaborative framework for keyphrase extraction consists of the step of obtaining the cluster context and the step of collaborative keyphrase extraction in each cluster. '
p273
sg14
F0.009028856408952398
saa(lp274
S'C08-1122-104'
p275
a(dp276
g5
S'All the candidate phrases in the document are ranked in decreasing order of the phrase scores and the top n phrases are selected as the keyphrases of the document.'
p277
sg7
S'n ranges from 1 to 20 in this study. Similarly for SingleRank, the phrase score is computed based on the document-level saliency scores of the words.  '
p278
sg9
S'0->ranked-VBN-root             0.00555804744083<BR>  1->phrases-NNS-nsubjpass    0.034238650699         0.0673959166072<BR>    2->All-PDT-predet    <BR>    2->the-DT-det    <BR>    2->candidate-NN-nn    0.0599775370622<BR>    2->document-NN-prep_in    0.10797156206<BR>      3->the-DT-det    <BR>  1->are-VBP-auxpass    <BR>  1->order-NN-prep_in    <BR>    2->decreasing-VBG-amod    <BR>    2->scores-NNS-prep_of    <BR>      3->the-DT-det    <BR>      3->phrase-NN-nn    <BR>  1->selected-VBN-conj_and    <BR>    2->phrases-NNS-nsubjpass    <BR>      3->the-DT-det    <BR>      3->top-JJ-amod    <BR>      3->n-NN-nn    <BR>    2->are-VBP-auxpass    <BR>    2->keyphrases-NNS-prep_as    <BR>      3->the-DT-det    <BR>      3->document-NN-prep_of    <BR>        4->the-DT-det    <BR>'
p279
sg11
F-1.761714
sg12
S'For instance, in the following sentence: \xe2\x80\x9cMad/JJ cow/NN disease/NN has/VBZ killed/VBN 10,000/CD cattle/NNS\xe2\x80\x9d, the candidate phrases are \xe2\x80\x9cMad cow disease\xe2\x80\x9d and \xe2\x80\x9ccattle\xe2\x80\x9d. The score of a candidate phrase pi is computed by summing the cluster-level saliency scores of the words contained in the phrase.  '
p280
sg14
F0.008704105907979511
saa(lp281
S'C08-1122-14'
p282
a(dp283
g5
S'CollabRank is implemented by first employing the clustering algorithm to obtain appropriate document clusters, and then using the graph-based ranking algorithm for collaborative single-document keyphrase extraction within each cluster.'
p284
sg7
S'Experimental results demonstrate the encouraging performance of the proposed approach. Different clustering algorithms have been investigated and we find that the system performance relies positively on the quality of document clusters.  '
p285
sg9
S'0->implemented-VBN-root             0.111344900032<BR>  1->CollabRank-NNP-nsubjpass    0.137181237832         0.137181237832<BR>  1->is-VBZ-auxpass    <BR>  1->employing-VBG-agent    <BR>    2->first-RB-advmod    <BR>    2->algorithm-NN-dobj    0.120166928243         0.128674083038<BR>      3->the-DT-det    <BR>      3->clustering-VBG-amod    0.137181237832<BR>    2->obtain-VB-xcomp    <BR>      3->to-TO-aux    <BR>      3->clusters-NNS-dobj    <BR>        4->appropriate-JJ-amod    <BR>        4->document-NN-nn    <BR>    2->using-VBG-conj_and    <BR>      3->then-RB-advmod    <BR>      3->algorithm-NN-dobj    <BR>        4->the-DT-det    <BR>        4->graph-based-JJ-amod    <BR>        4->ranking-JJ-amod    <BR>        4->extraction-NN-prep_for    <BR>          5->collaborative-JJ-amod    <BR>          5->single-document-JJ-amod    <BR>          5->keyphrase-NN-nn    <BR>          5->cluster-NN-prep_within    <BR>            6->each-DT-det    <BR>  1->using-VBG-agent    <BR>'
p286
sg11
F2.1649453
sg12
S'Previous methods usually conduct the keyphrase extraction task for single documents separately without interactions for each document, under the assumption that the documents are considered independent of each other. This paper proposes a novel approach named CollabRank to collaborative single-document keyphrase extraction by making use of mutual influences of multiple documents within a cluster context. '
p287
sg14
F0.008359484796515207
saa(lp288
S'C08-1122-99'
p289
a(dp290
g5
S'After the scores of all candidate words in the cluster have been computed, candidate phrases are selected and evaluated for each single document in the cluster.'
p291
sg7
S'The candidate words (i.e. nouns and adjectives) of a specified document d in the cluster, which is a subset of V, are marked in the document text, and sequences of adjacent candidate words are collapsed into a multi-word phrase. The phrases ending with an adjective are not allowed, and only the phrases ending with a noun are collected as the candidate phrases for the document. '
p292
sg9
S'0->selected-VBN-root             0.00922731339419<BR>  1->computed-VBN-advcl    <BR>    2->After-IN-mark    <BR>    2->scores-NNS-nsubjpass    <BR>      3->the-DT-det    <BR>      3->words-NNS-prep_of    <BR>        4->all-DT-det    <BR>        4->candidate-NN-nn    <BR>        4->cluster-NN-prep_in    <BR>          5->the-DT-det    <BR>    2->have-VBP-aux    <BR>    2->been-VBN-auxpass    <BR>  1->phrases-NNS-nsubjpass    0.034238650699         0.0471080938806<BR>    2->candidate-NN-nn    0.0599775370622<BR>  1->are-VBP-auxpass    <BR>  1->evaluated-VBN-conj_and    <BR>    2->phrases-NNS-nsubjpass    <BR>  1->document-NN-prep_for    <BR>    2->each-DT-det    <BR>    2->single-JJ-amod    <BR>    2->cluster-NN-prep_in    <BR>      3->the-DT-det    <BR>'
p293
sg11
F-1.7408633
sg12
S'Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any words falls below a given threshold (0.0001 in this study). For SingleRank, the saliency score WordScoredoc(vi) for word vi is computed in the same iterative way based on the local graph for the single document.  '
p294
sg14
F0.008199081027126435
saa(lp295
S'C08-1122-21'
p296
a(dp297
g5
S'The collaborative framework for keyphrase extraction consists of the step of obtaining the cluster context and the step of collaborative keyphrase extraction in each cluster.'
p298
sg7
S'In this study, the cluster context is obtained by applying the clustering algorithm on the document set, and we have investigated how the cluster context influences the keyphrase extraction performance by employing different clustering algorithms. The graph-based ranking algorithm is employed for collaborative keyphrase extraction for each document in a specified cluster. '
p299
sg9
S'0->consists-VBZ-root             0.0412829167358<BR>  1->framework-NN-nsubj    0.0762932332442         0.121124043955<BR>    2->The-DT-det    <BR>    2->collaborative-JJ-amod    0.133661477759<BR>    2->extraction-NN-prep_for    0.137270732409<BR>      3->keyphrase-JJ-amod    0.137270732409<BR>  1->step-NN-prep_of    <BR>    2->the-DT-det    <BR>    2->obtaining-VBG-prepc_of    <BR>      3->context-NN-dobj    0.155938390719         0.154030903567<BR>        4->the-DT-det    <BR>        4->cluster-NN-nn    0.222769129598<BR>        4->step-NN-conj_and    0.0685367324771<BR>          5->the-DT-det    <BR>          5->extraction-NN-prep_of    0.137270732409<BR>            6->collaborative-JJ-amod    0.133661477759<BR>            6->keyphrase-NN-nn    0.137270732409<BR>            6->cluster-NN-prep_in    0.222769129598<BR>              7->each-DT-det    <BR>      3->step-NN-dobj    <BR>'
p300
sg11
F0.44117391
sg12
S'Moreover, document keyphrases have been successfully used in the following IR and NLP tasks: document indexing (Gutwin et al., 1999), document classification (Krulwich and Burkey, 1996), document cluster Based on the above assumption, we propose a novel framework for collaborative singledocument keyphrase extraction by making use of the additional information from multiple documents within an appropriate cluster context. '
p301
sg14
F0.00813682637116251
saa(lp302
S'P99-1026-103'
p303
a(dp304
g5
S'The contexts created by the utterance understanding module can also be accessed by the response generation module so that it can produce responses based on the belief state in the context with the highest priority at a point in time.'
p305
sg7
S"We do not discuss the timing of the responses here, but, generally speaking, a reasonable strategy is to respond when the user pauses. In Japanese dialogue systems, producing a backchannel is effective when the user's intention is not clear at that point in time, but determining the content of responses in a real-time spoken dialogue system is also beyond the scope of this paper.  "
p306
sg9
S'0->accessed-VBN-root             0.00674761988471<BR>  1->contexts-NNS-nsubjpass    0.0472333391929         0.0450616648131<BR>    2->The-DT-det    <BR>    2->created-VBN-partmod    0.0337380994235<BR>      3->module-NN-agent    0.055331448315<BR>        4->the-DT-det    <BR>        4->utterance-JJ-amod    0.0560575328182<BR>        4->understanding-NN-nn    0.0329479043156<BR>  1->can-MD-aux    <BR>  1->also-RB-advmod    <BR>  1->be-VB-auxpass    <BR>  1->module-NN-agent    <BR>    2->the-DT-det    <BR>    2->response-NN-nn    <BR>    2->generation-NN-nn    <BR>  1->produce-VB-advcl    <BR>    2->so-RB-advmod    <BR>    2->that-IN-mark    <BR>    2->it-PRP-nsubj    <BR>    2->can-MD-aux    <BR>    2->responses-NNS-dobj    0.0207419160899         0.0207419160899<BR>    2->on-IN-prepc_based_on    <BR>    2->state-NN-pobj    <BR>      3->the-DT-det    <BR>      3->belief-NN-nn    <BR>      3->context-NN-prep_in    <BR>        4->the-DT-det    <BR>        4->priority-NN-prep_with    <BR>          5->the-DT-det    <BR>          5->highest-JJS-amod    <BR>          5->point-NN-prep_at    <BR>            6->a-DT-det    <BR>            6->time-NN-prep_in    <BR>'
p307
sg11
F-1.6665846
sg12
S'Although this heuristics seems rather simple, we have found it works well in our experimental systems. Although some additional techniques, such as discarding redundant contexts and multiplying a weight w (w > 1) to the priority of each context after the Step 4, are effective, details are not discussed here for lack of space.  '
p308
sg14
F0.009450928642418591
saa(lp309
S'P99-1026-138'
p310
a(dp311
g5
S'The response generation module is invoked when the user pauses, and plans responses based on the belief state of the context with the highest priority.'
p312
sg7
S'The response strategy is similar to that of previous frame-based dialogue systems (Bobrow et al., 1977). The speech production module outputs speech according to orders from the response generation module. '
p313
sg9
S'0->invoked-VBN-root             0.00674761988471<BR>  1->module-NN-nsubjpass    0.055331448315         0.0351642646834<BR>    2->The-DT-det    <BR>    2->response-NN-nn    0.0280287664091<BR>    2->generation-NN-nn    0.022132579326<BR>  1->is-VBZ-auxpass    <BR>  1->pauses-VBZ-advcl    <BR>    2->when-WRB-advmod    <BR>    2->user-NN-nsubj    <BR>      3->the-DT-det    <BR>    2->plans-VBZ-conj_and    <BR>      3->user-NN-nsubj    <BR>      3->responses-NNS-dobj    0.0207419160899         0.0207419160899<BR>      3->on-IN-prepc_based_on    <BR>      3->state-NN-pobj    <BR>        4->the-DT-det    <BR>        4->belief-NN-nn    <BR>        4->context-NN-prep_of    <BR>          5->the-DT-det    <BR>          5->priority-NN-prep_with    <BR>            6->the-DT-det    <BR>            6->highest-JJS-amod    <BR>  1->plans-VBZ-advcl    <BR>'
p314
sg11
F-1.7043213
sg12
S'A belief state is represented by a frame (Bobrow et al., 1977); thus, a speech act representation is a command for changing the slot value of a frame. Although a more sophisticated model would be required for the system to engage in a complicated dialogue, frame representations are sufficient for our tasks. '
p315
sg14
F0.008855701190884661
saa(lp316
S'P99-1026-105'
p317
a(dp318
g5
S"In Japanese dialogue systems, producing a backchannel is effective when the user's intention is not clear at that point in time, but determining the content of responses in a real-time spoken dialogue system is also beyond the scope of this paper. "
p319
sg7
S'Here we explain ISSS using a simple example. Consider again &quot;Wednesday next week&quot;. '
p320
sg9
S'0->effective-JJ-root             0.0140143832046<BR>  1->systems-NNS-prep_in    <BR>    2->Japanese-JJ-amod    <BR>    2->dialogue-NN-nn    <BR>  1->producing-VBG-csubj    0.00674761988471         0.00674761988471<BR>    2->backchannel-NN-dobj    0.006747619884710.00674761988471         0.00674761988471<BR>      3->a-DT-det    <BR>  1->is-VBZ-cop    <BR>  1->clear-JJ-advcl    <BR>    2->when-WRB-advmod    <BR>    2->intention-NN-nsubj    <BR>      3->user-NN-poss    <BR>        4->the-DT-det    <BR>    2->is-VBZ-cop    <BR>    2->not-RB-neg    <BR>    2->point-NN-prep_at    <BR>      3->that-DT-det    <BR>      3->time-NN-prep_in    <BR>  1->is-VBZ-conj_but    <BR>    2->determining-VBG-csubj    <BR>      3->content-NN-dobj    <BR>        4->the-DT-det    <BR>        4->responses-NNS-prep_of    <BR>          5->system-NN-prep_in    <BR>            6->a-DT-det    <BR>            6->spoken-VBN-amod    <BR>              7->real-time-RB-advmod    <BR>            6->dialogue-NN-nn    <BR>    2->also-RB-advmod    <BR>    2->scope-NN-prep_beyond    <BR>      3->the-DT-det    <BR>      3->paper-NN-prep_of    <BR>        4->this-DT-det    <BR>'
p321
sg11
F-1.720995
sg12
S'The contexts created by the utterance understanding module can also be accessed by the response generation module so that it can produce responses based on the belief state in the context with the highest priority at a point in time. We do not discuss the timing of the responses here, but, generally speaking, a reasonable strategy is to respond when the user pauses. '
p322
sg14
F0.008749624097160815
saa(lp323
S'P99-1026-93'
p324
a(dp325
g5
S'For each context, if the top of the stack is an SU, empty the stack and update the belief state according to the content of the SU.'
p326
sg7
S'Increase the priority by the square of the length (i.e., the number of words) of this SU.  4. '
p327
sg9
S'0->empty-VB-root             0.00674761988471<BR>  1->context-NN-prep_for    <BR>    2->each-DT-det    <BR>  1->SU-NNP-advcl    <BR>    2->if-IN-mark    <BR>    2->top-NN-nsubj    0.0134952397694         0.0236166695965<BR>      3->the-DT-det    <BR>      3->stack-NN-prep_of    0.0337380994235<BR>        4->the-DT-det    <BR>    2->is-VBZ-cop    <BR>    2->an-DT-det    <BR>  1->stack-NN-dobj    0.0337380994235         0.0337380994235<BR>    2->the-DT-det    <BR>  1->update-VB-conj_and    <BR>    2->state-NN-dobj    <BR>      3->the-DT-det    <BR>      3->belief-NN-nn    <BR>    2->to-TO-prepc_according_to    <BR>    2->content-NN-pobj    <BR>      3->the-DT-det    <BR>      3->SU-NNP-prep_of    <BR>        4->the-DT-det    <BR>'
p328
sg11
F-1.6552612
sg12
S'When a reduce operation is performed, increase the priority of the context by the priority assigned to the rule used for the reduce operation. 3. '
p329
sg14
F0.008477560904730239
saa(lp330
S'P99-1026-118'
p331
a(dp332
g5
S"The top of the stack in (2b) is an SU, thus (2c) is created, whose belief state contains the user's intention of meeting room reservation on Wednesday this week."
p333
sg7
S"We assume that 'Wednesday' means Wednesday this week by default if this utterance was made on Monday, and this is described in the additional conditions in Rule (I). After 'next week' is inputted, NP is pushed to the stacks of all contexts, resulting in (3a) and (3b). "
p334
sg9
S'0->created-VBN-root             0.0337380994235<BR>  1->top-NN-nsubjpass    0.0134952397694         0.030450813387<BR>    2->The-DT-det    <BR>    2->stack-NN-prep_of    0.0337380994235<BR>      3->the-DT-det    <BR>      3->SU-NNP-dep    0.101214298271<BR>        4->in-IN-mark    <BR>        4->2b-NNS-nsubj    0.0134952397694<BR>        4->is-VBZ-cop    <BR>        4->an-DT-det    <BR>        4->thus-RB-advmod    0.0140143832046<BR>      3->2c-NNP-appos    0.00674761988471<BR>  1->is-VBZ-auxpass    <BR>  1->contains-VBZ-ccomp    <BR>    2->state-NN-nsubj    <BR>      3->whose-WP$-poss    <BR>      3->belief-JJ-amod    <BR>    2->intention-NN-dobj    0.0186858442727         0.0575186468697<BR>      3->user-NN-poss    0.0829676643595<BR>        4->the-DT-det    <BR>      3->reservation-NN-prep_of    0.033198868989<BR>        4->meeting-NN-nn    0.033198868989<BR>        4->room-NN-nn    0.0829971724725<BR>        4->Wednesday-NNP-prep_on    0.0940634621355<BR>    2->week-NN-tmod    <BR>      3->this-DT-det    <BR>'
p335
sg11
F-0.73563303
sg12
S"When 'Wednesday' is inputted, its lexical feature structure is created and pushed to the stack. Since Rule (I) can be applied to this stack, (2b) in Figure 2 is created. "
p336
sg14
F0.008377071317506814
saa(lp337
S'P99-1026-10'
p338
a(dp339
g5
S"We also use speech act in this paper to mean a command that updates the hearer's belief state about the speaker's intention and the context of the dialogue."
p340
sg7
S'In this paper, a system using this assumption is called an interval-based system. The above assumption no longer holds when no restrictions are placed on the way the user speaks. '
p341
sg9
S'0->use-VBP-root             0.0256109616733<BR>  1->We-PRP-nsubj             0.0<BR>  1->also-RB-advmod    <BR>  1->act-NN-dobj    0.0606701664185         0.085201704037<BR>    2->speech-NN-nn    0.109733241656<BR>  1->paper-NN-prep_in    <BR>    2->this-DT-det    <BR>    2->mean-VB-infmod    <BR>      3->to-TO-aux    <BR>      3->command-NN-dobj    <BR>        4->a-DT-det    <BR>        4->updates-VBD-rcmod    <BR>          5->command-NN-nsubj    <BR>          5->state-NN-dobj    <BR>            6->hearer-NN-poss    <BR>              7->the-DT-det    <BR>            6->belief-NN-nn    <BR>          5->intention-NN-prep_about    <BR>            6->speaker-NN-poss    <BR>              7->the-DT-det    <BR>            6->context-NN-conj_and    <BR>              7->the-DT-det    <BR>              7->dialogue-NN-prep_of    <BR>                8->the-DT-det    <BR>          5->context-NN-prep_about    <BR>'
p342
sg11
F-0.87275855
sg12
S'Most previous spoken dialogue systems (e.g. systems by Allen et al. (1996), Zue et al. (1994) and Peckham (1993)) assume that the user makes one utterance unit in each speech interval, unless the push-to-talk method is used. Here, by utterance unit we mean a phrase from which a speech act representation is derived, and it corresponds to a sentence in written language. '
p343
sg14
F0.008321510764255401
saa(lp344
S'P99-1026-123'
p345
a(dp346
g5
S"Before 'next week' is inputted, the interpretation that the user wants to book a room on Wednesday this week has the highest priority, and then after that, the interpretation that the user wants to book a room on Wednesday next week has the highest "
p347
sg7
S'priority. Thus, by this method, the most plausible interpretation can be obtained in an incremental way.  '
p348
sg9
S'0->has-VBZ-root             0.0276657241575<BR>  1->inputted-VBN-advcl    <BR>    2->Before-IN-mark    <BR>    2->week-NN-nsubjpass    <BR>      3->next-JJ-amod    <BR>    2->is-VBZ-auxpass    <BR>  1->interpretation-NN-nsubj    0.022132579326         0.0580931027119<BR>    2->the-DT-det    <BR>    2->wants-VBZ-dep    0.0165994344945<BR>      3->that-IN-mark    <BR>      3->user-NN-nsubj    0.0829676643595<BR>        4->the-DT-det    <BR>      3->book-NN-prep_to    0.0497983034835<BR>      3->room-NN-dobj    0.0829971724725<BR>        4->a-DT-det    <BR>        4->Wednesday-NNP-prep_on    0.0940634621355<BR>  1->week-NN-nsubj    <BR>    2->this-DT-det    <BR>  1->priority-NN-dobj    0.0674761988471         0.0506071491353<BR>    2->the-DT-det    <BR>    2->highest-JJS-amod    0.0337380994235<BR>  1->has-VBZ-conj_and    <BR>    2->then-RB-advmod    <BR>    2->that-DT-prep_after    <BR>    2->interpretation-NN-nsubj    <BR>      3->the-DT-det    <BR>      3->wants-VBZ-dep    <BR>        4->that-IN-mark    <BR>        4->user-NN-nsubj    <BR>          5->the-DT-det    <BR>        4->book-NN-prep_to    <BR>        4->room-NN-dobj    <BR>          5->a-DT-det    <BR>          5->Wednesday-NNP-prep_on    <BR>    2->week-NN-nsubj    <BR>      3->next-JJ-amod    <BR>    2->highest-JJS-dobj    <BR>      3->the-DT-det    <BR>'
p349
sg11
F-0.84383755
sg12
S'Then Rule (II) is applied to (3a), making (4b). Rule (I) can be applied to (4b), and then (4c) is created and is turned into (4d), which has the highest priority. '
p350
sg14
F0.008240610800676488
saa(lp351
S'J81-3002-133'
p352
a(dp353
g5
S"Finally, any formula of the form &quot;for(x,p,c)&quot; can be replaced by just the formula c, in which all occurrences of x have been replaced by the formula: those(x,p) representing the subset of x's domain whose elements satisfy p. This replacement takes place in the data base component of our system."
p354
sg7
S'The reader can now verify that the representations shown in Figures 1 and 2 are equivalent.  In our NL subset, quantifier hierarchy obeys the following three rules, which perhaps are too simplistic, but have proved useful. '
p355
sg9
S'0->replaced-VBN-root             0.0201595148925<BR>  1->Finally-RB-advmod    <BR>  1->formula-NN-nsubjpass    0.0447989219833         0.040319029785<BR>    2->any-DT-det    <BR>    2->form-NN-prep_of    0.0358391375866<BR>      3->the-DT-det    <BR>      3->for-IN-prep    <BR>  1->x-SYM-dep    <BR>    2->p-NN-appos    <BR>    2->c-SYM-appos    <BR>  1->can-MD-aux    <BR>  1->be-VB-auxpass    <BR>  1->c-NN-agent    <BR>    2->just-RB-advmod    <BR>    2->the-DT-det    <BR>    2->formula-NN-nn    <BR>    2->replaced-VBN-rcmod    <BR>      3->c-NN-prep_in    <BR>      3->occurrences-NNS-nsubjpass    <BR>        4->all-DT-det    <BR>        4->x-NNP-prep_of    <BR>      3->have-VBP-aux    <BR>      3->been-VBN-auxpass    <BR>      3->formula-NN-agent    <BR>        4->the-DT-det    <BR>      3->representing-VBG-parataxis    <BR>        4->those-DT-nsubj    <BR>          5->x-SYM-dep    <BR>            6->p-NN-appos    <BR>        4->subset-NN-dobj    0.0111997304958         0.0121597073955<BR>          5->the-DT-det    <BR>          5->domain-NN-prep_of    0.0515187602808<BR>            6->x-NNP-poss    0.0<BR>          5->satisfy-VB-rcmod    0.0067198382975<BR>            6->elements-NNS-nsubj    0.00447989219833<BR>              7->subset-NN-poss    0.0111997304958<BR>            6->p-NN-dobj    0.0<BR>'
p356
sg11
F-1.3876144
sg12
S'This convention is particularly useful when negation is involved. For instance, &quot;No tengo un centavo&quot; (I have not a cent) would be wrongly represented in the &quot;exactly one&quot; interpretation: it would state that the number of cents I possess is not one,which means it can either be 0,2,3, etc. '
p357
sg14
F0.004926517402022
saa(lp358
S'J81-3002-64'
p359
a(dp360
g5
S'But in a type-checking system in which the first argument of the relation &quot;live&quot; is associated with the human domain, and in which employees\xe2\x80\x94and not salaries\xe2\x80\x94are known to belong to this same domain, the first reading is not even possible.'
p361
sg7
S'Ambiguities concerning different meanings of a word can often be resolved through domain checking. Types can also be used to place modifiers other than relative clauses. '
p362
sg9
S'0->takes-VBZ-root             0.0201595148925<BR>  1->replacement-NN-nsubj    0.00223994609917         0.00223994609917<BR>    2->This-DT-det    <BR>  1->place-NN-dobj    0.0123619946302         0.0123619946302<BR>  1->component-NN-prep_in    <BR>    2->the-DT-det    <BR>    2->data-NN-nn    <BR>    2->base-NN-nn    <BR>    2->system-NN-prep_of    <BR>      3->our-PRP$-poss    <BR>'
p363
sg11
F-1.5342667
sg12
S'What is the salary of the employee who lives in Lomas? From syntax alone, there is no way to decide whether the antecedent of the relative clause is &quot;the salary of the employee&quot; or &quot;the employee&quot;. '
p364
sg14
F0.00490544552064742
saa(lp365
S'J81-3002-313'
p366
a(dp367
g5
S') can be considered as a variant for &quot;Tomas vive en k&quot; (Tom lives in k), in which &quot;en k&quot; has been moved to the beginning of the sentence and replaced by &quot;Donde&quot;.'
p368
sg7
S"Relative clauses usually undergo similar transformations. For instance, &quot;El empleado cuya jefa es Juana&quot; (The employee whose manager is Joan) can be considered as a variant of &quot;El empleado [la jefa del empleado] es Juana&quot; (the employee [the manager of the employee] is Joan), where &quot;del empleado&quot; has shifted to just before &quot;jefa&quot; to be subsumed, together with &quot;la'', by the relative pronoun &quot;cuya&quot;. "
p369
sg9
S'0->possible-JJ-root             0.0141279938631<BR>  1->But-CC-cc    <BR>  1->system-NN-prep_in    <BR>    2->a-DT-det    <BR>    2->type-checking-JJ-amod    <BR>    2->associated-VBN-rcmod    <BR>      3->system-NN-prep_in    <BR>      3->argument-NN-nsubjpass    <BR>        4->the-DT-det    <BR>        4->first-JJ-amod    <BR>        4->relation-NN-prep_of    <BR>          5->the-DT-det    <BR>          5->live-JJ-amod    <BR>      3->is-VBZ-auxpass    <BR>      3->domain-NN-prep_with    <BR>        4->the-DT-det    <BR>        4->human-JJ-amod    <BR>      3->known-VBN-prep_in    <BR>        4->which-WDT-dobj             0.0<BR>        4->employees-NNS-nsubjpass    <BR>          5->salaries-NNS-dep    <BR>            6->and-CC-cc    <BR>            6->not-RB-dep    <BR>        4->are-VBP-auxpass    <BR>        4->belong-VB-xcomp    <BR>          5->employees-NNS-xsubj    <BR>          5->to-TO-aux    <BR>          5->domain-NN-prep_to    <BR>            6->this-DT-det    <BR>            6->same-JJ-amod    <BR>    2->known-VBN-conj_and    <BR>  1->known-VBN-prep_in    <BR>  1->reading-NN-nsubj    0.0067198382975         0.0119382906273<BR>    2->the-DT-det    <BR>    2->first-JJ-amod    0.0171567429571<BR>  1->is-VBZ-cop    <BR>  1->not-RB-neg    <BR>  1->even-RB-advmod    <BR>'
p370
sg11
F-1.7462055
sg12
S'Wh-questions, on the other hand, often require modifiers to be moved around and replaced by pronouns. For instance, &quot;Donde vive Tomas?&quot; (Where does Tom live? '
p371
sg14
F0.0047599278799452605
saa(lp372
S'J81-3002-157'
p373
a(dp374
g5
S'In the logic L3, the predication is assigned the &quot;pointless&quot; truth value; but in an improvement of this system, we are proposing the use of a fourth truth value, called &quot;mixed&quot;, for this situation.'
p375
sg7
S'It seems more appropriate to differentiate &quot;pointless&quot; and &quot;mixed&quot;, so that the system has easy access to locally detected semantic information, in case it needs to take further action. Distributive and collective plurals are distinguished in the lexicon by syntactically marking the relation they translate into. '
p376
sg9
S'0->considered-VBN-root             0.0156796226942<BR>  1->can-MD-aux    <BR>  1->be-VB-auxpass    <BR>  1->variant-NN-prep_as    <BR>    2->a-DT-det    <BR>    2->vive-NNP-prep_for    <BR>      3->Tomas-NNP-nn    <BR>      3->k-NN-prep_en    <BR>      3->lives-NNS-dep    <BR>        4->Tom-NNP-nn    <BR>        4->k-NN-prep_in    <BR>    2->moved-VBN-rcmod    <BR>      3->variant-NN-prep_in    <BR>      3->k-NN-nsubjpass    0.0         0.00559986524791<BR>        4->en-JJ-amod    0.0111997304958<BR>      3->has-VBZ-aux    <BR>      3->been-VBN-auxpass    <BR>      3->beginning-NN-prep_to    <BR>        4->the-DT-det    <BR>        4->sentence-NN-prep_of    <BR>          5->the-DT-det    <BR>      3->replaced-VBN-conj_and    <BR>        4->k-NN-nsubjpass    <BR>        4->Donde-NNP-prep_by    <BR>    2->replaced-VBN-rcmod    <BR>'
p377
sg11
F-1.7296922
sg12
S'Notice that both distributive and respective plurals presuppose that the set of formulas to be tested all have the same truth value. Whenever such a presupposition is not satisfied, the plural predication is neither true nor false. '
p378
sg14
F0.004555741022897706
saa(lp379
S'J81-3002-124'
p380
a(dp381
g5
S"for(x,p,c) the intuitive meaning of which is: &quot;c holds for the set E of all x's in x's domain which satisfy p&quot;."
p382
sg7
S"In the formula c, the set E will be represented simply by the variable x, so that x plays a double role. Each quantification is thus assigned an equivalent &quot;for&quot; expression, in which the determiner's meaning is represented. "
p383
sg9
S'0->assigned-VBN-root             0.00447989219833<BR>  1->L3-NN-prep_in    <BR>    2->the-DT-det    <BR>    2->logic-NN-nn    <BR>  1->predication-NN-nsubjpass    0.00447989219833         0.00447989219833<BR>    2->the-DT-det    <BR>  1->is-VBZ-auxpass    <BR>  1->value-NN-dobj    0.0313592453883         0.0209061635922<BR>    2->the-DT-det    <BR>    2->pointless-JJ-amod    0.0156796226942<BR>    2->truth-NN-nn    0.0156796226942<BR>  1->proposing-VBG-conj_but    <BR>    2->improvement-NN-prep_in    <BR>      3->an-DT-det    <BR>      3->system-NN-prep_of    <BR>        4->this-DT-det    <BR>    2->we-PRP-nsubj    <BR>    2->are-VBP-aux    <BR>    2->use-NN-dobj    <BR>      3->the-DT-det    <BR>      3->value-NN-prep_of    <BR>        4->a-DT-det    <BR>        4->fourth-JJ-amod    <BR>        4->truth-NN-nn    <BR>        4->called-VBN-partmod    <BR>          5->mixed-JJ-acomp    <BR>    2->situation-NN-prep_for    <BR>      3->this-DT-det    <BR>'
p384
sg11
F-1.8819529
sg12
S"In our example, x's type would be human (the intersection of the human and the animal domains). Instead of generating a different quantifier for each determiner, it is useful to represent all quantifications through a single one of the form:  "
p385
sg14
F0.004521146385820331
saa(lp386
S'J81-3002-142'
p387
a(dp388
g5
S'As a general rule, the negation introduced by &quot;no&quot; in a sentence is translated by placing the operator &quot;no&quot; (not) right after the quantification introduced by the subject.'
p389
sg7
S"For instance, &quot;La indemnizacion no compensa el despido de Martin&quot; (The indemnity does not compensate for Martin's dismissal) is represented: la(x,indemnizacion(x),no(el(y,despido-de(Martin,y), compensa(x,y)))) the indemnity not the dismissal-of compensate But negation is not always explicit. The Spanish determiner &quot;ningfin&quot; (no) can be regarded as an implicit negation, since it expresses that no portion of the domain of quantification satisfies the statement involved. "
p390
sg9
S"0->for-IN-root             0.128578647702<BR>  1->x-SYM-dep    <BR>    2->p-NN-appos    <BR>    2->c-SYM-appos    <BR>  1->meaning-NN-pobj    0.0105959953973         0.00641797074824<BR>    2->the-DT-det    <BR>    2->intuitive-JJ-amod    0.00223994609917<BR>  1->is-VBZ-prepc_of    <BR>    2->which-WDT-nsubj             0.0<BR>  1->holds-VBZ-dep    <BR>    2->c-SYM-nsubj    <BR>    2->E-NN-prep_for    <BR>      3->the-DT-det    <BR>      3->set-VBN-amod    <BR>      3->x-NN-prep_of    <BR>        4->all-DT-det    <BR>        4->'s-POS-possessive    <BR>        4->domain-NN-prep_in    <BR>          5->x-NNP-poss    <BR>      3->satisfy-VB-rcmod    <BR>        4->E-NN-nsubj    <BR>        4->p-NN-dobj    <BR>"
p391
sg11
F1.2985705
sg12
S'For instance, &quot;Sabato autografia el libro de cada visitante&quot; (Sabato autographs the book of each visitor) is represented: cada(x,visitante(x),e1(y,libro-de(x,y), autografia(Sabato,y))) each visitor the book-of autographs - Rule 3: When a referential word (a verb, a noun or an adjective) has more than one complement, quantification takes place from right to left: the rightmost complement generates a quantification which dominates the quantification(s) introduced by the leftmost complement(s). For instance, &quot;Raul regala un espejo a cada nifio&quot; (Rahl gives a mirror to each child) is represented: cada(x,nino(x),un(y,espejo(y),regala(Raul,y,x))) each child a mirror gives  '
p392
sg14
F0.004452243662538349
saa(lp393
S'J81-3002-100'
p394
a(dp395
g5
S'If a sentence contains a determiner, a quantification of the form &quot;those(x,p)&quot; is introduced, where x is a typed variable and p is a logical formula in our system.'
p396
sg7
S"Its evaluation yields the set of all x's in x's associated domain which satisfy p. According to the determiner's meaning, presuppositions about the cardinality of such a set are represented within the output formula. For instance, &quot;Three blind mice run&quot; is represented as equal(card(those(x,and(mice(x), and(blind(x),run(x))))),3) which says that the cardinality of the set of those blind mice that run is 3. "
p397
sg9
S'0->translated-VBN-root             0.00223994609917<BR>  1->rule-NN-prep_as    <BR>    2->a-DT-det    <BR>    2->general-JJ-amod    <BR>  1->negation-NN-nsubjpass    0.0313592453883         0.0328525427878<BR>    2->the-DT-det    <BR>    2->introduced-VBN-partmod    0.02687935319<BR>      3->by-IN-prep    <BR>        4->no-RB-pobj    <BR>      3->sentence-NN-prep_in    0.040319029785<BR>        4->a-DT-det    <BR>  1->is-VBZ-auxpass    <BR>  1->placing-VBG-agent    <BR>    2->operator-NN-dobj    0.0067198382975         0.0232954394313<BR>      3->the-DT-det    <BR>      3->introduced-VBN-rcmod    0.02687935319<BR>        4->no-RB-nsubj    <BR>          5->not-RB-dep    <BR>          5->right-RB-advmod    0.0201595148925<BR>          5->quantification-NN-prep_after    0.0358391375866<BR>            6->the-DT-det    <BR>        4->subject-NN-prep_by    0.02687935319<BR>          5->the-DT-det    <BR>'
p398
sg11
F-1.8151563
sg12
S'Our treatment of quantification has been devised to account for those presuppositions induced by NL quantifiers. We prefer to call them &quot;determiners&quot;, as they include all articles, cardinal numbers and words such as &quot;some&quot;, &quot;many&quot;, etc. '
p399
sg14
F0.004391494763268921
saa(lp400
S'C00-1073-75'
p401
a(dp402
g5
S"For each of the 3 attributes, 4 variables track whether the system has obtained the attribute's value, the system's confidence in the value (if obtained), the number of times the system has asked the user about the attribute, and the type of ASR grammar most recently used to ask for the attribute."
p403
sg7
S'The formal state space S maintained by NJFun for the purposes of learning is much simpler than the operations vector, due to the data sparsity concerns already discussed. The dialogue state space S contains only 7 variables, as summarized in Figure 3. '
p404
sg9
S'0->used-VBD-root             0.0426006168502<BR>  1->each-DT-prep_for    <BR>    2->attributes-NNS-prep_of    <BR>      3->the-DT-det    <BR>      3->3-CD-num    <BR>  1->track-VBP-parataxis    <BR>    2->variables-NNS-nsubj    <BR>      3->4-CD-num    <BR>    2->obtained-VBN-ccomp    <BR>      3->whether-IN-mark    <BR>      3->system-NN-nsubj    <BR>        4->the-DT-det    <BR>      3->has-VBZ-aux    <BR>      3->value-NN-dobj    0.0908254790321         0.126146498656<BR>        4->attribute-NN-poss    0.161467518279<BR>          5->the-DT-det    <BR>  1->confidence-NN-nsubj    0.0555044594085         0.0571843291813<BR>    2->system-NN-poss    0.0535932010783<BR>      3->the-DT-det    <BR>    2->value-NN-prep_in    0.0908254790321<BR>      3->the-DT-det    <BR>      3->obtained-VBD-dep    0.0383405551651<BR>        4->if-IN-mark    <BR>    2->number-NN-conj_and    0.0252292997311<BR>      3->the-DT-det    <BR>      3->times-NNS-prep_of    0.0246135215654<BR>        4->asked-VBN-rcmod    0.018460141174<BR>          5->system-NN-nsubj    0.0535932010783<BR>            6->the-DT-det    <BR>          5->has-VBZ-aux    <BR>          5->user-NN-dobj    0.0949142792227<BR>            6->the-DT-det    <BR>            6->attribute-NN-prep_about    0.161467518279<BR>              7->the-DT-det    <BR>    2->type-NN-conj_and    0.0307669019567<BR>      3->the-DT-det    <BR>      3->grammar-NNP-prep_of    0.0492270431307<BR>        4->ASR-NNP-nn    0.0468606785352<BR>  1->number-NN-nsubj    <BR>  1->type-NN-nsubj    <BR>  1->recently-RB-advmod    <BR>    2->most-RBS-advmod    <BR>  1->ask-VB-xcomp    <BR>    2->confidence-NN-xsubj    <BR>    2->number-NN-xsubj    <BR>    2->type-NN-xsubj    <BR>    2->to-TO-aux    <BR>    2->attribute-NN-prep_for    <BR>      3->the-DT-det    <BR>'
p405
sg11
F0.080833466
sg12
S'Solely for the purposes of controlling its operation (as opposed to the learning, which we discuss in a moment), NJFun internally maintains an operations vector of 14 variables. 2 variables track whether the system has greeted the user, and which attribute the system is currently attempting to obtain. '
p406
sg14
F0.009720221861282644
saa(lp407
S'C00-1073-45'
p408
a(dp409
g5
S'Our methodology involves 1) representing a dialogue strategy as a mapping from each state in the chosen state space S to a set of dialogue actions, 2) deploying an initial training system that generates exploratory training data with respect to S, 3) constructing an MDP model from the obtained training data, 4) using value iteration to learn the optimal dialogue strategy in the learned MDP, and 4) redeploying the system using the learned state/action mapping.'
p410
sg7
S'The next section details the use of this methodology to design the NJFun system.  NJFun is a real-time spoken dialogue system that provides users with information about things to do in New Jersey. '
p411
sg9
S'0->involves-VBZ-root             0.0201832828198<BR>  1->methodology-NN-nsubj    0.0511203426581         0.0511203426581<BR>    2->Our-PRP$-poss    <BR>  1->constructing-VBG-dep    <BR>    2->strategy-NN-nsubj    <BR>      3->1-LS-dep    <BR>      3->representing-RB-advmod    <BR>      3->a-DT-det    <BR>      3->dialogue-NN-nn    <BR>      3->mapping-NN-prep_as    <BR>        4->a-DT-det    <BR>        4->state-NN-prep_from    <BR>          5->each-DT-det    <BR>          5->S-NNP-prep_in    <BR>            6->the-DT-det    <BR>            6->chosen-JJ-amod    <BR>            6->state-NN-nn    <BR>            6->space-NN-nn    <BR>            6->set-NN-prep_to    <BR>              7->a-DT-det    <BR>              7->actions-NNS-prep_of    <BR>                8->dialogue-NN-nn    <BR>      3->2-CD-amod    <BR>      3->deploying-VBG-partmod    <BR>        4->system-NN-dobj    <BR>          5->an-DT-det    <BR>          5->initial-JJ-amod    <BR>          5->training-NN-nn    <BR>          5->generates-VBZ-rcmod    <BR>            6->system-NN-nsubj    <BR>            6->data-NNS-dobj    <BR>              7->exploratory-JJ-amod    <BR>              7->training-NN-nn    <BR>            6->respect-NN-prep_with    <BR>            6->S-NNP-prep_to    <BR>              7->3-CD-amod    <BR>    2->model-NN-dobj    0.0681604568774         0.0809405425419<BR>      3->an-DT-det    <BR>      3->MDP-NNP-nn    0.136320913755<BR>      3->training-NN-prep_from    0.0681604568774<BR>        4->the-DT-det    <BR>        4->obtained-JJ-amod    0.0511203426581<BR>    2->data-NNS-dep    <BR>      3->4-CD-amod    <BR>    2->using-VBG-partmod    <BR>      3->iteration-NN-dobj    <BR>        4->value-NN-nn    <BR>      3->learn-VB-xcomp    <BR>        4->to-TO-aux    <BR>        4->strategy-NN-dobj    <BR>          5->the-DT-det    <BR>          5->optimal-JJ-amod    <BR>          5->dialogue-NN-nn    <BR>        4->MDP-NNP-prep_in    <BR>          5->the-DT-det    <BR>          5->learned-NNP-nn    <BR>        4->redeploying-VB-conj_and    <BR>          5->4-LS-dep    <BR>          5->system-NN-dobj    <BR>            6->the-DT-det    <BR>          5->using-VBG-xcomp    <BR>            6->mapping-NN-dobj    <BR>              7->the-DT-det    <BR>              7->learned-JJ-amod    <BR>              7->state/action-NN-nn    <BR>      3->redeploying-VB-xcomp    <BR>'
p412
sg11
F-0.85470471
sg12
S'Our approach is to work directly in a minimal but carefully designed state space (Singh et al., 1999). The contribution of this paper is to empirically validate a practical methodology for using RL to build a dialogue system that optimizes its behavior from dialogue data. '
p413
sg14
F0.009573355113076984
saa(lp414
S'C00-1073-104'
p415
a(dp416
g5
S"The third state represents that NJFun is now working on the second attribute (location), that it already has this value with high confidence (location was obtained with activity after the user's first utterance), and that the dialogue history is good.4 This time NJFun chooses the ExpConf2 strategy, and confirms the attribute with the second NJFun utterance, and the state changes again."
p417
sg7
S'The processing of time is similar to that of location, which leads NJFun to the final state, where it performs the action &quot;Tell&quot; (corresponding to querying the database, presenting the results to the user, and asking the user to provide a reward). Note that in NJFun, the reward is always 0 except at the terminal state, as shown in the last column of Figure 5.  '
p418
sg9
S'0->represents-VBZ-root             0.0307669019567<BR>  1->state-NN-nsubj    0.106501542125         0.0563274612584<BR>    2->The-DT-det    <BR>    2->third-JJ-amod    0.00615338039134<BR>  1->working-VBG-ccomp    <BR>    2->that-IN-mark    <BR>    2->NJFun-NNP-nsubj    <BR>    2->is-VBZ-aux    <BR>    2->now-RB-advmod    <BR>    2->attribute-NN-prep_on    <BR>      3->the-DT-det    <BR>      3->second-JJ-amod    <BR>      3->location-NN-appos    <BR>    2->has-VBZ-conj_and    <BR>      3->that-IN-mark    <BR>      3->it-PRP-nsubj    <BR>      3->already-RB-advmod    <BR>      3->value-NN-dobj    0.0908254790321         0.0505371420809<BR>        4->this-DT-det    <BR>        4->confidence-NN-prep_with    0.0555044594085<BR>          5->high-JJ-amod    0.0123067607827<BR>          5->obtained-VBN-dep    0.0383405551651<BR>            6->location-NN-nsubjpass    0.0492270431307<BR>            6->was-VBD-auxpass    <BR>            6->activity-NN-prep_with    0.0504585994623<BR>            6->utterance-NN-prep_after    0.0201834397849<BR>              7->user-NN-poss    0.0949142792227<BR>                8->the-DT-det    <BR>              7->first-JJ-amod    0.0430736627394<BR>    2->good-JJ-conj_and    <BR>      3->that-IN-mark    <BR>      3->history-NN-nsubj    <BR>        4->the-DT-det    <BR>        4->dialogue-NN-nn    <BR>      3->is-VBZ-cop    <BR>      3->.4-CD-dep    <BR>      3->chooses-VBZ-ccomp    <BR>        4->NJFun-NN-nsubj    <BR>          5->This-DT-det    <BR>          5->time-NN-nn    <BR>        4->strategy-NN-dobj    <BR>          5->the-DT-det    <BR>          5->ExpConf2-JJ-amod    <BR>        4->confirms-VBZ-conj_and    <BR>          5->NJFun-NN-nsubj    <BR>          5->attribute-NN-dobj    <BR>            6->the-DT-det    <BR>          5->utterance-NN-prep_with    <BR>            6->the-DT-det    <BR>            6->second-JJ-amod    <BR>            6->NJFun-NNP-nn    <BR>      3->confirms-VBZ-ccomp    <BR>  1->has-VBZ-ccomp    <BR>  1->good-JJ-ccomp    <BR>  1->changes-VBZ-conj_and    <BR>    2->state-NN-nsubj    <BR>      3->the-DT-det    <BR>    2->again-RB-advmod    <BR>'
p419
sg11
F-0.76769424
sg12
S"After the user's response, the next state represents that NJFun has now greeted the user and obtained the activity value with high confidence, by using a nonrestrictive grammar. NJFun then chooses the NoConf strategy, so it does not attempt to confirm the activity, which causes the state to change but no prompt to be generated. "
p420
sg14
F0.00859925418655866
saa(lp421
S'C00-1073-105'
p422
a(dp423
g5
S'The processing of time is similar to that of location, which leads NJFun to the final state, where it performs the action &quot;Tell&quot; (corresponding to querying the database, presenting the results to the user, and asking the user to provide a reward).'
p424
sg7
S'Note that in NJFun, the reward is always 0 except at the terminal state, as shown in the last column of Figure 5.  We collected experimental dialogues for both training and testing our system. '
p425
sg9
S'0->similar-JJ-root             0.0100917198925<BR>  1->processing-NN-nsubj    0.00615338039134         0.0215368313697<BR>    2->The-DT-det    <BR>    2->time-NN-prep_of    0.0369202823481<BR>  1->is-VBZ-cop    <BR>  1->that-DT-prep_to    <BR>    2->location-NN-prep_of    <BR>      3->leads-VBZ-rcmod    <BR>        4->location-NN-nsubj    <BR>        4->NJFun-NNP-dobj    0.173389768195         0.173389768195<BR>        4->state-NN-prep_to    <BR>          5->the-DT-det    <BR>          5->final-JJ-amod    <BR>          5->performs-VBZ-rcmod    <BR>            6->where-WRB-advmod    <BR>            6->it-PRP-nsubj    <BR>            6->Tell-VB-dobj    <BR>              7->the-DT-det    <BR>              7->action-NN-dep    <BR>              7->corresponding-JJ-dep    <BR>                8->querying-VBG-prepc_to    <BR>                  9->database-NN-dobj    <BR>                    10->the-DT-det    <BR>                  9->presenting-VBG-conj_and    <BR>                    10->results-NNS-dobj    <BR>                      11->the-DT-det    <BR>                    10->user-NN-prep_to    <BR>                      11->the-DT-det    <BR>                  9->asking-VBG-conj_and    <BR>                    10->user-NN-dobj    <BR>                      11->the-DT-det    <BR>                      11->provide-VB-infmod    <BR>                        12->to-TO-aux    <BR>                        12->reward-NN-dobj    <BR>                          13->a-DT-det    <BR>                8->presenting-VBG-prepc_to    <BR>                8->asking-VBG-prepc_to    <BR>'
p426
sg11
F-0.58932688
sg12
S"NJFun then chooses the NoConf strategy, so it does not attempt to confirm the activity, which causes the state to change but no prompt to be generated. The third state represents that NJFun is now working on the second attribute (location), that it already has this value with high confidence (location was obtained with activity after the user's first utterance), and that the dialogue history is good.4 This time NJFun chooses the ExpConf2 strategy, and confirms the attribute with the second NJFun utterance, and the state changes again. "
p427
sg14
F0.008461944248455356
saa(lp428
S'C00-1073-4'
p429
a(dp430
g5
S'The role of the dialogue manager in such systems is to interact in a natural way to help the user complete the tasks that the system is designed to support.'
p431
sg7
S'Typically, an expert designs a dialogue manager by hand, and has to make many nontrivial design choices that can seriously impact system performance. This paper applies reinforcement learning (RL) to automatically learn design choices that optimize system performance for a chosen performance measure (Levin et al., 2000; Walker et al., 1998). '
p432
sg9
S'0->is-VBZ-root             0.0683772228366<BR>  1->role-NN-nsubj    0.0288142303435         0.117388032394<BR>    2->The-DT-det    <BR>    2->manager-NN-prep_of    0.0708842432248<BR>      3->the-DT-det    <BR>      3->dialogue-NN-nn    0.310008307176<BR>      3->systems-NNS-prep_in    0.0598453488308<BR>        4->such-JJ-amod    <BR>  1->interact-VB-xcomp    <BR>    2->role-NN-xsubj    <BR>    2->to-TO-aux    <BR>    2->way-NN-prep_in    <BR>      3->a-DT-det    <BR>      3->natural-JJ-amod    <BR>    2->help-VB-xcomp    <BR>      3->to-TO-aux    <BR>      3->complete-VB-ccomp    <BR>        4->user-NN-nsubj    <BR>          5->the-DT-det    <BR>        4->tasks-NNS-dobj    0.0236280810749         0.0236280810749<BR>          5->the-DT-det    <BR>        4->designed-VBN-ccomp    <BR>          5->that-IN-mark    <BR>          5->system-NN-nsubjpass    <BR>            6->the-DT-det    <BR>          5->is-VBZ-auxpass    <BR>          5->support-VB-xcomp    <BR>            6->system-NN-xsubj    <BR>            6->to-TO-aux    <BR>'
p433
sg11
F0.26468172
sg12
S'We then show that our approach measurably improves performance in an experimental system.  Recent advances in spoken language understanding have made it possible to develop dialogue systems for many applications. '
p434
sg14
F0.008094098496351506
saa(lp435
S'C00-1073-33'
p436
a(dp437
g5
S"The problem of learning the best dialogue strategy from data is thus reduced to computing the optimal policy for choosing actions in an MDP that is, the system's goal is to take actions so as to maximize expected reward."
p438
sg7
S'The computation of the optimal policy given the MDP can be done efficiently using standard RL algorithms. How do we build the desired MDP from sample dialogues? '
p439
sg9
S'0->reduced-VBN-root             0.0246133301479<BR>  1->problem-NN-nsubjpass    0.0340802284387         0.0754929664591<BR>    2->The-DT-det    <BR>    2->learning-VBG-prepc_of    0.0146020832433<BR>      3->strategy-NN-dobj    0.0756604013478<BR>        4->the-DT-det    <BR>        4->best-JJS-amod    0.0201832828198<BR>        4->dialogue-NN-nn    0.18915100337<BR>        4->data-NNS-prep_from    0.119280799535<BR>  1->is-VBZ-auxpass    <BR>  1->thus-RB-advmod    <BR>  1->computing-VBG-prepc_to    <BR>    2->policy-NN-dobj    0.0492266602957         0.0586935585866<BR>      3->the-DT-det    <BR>      3->optimal-JJ-amod    0.0681604568774<BR>    2->choosing-VBG-prepc_for    <BR>      3->actions-NNS-dobj    <BR>        4->MDP-NNP-prep_in    <BR>          5->an-DT-det    <BR>        4->is-VBZ-rcmod    <BR>          5->actions-NNS-nsubj    <BR>          5->is-VBZ-ccomp    <BR>            6->goal-NN-nsubj    <BR>              7->system-NN-poss    <BR>                8->the-DT-det    <BR>            6->take-VB-xcomp    <BR>              7->goal-NN-xsubj    <BR>              7->to-TO-aux    <BR>              7->actions-NNS-dobj    <BR>              7->as-RB-advmod    <BR>                8->so-RB-advmod    <BR>                8->maximize-VB-dep    <BR>                  9->to-TO-aux    <BR>                  9->reward-NN-dobj    <BR>                    10->expected-JJ-amod    <BR>'
p440
sg11
F-0.8045599
sg12
S"(We discuss various choices for this reward measure later, but in our experiments only terminal dialogue states have nonzero rewards, and the reward measures are quantities directly obtainable from the experimental set-up, such as user satisfaction or task completion. ) This experimental data is used to construct an MDP which models the users' interaction with the system. "
p441
sg14
F0.008044363528902393
saa(lp442
S'C00-1073-64'
p443
a(dp444
g5
S'In NJFun, we restricted the action choices to 1) the type of initiative to use when asking or reasking for an attribute, and 2) whether to confirm an attribute value once obtained.'
p445
sg7
S'The optimal actions may vary with dialogue state, and are subject to active debate in the literature. The examples in Figure 2 show that NJFun can ask the user about the first 2 attributes) using three types of initiative, based on the combination of the wording of the system prompt (open versus directive), and the type of grammar NJFun uses during ASR (restrictive versus non-restrictive). '
p446
sg9
S'0->restricted-VBZ-root             0.0123067607827<BR>  1->NJFun-NNP-prep_in    <BR>  1->we-PRP-nsubj             0.0<BR>  1->choices-NNS-dobj    0.031525412399         0.04856079585<BR>    2->the-DT-det    <BR>    2->action-NN-nn    0.065596179301<BR>  1->type-NN-prep_to    <BR>    2->1-LS-dep    <BR>    2->the-DT-det    <BR>    2->initiative-NN-prep_of    <BR>    2->use-VB-infmod    <BR>      3->to-TO-aux    <BR>      3->asking-VBG-dep    <BR>        4->when-WRB-advmod    <BR>        4->reasking-VBG-conj_or    <BR>        4->attribute-NN-prep_for    <BR>          5->an-DT-det    <BR>        4->obtained-VBD-conj_and    <BR>          5->2-LS-dep    <BR>          5->whether-IN-mark    <BR>          5->confirm-VB-csubj    <BR>            6->to-TO-aux    <BR>            6->value-NN-dobj    <BR>              7->an-DT-det    <BR>              7->attribute-NN-nn    <BR>            6->once-RB-advmod    <BR>      3->reasking-VBG-dep    <BR>      3->obtained-VBD-dep    <BR>'
p447
sg11
F-1.491282
sg12
S'Note that at some states it is easy for a human to make the correct action choice. We made obvious dialogue strategy choices in advance, and used learning only to optimize the difficult choices (Walker et al., 1998). '
p448
sg14
F0.007995726591504092
saa(lp449
S'P10-1024-280'
p450
a(dp451
g5
S'This is an indication that the collocation between the argument and the preposition is more indicative of the core/adjunct label than the obligatoriness of the slot (as expressed by the predicate-slot collocation).'
p452
sg7
S'Indeed, we can find examples where adjuncts, although optional, appear very often with a certain verb. An example is \xe2\x80\x98meet\xe2\x80\x99, which often takes a temporal adjunct, as in \xe2\x80\x98Let\xe2\x80\x99s meet [in July]\xe2\x80\x99. '
p453
sg9
S'0->indication-NN-root             0.0216289745918<BR>  1->This-DT-nsubj             0.0<BR>  1->is-VBZ-cop    <BR>  1->an-DT-det    <BR>  1->indicative-JJ-ccomp    <BR>    2->that-IN-mark    <BR>    2->collocation-NN-nsubj    <BR>      3->the-DT-det    <BR>      3->argument-NN-prep_between    <BR>        4->the-DT-det    <BR>        4->preposition-NN-conj_and    <BR>          5->the-DT-det    <BR>      3->preposition-NN-prep_between    <BR>    2->is-VBZ-cop    <BR>    2->more-RBR-advmod    <BR>    2->label-NN-prep_of    <BR>      3->the-DT-det    <BR>      3->core/adjunct-JJ-amod    <BR>      3->obligatoriness-NNS-prep_than    <BR>        4->the-DT-det    <BR>        4->slot-NN-prep_of    <BR>          5->the-DT-det    <BR>        4->expressed-VBD-dep    <BR>          5->as-IN-mark    <BR>          5->collocation-NN-prep_by    <BR>            6->the-DT-det    <BR>            6->predicate-slot-JJ-amod    <BR>'
p454
sg11
F-1.5931693
sg12
S'Table 1 presents the results of our main experiments. In both scenarios, the most accurate of the three basic classifiers was the argument-slot collocation classifier. '
p455
sg14
F0.006323716971490127
saa(lp456
S'P10-1024-119'
p457
a(dp458
g5
S'We define three measures, one quantifying the obligatoriness of the slot, another quantifying the selectional preference of the verb to the argument and a third that quantifies the association between the head word and the slot irrespective of the predicate (Section 3.3).'
p459
sg7
S'The measures\xe2\x80\x99 predictions are expected to coincide in clear cases, but may be less successful in others. Therefore, an ensemble-based method is used to combine the three measures into a single classifier. '
p460
sg9
S'0->define-VB-root             0.0219814958908<BR>  1->We-PRP-nsubj             0.0<BR>  1->measures-NNS-dobj    0.0346751757966         0.0308144120866<BR>    2->three-CD-num    0.0148607896271<BR>    2->one-CD-conj_and    0.0176655167791<BR>      3->quantifying-VBG-partmod    0.00879259835633<BR>        4->obligatoriness-NNS-dobj    0.00709381299119<BR>          5->the-DT-det    <BR>          5->slot-NN-prep_of    0.0767807464068<BR>            6->the-DT-det    <BR>    2->another-DT-conj_and    0.0131888975345<BR>      3->quantifying-VBG-partmod    0.00879259835633<BR>        4->preference-NN-dobj    0.0319221584604<BR>          5->the-DT-det    <BR>          5->selectional-JJ-amod    0.0248283454692<BR>          5->verb-NN-prep_of    0.0567505039295<BR>            6->the-DT-det    <BR>        4->argument-NN-prep_to    0.106837865811<BR>          5->the-DT-det    <BR>    2->third-JJ-conj_and    0.00439629917817<BR>      3->a-DT-det    <BR>      3->quantifies-VBZ-rcmod    0.00439629917817<BR>        4->third-JJ-nsubj    0.00439629917817<BR>        4->association-NN-dobj    0.00439629917817<BR>          5->the-DT-det    <BR>          5->word-NN-prep_between    0.0602974104251<BR>            6->the-DT-det    <BR>            6->head-NN-nn    0.0618293087269<BR>          5->irrespective-NN-conj_and    0.00879259835633<BR>            6->the-DT-det    <BR>            6->slot-NN-nn    0.0767807464068<BR>            6->predicate-NN-prep_of    0.0767807464068<BR>              7->the-DT-det    <BR>        4->irrespective-NN-dobj    0.00879259835633<BR>      3->Section-NN-appos    0.0264982751687<BR>        4->3.3-CD-num    0.0<BR>  1->one-CD-dobj    <BR>  1->another-DT-dobj    <BR>  1->third-JJ-dobj    <BR>'
p461
sg11
F-1.3610652
sg12
S'The sample extraction process is detailed in Section 3.2. Our approach makes use of both aspects of the distinction \xe2\x80\x93 obligatoriness and compositionality. '
p462
sg14
F0.005679284184257599
saa(lp463
S'P10-1024-188'
p464
a(dp465
g5
S'In order not to bias the counts towards predicates which tend to take more arguments, we define here N(p, s) to be the number of times the (p, s) pair occurred in the training corpus, irrespective of the number of head words the argument had (and not e.g., EhN(p, s, h)).'
p466
sg7
S'Argu ments with no prepositions are included in these counts as well (with s = NULL), so not to bias against predicates which tend to have less nonprepositional arguments. '
p467
sg9
S'0->define-VBD-root             0.0219814958908<BR>  1->bias-VB-advcl    <BR>    2->order-NN-prep_in    <BR>    2->not-RB-neg    <BR>    2->to-TO-aux    <BR>    2->counts-NNS-dobj    <BR>      3->the-DT-det    <BR>    2->predicates-NNS-prep_towards    <BR>      3->tend-VBP-rcmod    <BR>        4->predicates-NNS-nsubj    <BR>        4->take-VB-xcomp    <BR>          5->predicates-NNS-xsubj    <BR>          5->to-TO-aux    <BR>          5->arguments-NNS-dobj    <BR>            6->more-JJR-amod    <BR>  1->we-PRP-nsubj             0.0<BR>  1->here-RB-advmod    <BR>  1->N-NNP-dobj    0.0         0.0<BR>    2->p-NN-dep    0.0<BR>      3->s-PRP-dep    <BR>  1->number-NN-xcomp    <BR>    2->we-PRP-xsubj    <BR>    2->to-TO-aux    <BR>    2->be-VB-cop    <BR>    2->the-DT-det    <BR>    2->times-NNS-prep_of    <BR>      3->occurred-VBD-rcmod    <BR>        4->times-NNS-dobj    <BR>        4->pair-NN-nsubj    <BR>          5->the-DT-det    <BR>          5->p-NN-dep    <BR>            6->s-PRP-dep    <BR>        4->corpus-NN-prep_in    <BR>          5->the-DT-det    <BR>          5->training-NN-nn    <BR>        4->number-NN-prep_irrespective_of    <BR>          5->the-DT-det    <BR>          5->words-NNS-prep_of    <BR>            6->head-NN-nn    <BR>    2->had-VBD-parataxis    <BR>      3->argument-NN-nsubj    <BR>        4->the-DT-det    <BR>      3->EhN-NNS-dobj    <BR>        4->e.g.-NNP-dep    <BR>          5->and-CC-cc    <BR>          5->not-RB-dep    <BR>        4->h-NN-appos    <BR>          5->p-NN-nn    <BR>          5->s-NNS-dep    <BR>'
p468
sg11
F-1.5837696
sg12
S'Let p be a predicate and s a slot, then:  Since there is only a meager number of possible slots (that is, of prepositions), estimating the (predicate, slot) distribution can be made by the maximum likelihood estimator with manageable sparsity. '
p469
sg14
F0.005646025675001923
saa(lp470
S'P10-1024-9'
p471
a(dp472
g5
S'The marked argument is a core in 1 and an adjunct in 2 and 3.'
p473
sg7
S'Adjuncts form an independent semantic unit and their semantic role can often be inferred independently of the predicate (e.g., [after lunch] is usually a temporal modifier). Core \xe2\x88\x97 Omri Abend is grateful to the Azrieli Foundation for the award of an Azrieli Fellowship. '
p474
sg9
S'0->core-NN-root             0.122585278274<BR>  1->argument-NN-nsubj    0.122585278274         0.0761179904431<BR>    2->The-DT-det    <BR>    2->marked-JJ-amod    0.0296507026125<BR>  1->is-VBZ-cop    <BR>  1->a-DT-det    <BR>  1->1-CD-prep_in    <BR>  1->adjunct-NN-conj_and    <BR>    2->an-DT-det    <BR>    2->2-CD-prep_in    <BR>      3->3-CD-conj_and    <BR>    2->3-CD-prep_in    <BR>'
p475
sg11
F1.3908288
sg12
S'Adjuncts are optional arguments which, like adverbs, modify the meaning of the described event in a predictable or predicate-independent manner. Consider the following examples:  '
p476
sg14
F0.005569316727695694
saa(lp477
S'P10-1024-203'
p478
a(dp479
g5
S'In order to avoid tuning a parameter for each of the measures, we set the threshold as the median value of this measure in the test set.'
p480
sg7
S'That is, we find the threshold which tags half of the arguments as cores and half as adjuncts. This relies on the prior knowledge that prepositional arguments are roughly equally divided between cores and adjuncts7.  '
p481
sg9
S'0->set-VBD-root             0.0559408031338<BR>  1->avoid-VB-advcl    <BR>    2->In-IN-mark    <BR>    2->order-NN-dep    <BR>    2->to-TO-aux    <BR>    2->tuning-VBG-xcomp    <BR>      3->parameter-NN-dobj    <BR>        4->a-DT-det    <BR>      3->each-DT-prep_for    <BR>        4->measures-NNS-prep_of    <BR>          5->the-DT-det    <BR>  1->we-PRP-nsubj             0.0<BR>  1->threshold-NN-dobj    0.0219814958908         0.0219814958908<BR>    2->the-DT-det    <BR>  1->value-NN-prep_as    <BR>    2->the-DT-det    <BR>    2->median-JJ-amod    <BR>    2->measure-NN-prep_of    <BR>      3->this-DT-det    <BR>  1->set-NN-prep_in    <BR>    2->the-DT-det    <BR>    2->test-NN-nn    <BR>'
p482
sg11
F-0.5166134
sg12
S'Thresholding. In order to turn these measures into classifiers, we set a threshold below which arguments are marked as adjuncts and above which as cores. '
p483
sg14
F0.005420468336813949
saa(lp484
S'P10-1024-217'
p485
a(dp486
g5
S'We therefore apply the following procedure: (1) tag the training data with the ensemble classifier; (2) for each test sample x, if more than a ratio of \xce\xb1 of the training samples sharing the same predicate and slot with x are labeled as cores, tag x as core.'
p487
sg7
S'Otherwise, tag x as adjunct. Test samples which do not share a predicate and a slot with any training sample are considered out of coverage. '
p488
sg9
S'0->apply-VB-root             0.00879259835633<BR>  1->We-PRP-nsubj             0.0<BR>  1->therefore-RB-advmod    <BR>  1->procedure-NN-dobj    0.00879259835633         0.0114901121694<BR>    2->the-DT-det    <BR>    2->following-VBG-amod    0.0141876259824<BR>  1->tag-VB-parataxis    <BR>    2->1-CD-nsubj    <BR>    2->data-NNS-dobj    <BR>      3->the-DT-det    <BR>      3->training-NN-nn    <BR>    2->classifier-NN-prep_with    <BR>      3->the-DT-det    <BR>      3->ensemble-NN-nn    <BR>  1->x-VBZ-parataxis    <BR>    2->2-LS-dep    <BR>    2->x-VBZ-advcl    <BR>      3->for-IN-mark    <BR>      3->sample-NN-nsubj    <BR>        4->each-DT-det    <BR>        4->test-NN-nn    <BR>      3->labeled-VBN-advcl    <BR>        4->if-IN-mark    <BR>        4->ratio-NN-nsubjpass    <BR>          5->a-DT-num    <BR>            6->than-IN-quantmod    <BR>              7->more-JJR-mwe    <BR>          5->\xce\xb1-NN-prep_of    <BR>            6->samples-NNS-prep_of    <BR>              7->the-DT-det    <BR>              7->training-NN-nn    <BR>              7->sharing-VBG-partmod    <BR>                8->predicate-NN-dobj    <BR>                  9->the-DT-det    <BR>                  9->same-JJ-amod    <BR>                  9->slot-NN-conj_and    <BR>                  9->x-NNP-prep_with    <BR>                8->slot-NN-dobj    <BR>        4->are-VBP-auxpass    <BR>        4->cores-NNS-prep_as    <BR>    2->tag-NN-nsubj    <BR>    2->core-NN-prep_as    <BR>'
p489
sg11
F-1.85237
sg12
S'For instance, in our development data, a classifier which assigns all arguments that share a predicate and a slot their most common label, yields 94.3% accuracy on the pairs appearing at least 5 times. This property of the core-adjunct distinction greatly simplifies the task for supervised algorithms (see Section 2). '
p490
sg14
F0.0052913894397003175
saa(lp491
S'P10-1024-160'
p492
a(dp493
g5
S'Since the semantics of cores is more predicate dependent than the semantics of adjuncts, we expect arguments for which the predicate has a strong preference (in a specific slot) to be cores.'
p494
sg7
S'Selectional preference induction is a wellestablished task in NLP. It aims to quantify the likelihood that a certain argument appears in a certain slot of a predicate. '
p495
sg9
S'0->expect-VBP-root             0.00709381299119<BR>  1->dependent-JJ-advcl    <BR>    2->Since-IN-mark    <BR>    2->semantics-NNS-nsubj    <BR>      3->the-DT-det    <BR>      3->cores-NNS-prep_of    <BR>    2->is-VBZ-cop    <BR>    2->predicate-JJ-dep    <BR>      3->more-RBR-advmod    <BR>    2->semantics-NNS-prep_than    <BR>      3->the-DT-det    <BR>      3->adjuncts-NNS-prep_of    <BR>  1->we-PRP-nsubj             0.0<BR>  1->cores-NNS-xcomp    <BR>    2->arguments-NNS-nsubj    <BR>      3->has-VBZ-rcmod    <BR>        4->arguments-NNS-prep_for    <BR>        4->predicate-NN-nsubj    <BR>          5->the-DT-det    <BR>        4->preference-NN-dobj    0.0319221584604         0.0195079857258<BR>          5->a-DT-det    <BR>          5->strong-JJ-amod    0.00709381299119<BR>        4->in-IN-dep    <BR>          5->slot-NN-pobj    <BR>            6->a-DT-det    <BR>            6->specific-JJ-amod    <BR>    2->to-TO-aux    <BR>    2->be-VB-cop    <BR>'
p496
sg11
F-1.8398502
sg12
S'We now compute the following measures. Selectional Preference (SP). '
p497
sg14
F0.005259931113991863
saa(lp498
S'W06-3312-82'
p499
a(dp500
g5
S'If no nominalizations are present in the NP, instead of defaulting to VP attachment, the PP is attached to the closest NP to its left that is not the object of an of PP.'
p501
sg7
S'This behavior is intuitively consistent since in PPs are usually adjuncts to the main NP (which is usually an entity if not a nominalization) and are unlikely to modify any of the NP\xe2\x80\x99s modifiers.  The final heuristic encodes the frequent attachment of on PPs with NPs indicating effect, influence, impact, etc. '
p502
sg9
S'0->attached-VBN-root             0.0369731288737<BR>  1->present-JJ-advcl    <BR>    2->If-IN-mark    <BR>    2->nominalizations-NNS-nsubj    <BR>      3->no-DT-det    <BR>    2->are-VBP-cop    <BR>    2->NP-NNP-prep_in    <BR>      3->the-DT-det    <BR>    2->defaulting-VBG-prepc_instead_of    <BR>      3->attachment-NNP-prep_to    <BR>        4->VP-NNP-nn    <BR>  1->PP-NNP-nsubjpass    0.133103263945         0.133103263945<BR>    2->the-DT-det    <BR>  1->is-VBZ-auxpass    <BR>  1->NP-NN-prep_to    <BR>    2->the-DT-det    <BR>    2->closest-JJS-amod    <BR>  1->left-NN-prep_to    <BR>    2->its-PRP$-poss    <BR>    2->object-NN-rcmod    <BR>      3->left-NN-nsubj    <BR>      3->is-VBZ-cop    <BR>      3->not-RB-neg    <BR>      3->the-DT-det    <BR>      3->an-DT-prep_of    <BR>        4->PP-NNP-prep_of    <BR>'
p503
sg11
F-0.68691157
sg12
S'The major form of beta-amylase in Arabidopsis.. . Here, the system first attempts nominalization attachment. '
p504
sg14
F0.00781129229652004
saa(lp505
S'W06-3312-123'
p506
a(dp507
g5
S'The application of right association for PPs headed by of, for, and from resulted in correct attachment in 96.2% of their occurrences in the development corpus.'
p508
sg7
S'Because this class of PPs is processed using the baseline heuristic without any refinements, it has no effect on overall system accuracy as compared to overall baseline accuracy. However, it does provide a clear delineation of the subset of PPs for which right association is a sufficient and optimal solution for attachment. '
p509
sg9
S'0->resulted-VBD-root             0.0218233207542<BR>  1->application-NN-nsubj    0.0072744402514         0.0534803685475<BR>    2->The-DT-det    <BR>    2->association-NN-prep_of    0.0357908704107<BR>      3->right-JJ-amod    0.0417560154792<BR>      3->PPs-NNP-prep_for    0.164685081391<BR>        4->headed-VBN-partmod    0.0178954352054<BR>          5->by-IN-prep    <BR>            6->of-IN-pcomp    <BR>            6->for-IN-conj_and    <BR>            6->from-IN-conj_and    <BR>          5->for-IN-prep    <BR>          5->from-IN-prep    <BR>  1->attachment-NN-prep_in    <BR>    2->correct-JJ-amod    <BR>    2->%-NN-prep_in    <BR>      3->96.2-CD-num    <BR>      3->occurrences-NNS-prep_of    <BR>        4->their-PRP$-poss    <BR>  1->corpus-NN-prep_in    <BR>    2->the-DT-det    <BR>    2->development-NN-nn    <BR>'
p510
sg11
F-1.3800454
sg12
S'Thus all reported accuracy numbers reflect performance of the heuristics alone, isolated from possible chunking errors. The PP attachment module is, however, designed for input from the chunker and does not handle constructs which the chunker does not provide (e.g. PP conjunctions and non-simple parenthetical NPs).  '
p511
sg14
F0.007193093444902659
saa(lp512
S'W06-3312-165'
p513
a(dp514
g5
S'Overall system improvement over baseline attachment accuracy can be achieved through successful attachment of this class of PPs, particularly in and with PPs, which are the second and fourth most frequently used PPs in the development corpus, respectively.'
p515
sg7
S'Unfortunately, the usage of these PPs is also perhaps the hardest to characterize. The heuristic achieves only 76.2% accuracy. '
p516
sg9
S'0->achieved-VBN-root             0.0218233207542<BR>  1->improvement-NN-nsubjpass    0.0218233207542         0.0797249446834<BR>    2->Overall-JJ-amod    0.0581955220112<BR>    2->system-NN-nn    0.0559033525426<BR>    2->accuracy-NN-prep_over    0.125153218292<BR>      3->baseline-JJ-amod    0.0945677232682<BR>      3->attachment-NN-nn    0.122706531232<BR>  1->can-MD-aux    <BR>  1->be-VB-auxpass    <BR>  1->attachment-NN-prep_through    <BR>    2->successful-JJ-amod    <BR>    2->class-NN-prep_of    <BR>      3->this-DT-det    <BR>      3->PPs-NNP-prep_of    <BR>  1->particularly-RB-advmod    <BR>  1->in-IN-prep    <BR>    2->with-IN-conj_and    <BR>      3->PPs-NNP-pobj    0.164685081391         0.0679143541629<BR>        4->PPs-NN-rcmod    0.164685081391<BR>          5->PPs-NNP-nsubj    0.164685081391<BR>          5->are-VBP-cop    <BR>          5->the-DT-det    <BR>          5->second-JJ-amod    0.0178954352054<BR>            6->fourth-JJ-conj_and    0.0072744402514<BR>          5->fourth-JJ-amod    0.0072744402514<BR>          5->used-JJ-amod    0.0201447414098<BR>            6->frequently-RB-advmod    0.00596514506846<BR>              7->most-RBS-advmod    <BR>          5->corpus-NN-prep_in    0.0906281925561<BR>            6->the-DT-det    <BR>            6->development-NN-nn    0.0819969361222<BR>          5->respectively-RB-advmod    0.0218233207542<BR>  1->with-IN-prep    <BR>'
p517
sg11
F-0.79897555
sg12
S'There are, however, other similar errors where even the addition of such information does not immediately suggest the proper attachment.  The weak nominalization affinity heuristic covers a large portion of the development corpus (18.2%). '
p518
sg14
F0.007064359896956811
saa(lp519
S'W06-3312-173'
p520
a(dp521
g5
S'This resulted in a 3% increase in the accuracy for in PPs with no adverse effects on any of the other PPs with nominalization affinity.'
p522
sg7
S'Despite further anticipated improvements from similar changes, attachment of in PPs stands to benefit the most from additional semantic information in the form of rules that encode containment semantics (i.e. which types of things can be contained in other types of things). Possible containment rules exist for the few semantic categories that are already implemented; enzymes, for instance, can be contained in organisms, but organisms are rarely contained in anything (though organisms can be said to be contained in their species, the relationship is rarely expressed as containment). '
p523
sg9
S'0->resulted-VBD-root             0.0218233207542<BR>  1->This-DT-nsubj             0.0<BR>  1->increase-NN-prep_in    <BR>    2->a-DT-det    <BR>    2->%-NN-amod    <BR>      3->3-CD-number    <BR>    2->accuracy-NN-prep_in    <BR>      3->the-DT-det    <BR>  1->for-IN-dep    <BR>  1->PPs-NNP-prep_in    <BR>    2->effects-NNS-prep_with    <BR>      3->no-DT-det    <BR>      3->adverse-JJ-amod    <BR>      3->any-DT-prep_on    <BR>        4->PPs-NN-prep_of    <BR>          5->the-DT-det    <BR>          5->other-JJ-amod    <BR>          5->affinity-NN-prep_with    <BR>            6->nominalization-NN-nn    <BR>'
p524
sg11
F-1.5879872
sg12
S'As mentioned above, splitting nominalizations into general and specific classes may solve this problem. To explore this conjecture, the most common (particularly with in PPs) general nominalization, activity, was ignored when searching for nominalization attachment points. '
p525
sg14
F0.006941906593682379
saa(lp526
S'W06-3312-202'
p527
a(dp528
g5
S'The accuracy and coverage of each rule for the test data, as contrasted with the development set, is given in Table 2.'
p529
sg7
S'The baseline heuristic achieved an accuracy of 77.5%. A comparative performance breakdown by preposition is given in Table 1. '
p530
sg9
S'0->given-VBN-root             0.0431562821696<BR>  1->accuracy-NN-nsubjpass    0.125153218292         0.0453929421192<BR>    2->The-DT-det    <BR>    2->coverage-NN-conj_and    0.0298257253423<BR>    2->rule-NN-prep_of    0.0151085560573<BR>      3->each-DT-det    <BR>      3->data-NNS-prep_for    0.0474719103865<BR>        4->the-DT-det    <BR>        4->test-NN-nn    0.0447226820341<BR>    2->contrasted-VBN-dep    0.0145488805028<BR>      3->as-IN-mark    <BR>      3->set-NN-prep_with    0.00431562821696<BR>        4->the-DT-det    <BR>        4->development-NN-nn    0.0819969361222<BR>  1->coverage-NN-nsubjpass    <BR>  1->is-VBZ-auxpass    <BR>  1->Table-NNP-prep_in    <BR>    2->2-CD-num    <BR>'
p531
sg11
F-0.83979889
sg12
S'The system\xe2\x80\x99s overall attachment accuracy on this 8PMC query terms: metabolism, biosynthesis, proteolysis, peptidyltransferase, hexokinase, epimerase, laccase, ligase, dehydrogenase. test data is 82%, comparable to that for the development enzymology data. '
p532
sg14
F0.00687159106120847
saa(lp533
S'W06-3312-216'
p534
a(dp535
g5
S'Applying the strong nominalization affinity heuristic to these PPs resulted in an increase offor PP attachment accuracy in the test corpus to 75.8% and an overall increase in accuracy of 1.0%.'
p536
sg7
S'A similar pattern was observed for at PPs, where the pattern <CHEMICAL> at <CONCENTRATION> accounts for 25.6% of all at PP attachment errors and the majority of the performance decrease for the strong nominalization affinity heuristic between the two data sets. The remainder of the performance decrease for this heuristic is attributed to gaps in the  '
p537
sg9
S'0->resulted-VBD-root             0.0218233207542<BR>  1->Applying-VBG-csubj    0.0072744402514         0.0742135081507<BR>    2->heuristic-NN-dobj    0.1193029013690.119302901369         0.0683303818154<BR>      3->the-DT-det    <BR>      3->strong-JJ-amod    0.02982572534230.0298257253423<BR>      3->nominalization-NN-nn    0.07050659493430.0705065949343<BR>      3->affinity-NN-nn    0.05368630561610.0536863056161<BR>    2->PPs-NNP-prep_to    0.164685081391<BR>      3->these-DT-det    <BR>  1->accuracy-NN-prep_in    <BR>    2->an-DT-det    <BR>    2->increase-NN-nn    <BR>    2->offor-NN-nn    <BR>    2->PP-NN-nn    <BR>    2->attachment-NN-nn    <BR>    2->corpus-NN-prep_in    <BR>      3->the-DT-det    <BR>      3->test-NN-nn    <BR>  1->%-NN-prep_to    <BR>    2->75.8-CD-num    <BR>    2->increase-NN-conj_and    <BR>      3->an-DT-det    <BR>      3->overall-JJ-amod    <BR>  1->increase-NN-prep_to    <BR>  1->accuracy-NN-prep_in    <BR>    2->%-NN-prep_of    <BR>      3->1.0-CD-num    <BR>'
p538
sg11
F-0.81580806
sg12
S'In particular, for PPs with object NPs specifying a duration (or other measurement), as exemplified below, attach almost exclusively to VPs and nominalizations.  This behavior is also apparent in the development data, though in much smaller numbers. '
p539
sg14
F0.006817563755046842
saa(lp540
S'W06-3312-41'
p541
a(dp542
g5
S'In focusing on postnominal PPs, we exclude here PPs that trivially attach to the VP for lack of NP attachment points and focus on the subset of PPs with the highest degree of attachment ambiguity. '
p543
sg7
S'For this exploratory study we compiled two manually annotated corporal, a smaller, targeted development corpus consisting of sentences referring to enzymes in five articles, and a larger test corpus consisting of the full text of nine articles drawn from a wider set of topics. This bias in the data was set deliberately to test whether NPs referring to enzymes follow a distinct pattern. '
p544
sg9
S'0->exclude-VBP-root             0.0265737963594<BR>  1->focusing-VBG-prepc_in    <BR>    2->PPs-NNP-prep_on    <BR>      3->postnominal-JJ-amod    <BR>  1->we-PRP-nsubj             0.0<BR>  1->here-RB-advmod    <BR>  1->PPs-NNP-dobj    0.14385225539         0.0870003718671<BR>    2->attach-VB-rcmod    0.0224354248637<BR>      3->PPs-NNP-nsubj    0.14385225539<BR>      3->trivially-RB-advmod    0.0324065033878<BR>      3->VP-NNP-prep_to    0.0673062745911<BR>        4->the-DT-det    <BR>      3->lack-NN-prep_for    0.0324065033878<BR>        4->points-NNS-prep_of    0.0576763636514<BR>          5->NP-NNP-nn    0.0996163070121<BR>          5->attachment-NN-nn    0.230163608625<BR>      3->focus-VB-conj_and    0.0265737963594<BR>        4->PPs-NNP-nsubj    0.14385225539<BR>        4->subset-NN-prep_on    0.0265737963594<BR>          5->the-DT-det    <BR>          5->PPs-NNP-prep_of    0.14385225539<BR>        4->degree-NN-prep_with    0.0265737963594<BR>          5->the-DT-det    <BR>          5->highest-JJS-amod    0.0324065033878<BR>          5->ambiguity-NNS-prep_of    0.0797213890783<BR>            6->attachment-NN-nn    0.230163608625<BR>    2->focus-VB-rcmod    0.0265737963594<BR>'
p545
sg11
F-0.83421907
sg12
S'Consequently, the possible attachment points for a given PP are more numerous. By \xe2\x80\x9cpostnominal\xe2\x80\x9d, we denote PPs following an NP, where the attachment point may be within the NP but may also precede it. '
p546
sg14
F0.0067478929557186615
saatp547
Rp548
.